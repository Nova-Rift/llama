{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import html\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import sentencepiece as spm\n",
    "from llama import Tokenizer\n",
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16  # how many independent sequences will we process in parallel?\n",
    "block_size = 1000  # what is the maximum context length for predictions?\n",
    "max_iters = 100\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 128\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.01\n",
    "# ------------\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "df = pd.read_csv('../data/opt_intelligence_test_data.csv')\n",
    "\n",
    "# remove NaN\n",
    "df = df.dropna(subset=['PL_DATE_OF_BIRTH'])\n",
    "\n",
    "# remove HTML characters\n",
    "df['O_BODY1'] = df['O_BODY1'].apply(html.unescape)\n",
    "df['O_NAME'] = df['O_NAME'].apply(html.unescape)\n",
    "df['O_HEADLINE1'] = df['O_HEADLINE1'].apply(html.unescape)\n",
    "df['O_DISPLAY_NAME'] = df['O_DISPLAY_NAME'].apply(html.unescape)\n",
    "\n",
    "# shuffle dem bitches\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = math.floor(df.shape[0]*.9)\n",
    "train_data = df.iloc[:n, :]\n",
    "val_data = df.iloc[n:, :]\n",
    "\n",
    "tokenizer = Tokenizer(model_path='tokenizer.model')\n",
    "\n",
    "def get_batch(split):\n",
    "    strings = []\n",
    "    optins = []\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    \n",
    "    # Separate positive and negative classes\n",
    "    df_positive = data[data.OPTED_IN == 1]\n",
    "    df_negative = data[data.OPTED_IN == 0]\n",
    "    \n",
    "    # Select half the batch size from each class\n",
    "    half_batch = batch_size // 2\n",
    "    idx_positive = torch.randperm(len(df_positive))[:half_batch]\n",
    "    idx_negative = torch.randperm(len(df_negative))[:half_batch] + len(df_positive)\n",
    "    \n",
    "    # Combine indices and shuffle\n",
    "    indices = torch.cat([idx_positive, idx_negative])\n",
    "    indices = indices[torch.randperm(len(indices))]\n",
    "\n",
    "    # Join positive and negative classes\n",
    "    df_combined = pd.concat([df_positive, df_negative])\n",
    "\n",
    "    for i in indices:\n",
    "        row = df_combined.iloc[i.item()]\n",
    "        string_dict = row[:-1].to_dict()  # turns row into dictionary cols=keys\n",
    "        string = ', '.join(f'{k}: {v}' for k, v in string_dict.items())  # creates string from row dict\n",
    "        encoded_string = torch.tensor(tokenizer.encode(string, bos=True, eos=False))  # encode string to tensor\n",
    "        full_tensor = torch.full((block_size,), 0)  # create tensor as long as longest and fill with new token\n",
    "        # using same token as <unk> 0\n",
    "        full_tensor[:len(encoded_string)] = encoded_string  # replace beginning of full tensor with original string tensor\n",
    "        encoded_string = full_tensor  # encoded string with padding\n",
    "        strings.append(encoded_string)  # add tensor to list of tensors\n",
    "        optin_dict = row[-1:].to_dict()  # convert optin column to dict\n",
    "        optins.append(optin_dict['opted_in'.upper()])  # add optin value to list\n",
    "        \n",
    "    optins = torch.tensor(optins)  # turn optins list to tensor\n",
    "    \n",
    "    x, y = torch.stack(strings), optins\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "# from typing import Optional, Tuple\n",
    "# from dataclasses import dataclass\n",
    "# import math\n",
    "\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 256\n",
    "    n_layers: int = 4\n",
    "    n_heads: int = 4\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    norm_eps: float = 1e-06\n",
    "    max_batch_size: int = 16\n",
    "    max_seq_len: int = 1024\n",
    "\n",
    "\n",
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight\n",
    "\n",
    "\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis\n",
    "\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "\n",
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cis: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "\n",
    "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        bsz, seqlen, _ = x.shape\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "\n",
    "        xq = xq.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n",
    "\n",
    "        keys = xk\n",
    "        values = xv\n",
    "\n",
    "        xq = xq.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        if mask is not None:\n",
    "            scores = scores + mask\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        output = torch.matmul(scores, values)\n",
    "        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        return self.wo(output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        hidden_dim: int,\n",
    "        multiple_of: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(2 * hidden_dim / 3)\n",
    "        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
    "\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w2(F.silu(self.w1(x)) * self.w3(x))\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.attention = Attention(args)\n",
    "        self.feed_forward = FeedForward(\n",
    "            dim=args.dim, hidden_dim=4 * args.dim, multiple_of=args.multiple_of\n",
    "        )\n",
    "        self.layer_id = layer_id\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        h = x + self.attention.forward(self.attention_norm(x), start_pos, freqs_cis, mask)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, params: ModelArgs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = params\n",
    "        self.vocab_size = params.vocab_size\n",
    "        self.n_layers = params.n_layers\n",
    "\n",
    "        self.tok_embeddings = nn.Embedding(params.vocab_size, params.dim)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for layer_id in range(params.n_layers):\n",
    "            self.layers.append(TransformerBlock(layer_id, params))\n",
    "\n",
    "        self.norm = RMSNorm(params.dim, eps=params.norm_eps)\n",
    "        self.output = nn.Linear(params.dim, 1, bias=False)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(\n",
    "            self.params.dim // self.params.n_heads, self.params.max_seq_len * 2\n",
    "        )\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, start_pos: int, targets=None):\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        h = self.tok_embeddings(tokens)\n",
    "        self.freqs_cis = self.freqs_cis.to(h.device)\n",
    "        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]\n",
    "\n",
    "        mask = None\n",
    "        if seqlen > 1:\n",
    "            mask = torch.full((1, 1, seqlen, seqlen), float(\"-inf\"), device=tokens.device)\n",
    "            mask = torch.triu(mask, diagonal=start_pos + 1).type_as(h)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, start_pos, freqs_cis, mask)\n",
    "        h = self.norm(h)\n",
    "        output = self.output(h[:, -1, :])  # only compute last logits\n",
    "        preds = torch.sigmoid(output) # Apply sigmoid to obtain probabilities\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.binary_cross_entropy(preds.view(-1), targets.float()) # Use BCE loss, ensure targets are float\n",
    "\n",
    "        return preds, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.602432 M parameters\n"
     ]
    }
   ],
   "source": [
    "args = ModelArgs(vocab_size=tokenizer.n_words)\n",
    "args\n",
    "\n",
    "model = Transformer(args)\n",
    "model = model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# Hyperparameters\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:17<00:00,  5.68it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "eval_num = 10\n",
    "epochs = 100\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "max_iters = epochs\n",
    "for iter in trange(max_iters):\n",
    "\n",
    "#     # every once in a while evaluate the loss on train and val sets\n",
    "#     if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "#         losses = estimate_loss()\n",
    "#         print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, 0, yb)\n",
    "    loss_list.append(loss.item())\n",
    "#     optimizer.zero_grad()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    \n",
    "#     if iter % eval_num == 0:\n",
    "#         total = sum(loss_list)\n",
    "#         loss_list = []\n",
    "#         avg = total / eval_num\n",
    "#         print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f60cda9d460>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(list1, list2):\n",
    "    correct = 0\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] == list2[i]:\n",
    "            correct += 1\n",
    "    return correct / len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.636875\n",
      "perc   pred   true  \n",
      "  0.29      0      0\n",
      "  0.29      0      0\n",
      "  0.31      0      0\n",
      "  0.34      0      1\n",
      "  0.44      0      1\n",
      "  0.47      0      0\n",
      "  0.45      0      0\n",
      "  0.44      0      1\n",
      "  0.51      1      0\n",
      "  0.48      0      1\n",
      "  0.36      0      0\n",
      "  0.50      0      1\n",
      "  0.48      0      1\n",
      "  0.92      1      1\n",
      "  0.36      0      1\n",
      "  0.28      0      0\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "lists1 = []\n",
    "lists2 = []\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    X, y = get_batch('test')\n",
    "\n",
    "    output, _ = model(X, 0)\n",
    "\n",
    "\n",
    "#     mean = output.mean()\n",
    "\n",
    "    outing = []\n",
    "\n",
    "    for outs in output:\n",
    "        if outs.item() >= 0.5:\n",
    "            outing.append(1)\n",
    "        else:\n",
    "            outing.append(0)\n",
    "\n",
    "    list1 = outing\n",
    "    lists1.append(list1)\n",
    "\n",
    "    list2 = y.tolist()\n",
    "    lists2.append(list2)\n",
    "    \n",
    "    accuracy_list.append(accuracy(list1, list2))\n",
    "        \n",
    "print(f'Accuracy = {sum(accuracy_list) / len(accuracy_list)}')\n",
    "\n",
    "print('{:6s} {:6s} {:6s}'.format('perc', 'pred', 'true'))\n",
    "for l1, l2, l3 in zip([round(num, 2) for num in output.view(-1).tolist()], list1, list2):\n",
    "    print(f'{l1:6.2f} {l2:6} {l3:6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=300)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
