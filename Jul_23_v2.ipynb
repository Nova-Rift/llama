{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import html\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import sentencepiece as spm\n",
    "from llama import Tokenizer\n",
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16  # how many independent sequences will we process in parallel?\n",
    "block_size = 1000  # what is the maximum context length for predictions?\n",
    "max_iters = 100\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 128\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.01\n",
    "# ------------\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "df = pd.read_csv('../data/opt_intelligence_test_data.csv')\n",
    "\n",
    "# remove NaN\n",
    "df = df.dropna(subset=['PL_DATE_OF_BIRTH'])\n",
    "\n",
    "# remove HTML characters\n",
    "df['O_BODY1'] = df['O_BODY1'].apply(html.unescape)\n",
    "df['O_NAME'] = df['O_NAME'].apply(html.unescape)\n",
    "df['O_HEADLINE1'] = df['O_HEADLINE1'].apply(html.unescape)\n",
    "df['O_DISPLAY_NAME'] = df['O_DISPLAY_NAME'].apply(html.unescape)\n",
    "\n",
    "# shuffle dem bitches\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = math.floor(df.shape[0]*.9)\n",
    "train_data = df.iloc[:n, :]\n",
    "val_data = df.iloc[n:, :]\n",
    "\n",
    "tokenizer = Tokenizer(model_path='tokenizer.model')\n",
    "\n",
    "def get_batch(split):\n",
    "    strings = []\n",
    "    optins = []\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    \n",
    "    # Separate positive and negative classes\n",
    "    df_positive = data[data.OPTED_IN == 1]\n",
    "    df_negative = data[data.OPTED_IN == 0]\n",
    "    \n",
    "    # Select half the batch size from each class\n",
    "    half_batch = batch_size // 2\n",
    "    idx_positive = torch.randperm(len(df_positive))[:half_batch]\n",
    "    idx_negative = torch.randperm(len(df_negative))[:half_batch] + len(df_positive)\n",
    "    \n",
    "    # Combine indices and shuffle\n",
    "    indices = torch.cat([idx_positive, idx_negative])\n",
    "    indices = indices[torch.randperm(len(indices))]\n",
    "\n",
    "    # Join positive and negative classes\n",
    "    df_combined = pd.concat([df_positive, df_negative])\n",
    "\n",
    "    for i in indices:\n",
    "        row = df_combined.iloc[i.item()]\n",
    "        string_dict = row[:-1].to_dict()  # turns row into dictionary cols=keys\n",
    "        string = ', '.join(f'{k}: {v}' for k, v in string_dict.items())  # creates string from row dict\n",
    "        encoded_string = torch.tensor(tokenizer.encode(string, bos=True, eos=False))  # encode string to tensor\n",
    "        full_tensor = torch.full((block_size,), 0)  # create tensor as long as longest and fill with new token\n",
    "        # using same token as <unk> 0\n",
    "        full_tensor[:len(encoded_string)] = encoded_string  # replace beginning of full tensor with original string tensor\n",
    "        encoded_string = full_tensor  # encoded string with padding\n",
    "        strings.append(encoded_string)  # add tensor to list of tensors\n",
    "        optin_dict = row[-1:].to_dict()  # convert optin column to dict\n",
    "        optins.append(optin_dict['opted_in'.upper()])  # add optin value to list\n",
    "        \n",
    "    optins = torch.tensor(optins)  # turn optins list to tensor\n",
    "    \n",
    "    x, y = torch.stack(strings), optins\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "# from typing import Optional, Tuple\n",
    "# from dataclasses import dataclass\n",
    "# import math\n",
    "\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 256\n",
    "    n_layers: int = 4\n",
    "    n_heads: int = 4\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    norm_eps: float = 1e-06\n",
    "    max_batch_size: int = 16\n",
    "    max_seq_len: int = 1024\n",
    "\n",
    "\n",
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight\n",
    "\n",
    "\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis\n",
    "\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "\n",
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cis: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "\n",
    "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        bsz, seqlen, _ = x.shape\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "\n",
    "        xq = xq.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n",
    "\n",
    "        keys = xk\n",
    "        values = xv\n",
    "\n",
    "        xq = xq.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        if mask is not None:\n",
    "            scores = scores + mask\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        output = torch.matmul(scores, values)\n",
    "        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        return self.wo(output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        hidden_dim: int,\n",
    "        multiple_of: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(2 * hidden_dim / 3)\n",
    "        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
    "\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w2(F.silu(self.w1(x)) * self.w3(x))\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.attention = Attention(args)\n",
    "        self.feed_forward = FeedForward(\n",
    "            dim=args.dim, hidden_dim=4 * args.dim, multiple_of=args.multiple_of\n",
    "        )\n",
    "        self.layer_id = layer_id\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        h = x + self.attention.forward(self.attention_norm(x), start_pos, freqs_cis, mask)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, params: ModelArgs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = params\n",
    "        self.vocab_size = params.vocab_size\n",
    "        self.n_layers = params.n_layers\n",
    "\n",
    "        self.tok_embeddings = nn.Embedding(params.vocab_size, params.dim)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for layer_id in range(params.n_layers):\n",
    "            self.layers.append(TransformerBlock(layer_id, params))\n",
    "\n",
    "        self.norm = RMSNorm(params.dim, eps=params.norm_eps)\n",
    "        self.output = nn.Linear(params.dim, 1, bias=False)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(\n",
    "            self.params.dim // self.params.n_heads, self.params.max_seq_len * 2\n",
    "        )\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, start_pos: int, targets=None):\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        h = self.tok_embeddings(tokens)\n",
    "        self.freqs_cis = self.freqs_cis.to(h.device)\n",
    "        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]\n",
    "\n",
    "        mask = None\n",
    "        if seqlen > 1:\n",
    "            mask = torch.full((1, 1, seqlen, seqlen), float(\"-inf\"), device=tokens.device)\n",
    "            mask = torch.triu(mask, diagonal=start_pos + 1).type_as(h)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, start_pos, freqs_cis, mask)\n",
    "        h = self.norm(h)\n",
    "        output = self.output(h[:, -1, :])  # only compute last logits\n",
    "        preds = torch.sigmoid(output) # Apply sigmoid to obtain probabilities\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.binary_cross_entropy(preds.view(-1), targets.float()) # Use BCE loss, ensure targets are float\n",
    "\n",
    "        return preds, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.602432 M parameters\n"
     ]
    }
   ],
   "source": [
    "args = ModelArgs(vocab_size=tokenizer.n_words)\n",
    "args\n",
    "\n",
    "model = Transformer(args)\n",
    "model = model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# Hyperparameters\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:17<00:00,  5.56it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "eval_num = 10\n",
    "epochs = 100\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "max_iters = epochs\n",
    "for iter in trange(max_iters):\n",
    "\n",
    "#     # every once in a while evaluate the loss on train and val sets\n",
    "#     if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "#         losses = estimate_loss()\n",
    "#         print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, 0, yb)\n",
    "    loss_list.append(loss.item())\n",
    "#     optimizer.zero_grad()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    \n",
    "#     if iter % eval_num == 0:\n",
    "#         total = sum(loss_list)\n",
    "#         loss_list = []\n",
    "#         avg = total / eval_num\n",
    "#         print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd958150c40>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(list1, list2):\n",
    "    correct = 0\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] == list2[i]:\n",
    "            correct += 1\n",
    "    return correct / len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 14.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.633125\n",
      "perc   pred   true  \n",
      "  0.97      1      1\n",
      "  0.50      1      0\n",
      "  0.26      0      0\n",
      "  0.23      0      1\n",
      "  0.49      0      0\n",
      "  0.97      1      1\n",
      "  0.97      1      1\n",
      "  0.51      1      1\n",
      "  0.25      0      1\n",
      "  0.46      0      0\n",
      "  0.63      1      0\n",
      "  0.98      1      1\n",
      "  0.41      0      0\n",
      "  0.97      1      1\n",
      "  0.25      0      0\n",
      "  0.50      1      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "lists1 = []\n",
    "lists2 = []\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "for epoch in trange(EPOCHS):\n",
    "\n",
    "    X, y = get_batch('test')\n",
    "\n",
    "    output, _ = model(X, 0)\n",
    "\n",
    "\n",
    "#     mean = output.mean()\n",
    "\n",
    "    outing = []\n",
    "\n",
    "    for outs in output:\n",
    "        if outs.item() >= 0.5:\n",
    "            outing.append(1)\n",
    "        else:\n",
    "            outing.append(0)\n",
    "\n",
    "    list1 = outing\n",
    "    lists1.append(list1)\n",
    "\n",
    "    list2 = y.tolist()\n",
    "    lists2.append(list2)\n",
    "    \n",
    "    accuracy_list.append(accuracy(list1, list2))\n",
    "        \n",
    "print(f'Accuracy = {sum(accuracy_list) / len(accuracy_list)}')\n",
    "\n",
    "print('{:6s} {:6s} {:6s}'.format('perc', 'pred', 'true'))\n",
    "for l1, l2, l3 in zip([round(num, 2) for num in output.view(-1).tolist()], list1, list2):\n",
    "    print(f'{l1:6.2f} {l2:6} {l3:6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=300)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
