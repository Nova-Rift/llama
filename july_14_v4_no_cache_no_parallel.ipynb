{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import html\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import sentencepiece as spm\n",
    "from llama import Tokenizer\n",
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "import random\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 1000  # what is the maximum context length for predictions?\n",
    "max_iters = 100\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 128\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.01\n",
    "# ------------\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "df = pd.read_csv('../data/opt_intelligence_test_data.csv')\n",
    "\n",
    "# remove NaN\n",
    "df = df.dropna(subset=['PL_DATE_OF_BIRTH'])\n",
    "\n",
    "# remove HTML characters\n",
    "df['O_BODY1'] = df['O_BODY1'].apply(html.unescape)\n",
    "df['O_NAME'] = df['O_NAME'].apply(html.unescape)\n",
    "df['O_HEADLINE1'] = df['O_HEADLINE1'].apply(html.unescape)\n",
    "df['O_DISPLAY_NAME'] = df['O_DISPLAY_NAME'].apply(html.unescape)\n",
    "\n",
    "# shuffle dem bitches\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = math.floor(df.shape[0]*.9)\n",
    "train_data = df.iloc[:n, :]\n",
    "val_data = df.iloc[n:, :]\n",
    "\n",
    "tokenizer = Tokenizer(model_path='tokenizer.model')\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    strings = []\n",
    "    optins = []\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    \n",
    "    # Separate positive and negative classes\n",
    "    df_positive = data[data.OPTED_IN == 1]\n",
    "    df_negative = data[data.OPTED_IN == 0]\n",
    "    \n",
    "    # Select half the batch size from each class\n",
    "    half_batch = batch_size // 2\n",
    "    idx_positive = torch.randperm(len(df_positive))[:half_batch]\n",
    "    idx_negative = torch.randperm(len(df_negative))[:half_batch]\n",
    "\n",
    "    for idx, df_class in zip([idx_positive, idx_negative], [df_positive, df_negative]):\n",
    "        for i in idx:\n",
    "            string_dict = df_class.iloc[i.item()][:-1].to_dict() # turns row into dictionary cols=keys\n",
    "            string = ', '.join(f'{k}: {v}' for k, v in string_dict.items()) # creates string from row dict\n",
    "            encoded_string = torch.tensor(tokenizer.encode(string, bos=True, eos=False)) # encode string to tensor\n",
    "            full_tensor = torch.full((block_size,), 0) # create tensor as long as longest and fill with new token\n",
    "            # using same token as <unk> 0\n",
    "            full_tensor[:len(encoded_string)] = encoded_string # replace beginning of full tensor with original string tensor\n",
    "            encoded_string = full_tensor # encoded string with padding\n",
    "            strings.append(encoded_string) # add tensor to list of tensors\n",
    "            optin_dict = df_class.iloc[i.item()][-1:].to_dict() # convert optin column to dict\n",
    "            optins.append(optin_dict['opted_in'.upper()]) # add optin value to list\n",
    "\n",
    "    # Turn lists into tensors\n",
    "    strings_tensor = torch.stack(strings)\n",
    "    optins_tensor = torch.tensor(optins)\n",
    "\n",
    "    # Concatenate positive and negative examples, then randomize the whole batch\n",
    "    combined = list(zip(strings_tensor, optins_tensor))\n",
    "    random.shuffle(combined)\n",
    "    x, y = zip(*combined)\n",
    "\n",
    "    x, y = torch.stack(x), torch.tensor(y)\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "get_batch('train')\n",
    "\n",
    "# from typing import Optional, Tuple\n",
    "# from dataclasses import dataclass\n",
    "# import math\n",
    "\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 256\n",
    "    n_layers: int = 4\n",
    "    n_heads: int = 4\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    norm_eps: float = 1e-06\n",
    "    max_batch_size: int = 16\n",
    "    max_seq_len: int = 1024\n",
    "\n",
    "\n",
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight\n",
    "\n",
    "\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis\n",
    "\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "\n",
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cis: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "\n",
    "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        bsz, seqlen, _ = x.shape\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "\n",
    "        xq = xq.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n",
    "\n",
    "        keys = xk\n",
    "        values = xv\n",
    "\n",
    "        xq = xq.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        if mask is not None:\n",
    "            scores = scores + mask\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        output = torch.matmul(scores, values)\n",
    "        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        return self.wo(output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        hidden_dim: int,\n",
    "        multiple_of: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(2 * hidden_dim / 3)\n",
    "        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
    "\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w2(F.silu(self.w1(x)) * self.w3(x))\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.attention = Attention(args)\n",
    "        self.feed_forward = FeedForward(\n",
    "            dim=args.dim, hidden_dim=4 * args.dim, multiple_of=args.multiple_of\n",
    "        )\n",
    "        self.layer_id = layer_id\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        h = x + self.attention.forward(self.attention_norm(x), start_pos, freqs_cis, mask)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, params: ModelArgs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = params\n",
    "        self.vocab_size = params.vocab_size\n",
    "        self.n_layers = params.n_layers\n",
    "\n",
    "        self.tok_embeddings = nn.Embedding(params.vocab_size, params.dim)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for layer_id in range(params.n_layers):\n",
    "            self.layers.append(TransformerBlock(layer_id, params))\n",
    "\n",
    "        self.norm = RMSNorm(params.dim, eps=params.norm_eps)\n",
    "        self.output = nn.Linear(params.dim, 1, bias=False)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(\n",
    "            self.params.dim // self.params.n_heads, self.params.max_seq_len * 2\n",
    "        )\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, start_pos: int, targets=None):\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        h = self.tok_embeddings(tokens)\n",
    "        self.freqs_cis = self.freqs_cis.to(h.device)\n",
    "        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]\n",
    "\n",
    "        mask = None\n",
    "        if seqlen > 1:\n",
    "            mask = torch.full((1, 1, seqlen, seqlen), float(\"-inf\"), device=tokens.device)\n",
    "            mask = torch.triu(mask, diagonal=start_pos + 1).type_as(h)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, start_pos, freqs_cis, mask)\n",
    "        h = self.norm(h)\n",
    "        output = self.output(h[:, -1, :])  # only compute last logits\n",
    "        preds = torch.sigmoid(output) # Apply sigmoid to obtain probabilities\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.binary_cross_entropy(preds.view(-1), targets.float()) # Use BCE loss, ensure targets are float\n",
    "\n",
    "        return preds, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.602432 M parameters\n"
     ]
    }
   ],
   "source": [
    "args = ModelArgs(vocab_size=tokenizer.n_words)\n",
    "args\n",
    "\n",
    "model = Transformer(args)\n",
    "model = model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# Hyperparameters\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:17<00:00,  5.72it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "eval_num = 10\n",
    "epochs = 100\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "max_iters = epochs\n",
    "for iter in trange(max_iters):\n",
    "\n",
    "#     # every once in a while evaluate the loss on train and val sets\n",
    "#     if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "#         losses = estimate_loss()\n",
    "#         print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, 0, yb)\n",
    "    loss_list.append(loss.item())\n",
    "#     optimizer.zero_grad()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    \n",
    "#     if iter % eval_num == 0:\n",
    "#         total = sum(loss_list)\n",
    "#         loss_list = []\n",
    "#         avg = total / eval_num\n",
    "#         print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc6e0195d30>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(list1, list2):\n",
    "    correct = 0\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] == list2[i]:\n",
    "            correct += 1\n",
    "    return correct / len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.690625\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "lists1 = []\n",
    "lists2 = []\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    X, y = get_batch('test')\n",
    "    \n",
    "    \n",
    "\n",
    "    output, _ = model(X, 0)\n",
    "    output\n",
    "\n",
    "#     print(output)\n",
    "    \n",
    "#     # Assuming output is a PyTorch tensor\n",
    "#     output_sorted = output.tolist()\n",
    "\n",
    "#     # Flatten the list if it's a list of lists\n",
    "#     output_sorted = [item for sublist in output_sorted for item in sublist]\n",
    "\n",
    "#     # Round each number in the list\n",
    "#     output_sorted = [round(num, 2) for num in output_sorted]\n",
    "\n",
    "#     # Sort the list\n",
    "#     output_sorted.sort(reverse=True)\n",
    "\n",
    "#     # Print the list\n",
    "#     print('output = {}'.format(output_sorted))\n",
    "    \n",
    "    mean = output.mean()\n",
    "\n",
    "    outing = []\n",
    "\n",
    "    for outs in output:\n",
    "        if outs.item() >= mean:\n",
    "            outing.append(1)\n",
    "        else:\n",
    "            outing.append(0)\n",
    "\n",
    "    list1 = outing\n",
    "#     print('list1 = {}'.format(list1))\n",
    "    lists1.append(list1)\n",
    "\n",
    "    list2 = y.tolist()\n",
    "#     print('list2 = {}'.format(list2))\n",
    "    lists2.append(list2)\n",
    "    \n",
    "#     print()\n",
    "#     print('------------------------------------------')\n",
    "#     print()\n",
    "    accuracy_list.append(accuracy(list1, list2))\n",
    "    \n",
    "print(sum(accuracy_list) / len(accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=300)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
