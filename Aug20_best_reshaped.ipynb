{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import html\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import sentencepiece as spm\n",
    "from llama import Tokenizer\n",
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16  # how many independent sequences will we process in parallel?\n",
    "block_size = 1000  # what is the maximum context length for predictions?\n",
    "max_iters = 100\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 128\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.01\n",
    "# ------------\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "df = pd.read_csv('./opt_intelligence_test_data.csv')\n",
    "\n",
    "# remove NaN\n",
    "df = df.dropna(subset=['PL_DATE_OF_BIRTH'])\n",
    "\n",
    "# remove HTML characters\n",
    "df['O_BODY1'] = df['O_BODY1'].apply(html.unescape)\n",
    "df['O_NAME'] = df['O_NAME'].apply(html.unescape)\n",
    "df['O_HEADLINE1'] = df['O_HEADLINE1'].apply(html.unescape)\n",
    "df['O_DISPLAY_NAME'] = df['O_DISPLAY_NAME'].apply(html.unescape)\n",
    "\n",
    "# shuffle dem bitches\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = math.floor(df.shape[0]*.9)\n",
    "train_data = df.iloc[:n, :]\n",
    "val_data = df.iloc[n:, :]\n",
    "\n",
    "tokenizer = Tokenizer(model_path='tokenizer.model')\n",
    "\n",
    "def get_batch(split):\n",
    "    strings = []\n",
    "    optins = []\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    \n",
    "    # Separate positive and negative classes\n",
    "    df_positive = data[data.OPTED_IN == 1]\n",
    "    df_negative = data[data.OPTED_IN == 0]\n",
    "    \n",
    "    # Select half the batch size from each class\n",
    "    half_batch = batch_size // 2\n",
    "    idx_positive = torch.randperm(len(df_positive))[:half_batch]\n",
    "    idx_negative = torch.randperm(len(df_negative))[:half_batch] + len(df_positive)\n",
    "    \n",
    "    # Combine indices and shuffle\n",
    "    indices = torch.cat([idx_positive, idx_negative])\n",
    "    indices = indices[torch.randperm(len(indices))]\n",
    "\n",
    "    # Join positive and negative classes\n",
    "    df_combined = pd.concat([df_positive, df_negative])\n",
    "\n",
    "    for i in indices:\n",
    "        row = df_combined.iloc[i.item()]\n",
    "        string_dict = row[:-1].to_dict()  # turns row into dictionary cols=keys\n",
    "        string = ', '.join(f'{k}: {v}' for k, v in string_dict.items())  # creates string from row dict\n",
    "        encoded_string = torch.tensor(tokenizer.encode(string, bos=True, eos=False))  # encode string to tensor\n",
    "        full_tensor = torch.full((block_size,), 0)  # create tensor as long as longest and fill with new token\n",
    "        # using same token as <unk> 0\n",
    "        full_tensor[:len(encoded_string)] = encoded_string  # replace beginning of full tensor with original string tensor\n",
    "        encoded_string = full_tensor  # encoded string with padding\n",
    "        strings.append(encoded_string)  # add tensor to list of tensors\n",
    "        optin_dict = row[-1:].to_dict()  # convert optin column to dict\n",
    "        optins.append(optin_dict['opted_in'.upper()])  # add optin value to list\n",
    "        \n",
    "    optins = torch.tensor(optins)  # turn optins list to tensor\n",
    "    \n",
    "    x, y = torch.stack(strings), optins\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "# from typing import Optional, Tuple\n",
    "# from dataclasses import dataclass\n",
    "# import math\n",
    "\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 4096\n",
    "    n_layers: int = 32\n",
    "    n_heads: int = 32\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    norm_eps: float = 1e-06\n",
    "    max_batch_size: int = 1\n",
    "    max_seq_len: int = 512\n",
    "\n",
    "# @dataclass\n",
    "# class ModelArgs:\n",
    "#     dim: int = 64\n",
    "#     n_layers: int = 8\n",
    "#     n_heads: int = 8\n",
    "#     vocab_size: int = -1  # defined later by tokenizer\n",
    "#     multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "#     norm_eps: float = 1e-06\n",
    "#     max_batch_size: int = 1\n",
    "#     max_seq_len: int = 512   \n",
    "\n",
    "\n",
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight\n",
    "\n",
    "\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis\n",
    "\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "\n",
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cis: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "\n",
    "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        bsz, seqlen, _ = x.shape\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "\n",
    "        xq = xq.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n",
    "\n",
    "        keys = xk\n",
    "        values = xv\n",
    "\n",
    "        xq = xq.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        if mask is not None:\n",
    "            scores = scores + mask\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        output = torch.matmul(scores, values)\n",
    "        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        return self.wo(output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        hidden_dim: int,\n",
    "        multiple_of: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(2 * hidden_dim / 3)\n",
    "        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
    "\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w2(F.silu(self.w1(x)) * self.w3(x))\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.attention = Attention(args)\n",
    "        self.feed_forward = FeedForward(\n",
    "            dim=args.dim, hidden_dim=4 * args.dim, multiple_of=args.multiple_of\n",
    "        )\n",
    "        self.layer_id = layer_id\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        h = x + self.attention.forward(self.attention_norm(x), start_pos, freqs_cis, mask)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, params: ModelArgs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = params\n",
    "        self.vocab_size = params.vocab_size\n",
    "        self.n_layers = params.n_layers\n",
    "\n",
    "        self.tok_embeddings = nn.Embedding(params.vocab_size, params.dim)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for layer_id in range(params.n_layers):\n",
    "            self.layers.append(TransformerBlock(layer_id, params))\n",
    "\n",
    "        self.norm = RMSNorm(params.dim, eps=params.norm_eps)\n",
    "        self.output = nn.Linear(params.dim, 1, bias=False)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(\n",
    "            self.params.dim // self.params.n_heads, self.params.max_seq_len * 2\n",
    "        )\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, start_pos: int, targets=None):\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        h = self.tok_embeddings(tokens)\n",
    "        self.freqs_cis = self.freqs_cis.to(h.device)\n",
    "        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]\n",
    "\n",
    "        mask = None\n",
    "        if seqlen > 1:\n",
    "            mask = torch.full((1, 1, seqlen, seqlen), float(\"-inf\"), device=tokens.device)\n",
    "            mask = torch.triu(mask, diagonal=start_pos + 1).type_as(h)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, start_pos, freqs_cis, mask)\n",
    "        h = self.norm(h)\n",
    "        output = self.output(h[:, -1, :])  # only compute last logits\n",
    "        preds = torch.sigmoid(output) # Apply sigmoid to obtain probabilities\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.binary_cross_entropy(preds.view(-1), targets.float()) # Use BCE loss, ensure targets are float\n",
    "\n",
    "        return preds, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.57344 M parameters\n"
     ]
    }
   ],
   "source": [
    "args = ModelArgs(vocab_size=tokenizer.n_words)\n",
    "args\n",
    "\n",
    "model = Transformer(args)\n",
    "model = model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# Hyperparameters\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6607.347712 M parameters\n"
     ]
    }
   ],
   "source": [
    "from llama import Tokenizer, LLaMA\n",
    "\n",
    "tokenizer = Tokenizer(model_path='./tokenizer.model')\n",
    "\n",
    "model_args = ModelArgs()\n",
    "model_args.vocab_size = tokenizer.n_words\n",
    "\n",
    "torch.set_default_tensor_type(torch.cuda.HalfTensor)\n",
    "model = Transformer(model_args)\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "checkpoint = torch.load('../7B/consolidated.00.pth', map_location=\"cpu\")\n",
    "\n",
    "pretrained_checkpoint = {k: v for k, v in checkpoint.items() if 'output' not in k}\n",
    "\n",
    "model.load_state_dict(pretrained_checkpoint, strict=False)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 978.00 MiB (GPU 0; 47.54 GiB total capacity; 44.43 GiB already allocated; 803.12 MiB free; 45.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     xb, yb \u001b[38;5;241m=\u001b[39m get_batch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# evaluate the loss\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     logits, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     loss_list\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#     optimizer.zero_grad()\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[2], line 305\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, tokens, start_pos, targets)\u001b[0m\n\u001b[1;32m    302\u001b[0m     mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtriu(mask, diagonal\u001b[38;5;241m=\u001b[39mstart_pos \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtype_as(h)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 305\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs_cis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(h)\n\u001b[1;32m    307\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(h[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])  \u001b[38;5;66;03m# only compute last logits\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[2], line 267\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x, start_pos, freqs_cis, mask)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, start_pos: \u001b[38;5;28mint\u001b[39m, freqs_cis: torch\u001b[38;5;241m.\u001b[39mTensor, mask: Optional[torch\u001b[38;5;241m.\u001b[39mTensor]):\n\u001b[0;32m--> 267\u001b[0m     h \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs_cis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m     out \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn_norm(h))\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "Cell \u001b[0;32mIn[2], line 221\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, x, start_pos, freqs_cis, mask)\u001b[0m\n\u001b[1;32m    219\u001b[0m keys \u001b[38;5;241m=\u001b[39m keys\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    220\u001b[0m values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     scores \u001b[38;5;241m=\u001b[39m scores \u001b[38;5;241m+\u001b[39m mask\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 978.00 MiB (GPU 0; 47.54 GiB total capacity; 44.43 GiB already allocated; 803.12 MiB free; 45.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "eval_num = 10\n",
    "epochs = 100\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "max_iters = epochs\n",
    "for iter in trange(max_iters):\n",
    "\n",
    "#     # every once in a while evaluate the loss on train and val sets\n",
    "#     if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "#         losses = estimate_loss()\n",
    "#         print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, 0, yb)\n",
    "    loss_list.append(loss.item())\n",
    "#     optimizer.zero_grad()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    \n",
    "#     if iter % eval_num == 0:\n",
    "#         total = sum(loss_list)\n",
    "#         loss_list = []\n",
    "#         avg = total / eval_num\n",
    "#         print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f62c7acdd80>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(list1, list2):\n",
    "    correct = 0\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] == list2[i]:\n",
    "            correct += 1\n",
    "    return correct / len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:07<00:00, 13.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.651875\n",
      "perc   pred   true  \n",
      "  0.32      0      0\n",
      "  0.90      1      0\n",
      "  0.57      1      1\n",
      "  0.32      0      0\n",
      "  0.58      1      1\n",
      "  0.38      0      0\n",
      "  0.40      0      0\n",
      "  0.33      0      0\n",
      "  0.33      0      1\n",
      "  0.34      0      0\n",
      "  0.84      1      1\n",
      "  0.35      0      1\n",
      "  0.48      0      1\n",
      "  0.33      0      1\n",
      "  0.51      1      1\n",
      "  0.46      0      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "lists1 = []\n",
    "lists2 = []\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "for epoch in trange(EPOCHS):\n",
    "\n",
    "    X, y = get_batch('test')\n",
    "\n",
    "    output, _ = model(X, 0)\n",
    "\n",
    "\n",
    "#     mean = output.mean()\n",
    "\n",
    "    outing = []\n",
    "\n",
    "    for outs in output:\n",
    "        if outs.item() >= 0.5:\n",
    "            outing.append(1)\n",
    "        else:\n",
    "            outing.append(0)\n",
    "\n",
    "    list1 = outing\n",
    "    lists1.append(list1)\n",
    "\n",
    "    list2 = y.tolist()\n",
    "    lists2.append(list2)\n",
    "    \n",
    "    accuracy_list.append(accuracy(list1, list2))\n",
    "        \n",
    "print(f'Accuracy = {sum(accuracy_list) / len(accuracy_list)}')\n",
    "\n",
    "print('{:6s} {:6s} {:6s}'.format('perc', 'pred', 'true'))\n",
    "for l1, l2, l3 in zip([round(num, 2) for num in output.view(-1).tolist()], list1, list2):\n",
    "    print(f'{l1:6.2f} {l2:6} {l3:6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=300)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
