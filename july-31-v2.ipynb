{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import html\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import sentencepiece as spm\n",
    "from llama import Tokenizer\n",
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16  # how many independent sequences will we process in parallel?\n",
    "block_size = 1000  # what is the maximum context length for predictions?\n",
    "max_iters = 100\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 128\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.01\n",
    "# ------------\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "df = pd.read_csv('../data/opt_intelligence_test_data.csv')\n",
    "\n",
    "# remove NaN\n",
    "df = df.dropna(subset=['PL_DATE_OF_BIRTH'])\n",
    "\n",
    "# remove HTML characters\n",
    "df['O_BODY1'] = df['O_BODY1'].apply(html.unescape)\n",
    "df['O_NAME'] = df['O_NAME'].apply(html.unescape)\n",
    "df['O_HEADLINE1'] = df['O_HEADLINE1'].apply(html.unescape)\n",
    "df['O_DISPLAY_NAME'] = df['O_DISPLAY_NAME'].apply(html.unescape)\n",
    "\n",
    "# shuffle dem bitches\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = math.floor(df.shape[0]*.9)\n",
    "train_data = df.iloc[:n, :]\n",
    "val_data = df.iloc[n:, :]\n",
    "\n",
    "tokenizer = Tokenizer(model_path='tokenizer.model')\n",
    "\n",
    "def get_batch(split):\n",
    "    strings = []\n",
    "    optins = []\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    \n",
    "    # Separate positive and negative classes\n",
    "    df_positive = data[data.OPTED_IN == 1]\n",
    "    df_negative = data[data.OPTED_IN == 0]\n",
    "    \n",
    "    # Select half the batch size from each class\n",
    "    half_batch = batch_size // 2\n",
    "    idx_positive = torch.randperm(len(df_positive))[:half_batch]\n",
    "    idx_negative = torch.randperm(len(df_negative))[:half_batch] + len(df_positive)\n",
    "    \n",
    "    # Combine indices and shuffle\n",
    "    indices = torch.cat([idx_positive, idx_negative])\n",
    "    indices = indices[torch.randperm(len(indices))]\n",
    "\n",
    "    # Join positive and negative classes\n",
    "    df_combined = pd.concat([df_positive, df_negative])\n",
    "\n",
    "    for i in indices:\n",
    "        row = df_combined.iloc[i.item()]\n",
    "        string_dict = row[:-1].to_dict()  # turns row into dictionary cols=keys\n",
    "        string = ', '.join(f'{k}: {v}' for k, v in string_dict.items())  # creates string from row dict\n",
    "        encoded_string = torch.tensor(tokenizer.encode(string, bos=True, eos=False))  # encode string to tensor\n",
    "        full_tensor = torch.full((block_size,), 0)  # create tensor as long as longest and fill with new token\n",
    "        # using same token as <unk> 0\n",
    "        full_tensor[:len(encoded_string)] = encoded_string  # replace beginning of full tensor with original string tensor\n",
    "        encoded_string = full_tensor  # encoded string with padding\n",
    "        strings.append(encoded_string)  # add tensor to list of tensors\n",
    "        optin_dict = row[-1:].to_dict()  # convert optin column to dict\n",
    "        optins.append(optin_dict['opted_in'.upper()])  # add optin value to list\n",
    "        \n",
    "    optins = torch.tensor(optins)  # turn optins list to tensor\n",
    "    \n",
    "    x, y = torch.stack(strings), optins\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "# from typing import Optional, Tuple\n",
    "# from dataclasses import dataclass\n",
    "# import math\n",
    "\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 256\n",
    "    n_layers: int = 4\n",
    "    n_heads: int = 4\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    norm_eps: float = 1e-06\n",
    "    max_batch_size: int = 16\n",
    "    max_seq_len: int = 1024\n",
    "\n",
    "\n",
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight\n",
    "\n",
    "\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis\n",
    "\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "\n",
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cis: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "\n",
    "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        bsz, seqlen, _ = x.shape\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "\n",
    "        xq = xq.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n",
    "\n",
    "        keys = xk\n",
    "        values = xv\n",
    "\n",
    "        xq = xq.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        if mask is not None:\n",
    "            scores = scores + mask\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        output = torch.matmul(scores, values)\n",
    "        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        return self.wo(output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        hidden_dim: int,\n",
    "        multiple_of: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(2 * hidden_dim / 3)\n",
    "        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
    "\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w2(F.silu(self.w1(x)) * self.w3(x))\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.attention = Attention(args)\n",
    "        self.feed_forward = FeedForward(\n",
    "            dim=args.dim, hidden_dim=4 * args.dim, multiple_of=args.multiple_of\n",
    "        )\n",
    "        self.layer_id = layer_id\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        h = x + self.attention.forward(self.attention_norm(x), start_pos, freqs_cis, mask)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, params: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "        self.vocab_size = params.vocab_size\n",
    "        self.n_layers = params.n_layers\n",
    "\n",
    "        self.tok_embeddings = nn.Embedding(params.vocab_size, params.dim)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for layer_id in range(params.n_layers):\n",
    "            self.layers.append(TransformerBlock(layer_id, params))\n",
    "\n",
    "        self.norm = RMSNorm(params.dim, eps=params.norm_eps)\n",
    "\n",
    "        self.output = nn.Linear(params.dim, params.vocab_size, bias=False)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(\n",
    "            self.params.dim // self.params.n_heads, self.params.max_seq_len * 2\n",
    "        )\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def forward(self, tokens: torch.Tensor, start_pos: int):\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        h = self.tok_embeddings(tokens)\n",
    "        self.freqs_cis = self.freqs_cis.to(h.device)\n",
    "        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]\n",
    "\n",
    "        mask = None\n",
    "        if seqlen > 1:\n",
    "            mask = torch.full((1, 1, seqlen, seqlen), float(\"-inf\"), device=tokens.device)\n",
    "            mask = torch.triu(mask, diagonal=start_pos + 1).type_as(h)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, start_pos, freqs_cis, mask)\n",
    "        h = self.norm(h)\n",
    "        output = self.output(h[:, -1, :])  # only compute last logits\n",
    "        return output.float()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.794176 M parameters\n"
     ]
    }
   ],
   "source": [
    "args = ModelArgs(vocab_size=tokenizer.n_words)\n",
    "args\n",
    "\n",
    "model = Transformer(args)\n",
    "model = model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# Hyperparameters\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './saved_models/untrained_llama.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:18<00:00,  5.52it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "eval_num = 10\n",
    "epochs = 100\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "max_iters = epochs\n",
    "for iter in trange(max_iters):\n",
    "\n",
    "#     # every once in a while evaluate the loss on train and val sets\n",
    "#     if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "#         losses = estimate_loss()\n",
    "#         print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, 0, yb)\n",
    "    loss_list.append(loss.item())\n",
    "#     optimizer.zero_grad()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    \n",
    "#     if iter % eval_num == 0:\n",
    "#         total = sum(loss_list)\n",
    "#         loss_list = []\n",
    "#         avg = total / eval_num\n",
    "#         print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6fe25a8040>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(list1, list2):\n",
    "    correct = 0\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] == list2[i]:\n",
    "            correct += 1\n",
    "    return correct / len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.648125\n",
      "perc   pred   true  \n",
      "  0.35      0      0\n",
      "  0.46      0      0\n",
      "  0.47      0      0\n",
      "  0.63      1      1\n",
      "  0.63      1      1\n",
      "  0.27      0      0\n",
      "  0.27      0      0\n",
      "  0.35      0      1\n",
      "  0.44      0      0\n",
      "  0.53      1      1\n",
      "  0.36      0      0\n",
      "  0.38      0      1\n",
      "  0.38      0      1\n",
      "  0.59      1      1\n",
      "  0.85      1      1\n",
      "  0.47      0      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "lists1 = []\n",
    "lists2 = []\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "for epoch in trange(EPOCHS):\n",
    "\n",
    "    X, y = get_batch('test')\n",
    "\n",
    "    output, _ = model(X, 0)\n",
    "\n",
    "\n",
    "#     mean = output.mean()\n",
    "\n",
    "    outing = []\n",
    "\n",
    "    for outs in output:\n",
    "        if outs.item() >= 0.5:\n",
    "            outing.append(1)\n",
    "        else:\n",
    "            outing.append(0)\n",
    "\n",
    "    list1 = outing\n",
    "    lists1.append(list1)\n",
    "\n",
    "    list2 = y.tolist()\n",
    "    lists2.append(list2)\n",
    "    \n",
    "    accuracy_list.append(accuracy(list1, list2))\n",
    "        \n",
    "print(f'Accuracy = {sum(accuracy_list) / len(accuracy_list)}')\n",
    "\n",
    "print('{:6s} {:6s} {:6s}'.format('perc', 'pred', 'true'))\n",
    "for l1, l2, l3 in zip([round(num, 2) for num in output.view(-1).tolist()], list1, list2):\n",
    "    print(f'{l1:6.2f} {l2:6} {l3:6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=300)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
