{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import html\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import sentencepiece as spm\n",
    "from llama import Tokenizer\n",
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16  # how many independent sequences will we process in parallel?\n",
    "block_size = 1000  # what is the maximum context length for predictions?\n",
    "max_iters = 100\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 128\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.01\n",
    "# ------------\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "df = pd.read_csv('../data/opt_intelligence_test_data.csv')\n",
    "\n",
    "# remove NaN\n",
    "df = df.dropna(subset=['PL_DATE_OF_BIRTH'])\n",
    "\n",
    "# remove HTML characters\n",
    "df['O_BODY1'] = df['O_BODY1'].apply(html.unescape)\n",
    "df['O_NAME'] = df['O_NAME'].apply(html.unescape)\n",
    "df['O_HEADLINE1'] = df['O_HEADLINE1'].apply(html.unescape)\n",
    "df['O_DISPLAY_NAME'] = df['O_DISPLAY_NAME'].apply(html.unescape)\n",
    "\n",
    "# shuffle dem bitches\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = math.floor(df.shape[0]*.9)\n",
    "train_data = df.iloc[:n, :]\n",
    "val_data = df.iloc[n:, :]\n",
    "\n",
    "tokenizer = Tokenizer(model_path='tokenizer.model')\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    strings = []\n",
    "    optins = []\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    \n",
    "    # Separate positive and negative classes\n",
    "    df_positive = data[data.OPTED_IN == 1]\n",
    "    df_negative = data[data.OPTED_IN == 0]\n",
    "    \n",
    "    # Select half the batch size from each class\n",
    "    half_batch = batch_size // 2\n",
    "    idx_positive = torch.randperm(len(df_positive))[:half_batch]\n",
    "    idx_negative = torch.randperm(len(df_negative))[:half_batch]\n",
    "    \n",
    "    for idx, df_class in zip([idx_positive, idx_negative], [df_positive, df_negative]):\n",
    "        for i in idx:\n",
    "            string_dict = df_class.iloc[i.item()][:-1].to_dict() # turns row into dictionary cols=keys\n",
    "            string = ', '.join(f'{k}: {v}' for k, v in string_dict.items()) # creates string from row dict\n",
    "            encoded_string = torch.tensor(tokenizer.encode(string, bos=True, eos=False)) # encode string to tensor\n",
    "            full_tensor = torch.full((block_size,), 0) # create tensor as long as longest and fill with new token\n",
    "            # using same token as <unk> 0\n",
    "            full_tensor[:len(encoded_string)] = encoded_string # replace beginning of full tensor with original string tensor\n",
    "            encoded_string = full_tensor # encoded string with padding\n",
    "            strings.append(encoded_string) # add tensor to list of tensors\n",
    "            optin_dict = df_class.iloc[i.item()][-1:].to_dict() # convert optin column to dict\n",
    "            optins.append(optin_dict['opted_in'.upper()]) # add optin value to list\n",
    "        \n",
    "    optins = torch.tensor(optins) # turn optins list to tensor\n",
    "    \n",
    "    x, y = torch.stack(strings), optins\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "# from typing import Optional, Tuple\n",
    "# from dataclasses import dataclass\n",
    "# import math\n",
    "\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 256\n",
    "    n_layers: int = 4\n",
    "    n_heads: int = 4\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    norm_eps: float = 1e-06\n",
    "    max_batch_size: int = 16\n",
    "    max_seq_len: int = 1024\n",
    "\n",
    "\n",
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight\n",
    "\n",
    "\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis\n",
    "\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "\n",
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cis: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "\n",
    "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        bsz, seqlen, _ = x.shape\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "\n",
    "        xq = xq.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n",
    "\n",
    "        keys = xk\n",
    "        values = xv\n",
    "\n",
    "        xq = xq.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        if mask is not None:\n",
    "            scores = scores + mask\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        output = torch.matmul(scores, values)\n",
    "        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        return self.wo(output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        hidden_dim: int,\n",
    "        multiple_of: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(2 * hidden_dim / 3)\n",
    "        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
    "\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w2(F.silu(self.w1(x)) * self.w3(x))\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.attention = Attention(args)\n",
    "        self.feed_forward = FeedForward(\n",
    "            dim=args.dim, hidden_dim=4 * args.dim, multiple_of=args.multiple_of\n",
    "        )\n",
    "        self.layer_id = layer_id\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        h = x + self.attention.forward(self.attention_norm(x), start_pos, freqs_cis, mask)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, params: ModelArgs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = params\n",
    "        self.vocab_size = params.vocab_size\n",
    "        self.n_layers = params.n_layers\n",
    "\n",
    "        self.tok_embeddings = nn.Embedding(params.vocab_size, params.dim)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for layer_id in range(params.n_layers):\n",
    "            self.layers.append(TransformerBlock(layer_id, params))\n",
    "\n",
    "        self.norm = RMSNorm(params.dim, eps=params.norm_eps)\n",
    "        self.output = nn.Linear(params.dim, 1, bias=False)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(\n",
    "            self.params.dim // self.params.n_heads, self.params.max_seq_len * 2\n",
    "        )\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, start_pos: int, targets=None):\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        h = self.tok_embeddings(tokens)\n",
    "        self.freqs_cis = self.freqs_cis.to(h.device)\n",
    "        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]\n",
    "\n",
    "        mask = None\n",
    "        if seqlen > 1:\n",
    "            mask = torch.full((1, 1, seqlen, seqlen), float(\"-inf\"), device=tokens.device)\n",
    "            mask = torch.triu(mask, diagonal=start_pos + 1).type_as(h)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, start_pos, freqs_cis, mask)\n",
    "        h = self.norm(h)\n",
    "        output = self.output(h[:, -1, :])  # only compute last logits\n",
    "        preds = torch.sigmoid(output) # Apply sigmoid to obtain probabilities\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.binary_cross_entropy(preds.view(-1), targets.float()) # Use BCE loss, ensure targets are float\n",
    "\n",
    "        return preds, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.602432 M parameters\n"
     ]
    }
   ],
   "source": [
    "args = ModelArgs(vocab_size=tokenizer.n_words)\n",
    "args\n",
    "\n",
    "model = Transformer(args)\n",
    "model = model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# Hyperparameters\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:17<00:00,  5.63it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "eval_num = 10\n",
    "epochs = 100\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "max_iters = epochs\n",
    "for iter in trange(max_iters):\n",
    "\n",
    "#     # every once in a while evaluate the loss on train and val sets\n",
    "#     if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "#         losses = estimate_loss()\n",
    "#         print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, 0, yb)\n",
    "    loss_list.append(loss.item())\n",
    "#     optimizer.zero_grad()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    \n",
    "#     if iter % eval_num == 0:\n",
    "#         total = sum(loss_list)\n",
    "#         loss_list = []\n",
    "#         avg = total / eval_num\n",
    "#         print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f83ec1a77f0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(list1, list2):\n",
    "    correct = 0\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] == list2[i]:\n",
    "            correct += 1\n",
    "    return correct / len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65125\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "lists1 = []\n",
    "lists2 = []\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    X, y = get_batch('test')\n",
    "\n",
    "    output, _ = model(X, 0)\n",
    "    output\n",
    "\n",
    "    mean = output.mean()\n",
    "\n",
    "    outing = []\n",
    "\n",
    "    for outs in output:\n",
    "        if outs.item() >= mean:\n",
    "            outing.append(1)\n",
    "        else:\n",
    "            outing.append(0)\n",
    "\n",
    "    list1 = outing\n",
    "    lists1.append(list1)\n",
    "\n",
    "    list2 = y.tolist()\n",
    "    lists2.append(list2)\n",
    "    \n",
    "    accuracy_list.append(accuracy(list1, list2))\n",
    "    \n",
    "print(sum(accuracy_list) / len(accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=300)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
