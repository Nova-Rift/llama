{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25a0346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 512\n",
    "    n_layers: int = 8\n",
    "    n_heads: int = 8\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    norm_eps: float = 1e-5\n",
    "    max_batch_size: int = 32\n",
    "    max_seq_len: int = 2048\n",
    "\n",
    "\n",
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight\n",
    "\n",
    "\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis\n",
    "\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "\n",
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cis: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "\n",
    "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
    "\n",
    "        self.cache_k = torch.zeros(\n",
    "            (args.max_batch_size, args.max_seq_len, self.n_heads, self.head_dim)\n",
    "        ).cuda()\n",
    "        self.cache_v = torch.zeros(\n",
    "            (args.max_batch_size, args.max_seq_len, self.n_heads, self.head_dim)\n",
    "        ).cuda()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        bsz, seqlen, _ = x.shape\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "\n",
    "        xq = xq.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n",
    "\n",
    "        self.cache_k = self.cache_k.to(xq)\n",
    "        self.cache_v = self.cache_v.to(xq)\n",
    "\n",
    "        self.cache_k[:bsz, start_pos : start_pos + seqlen] = xk\n",
    "        self.cache_v[:bsz, start_pos : start_pos + seqlen] = xv\n",
    "\n",
    "        keys = self.cache_k[:bsz, : start_pos + seqlen]\n",
    "        values = self.cache_v[:bsz, : start_pos + seqlen]\n",
    "\n",
    "        xq = xq.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        if mask is not None:\n",
    "            scores = scores + mask  # (bs, n_local_heads, slen, cache_len + slen)\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        output = torch.matmul(scores, values)  # (bs, n_local_heads, slen, head_dim)\n",
    "        output = output.transpose(\n",
    "            1, 2\n",
    "        ).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        return self.wo(output)\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        hidden_dim: int,\n",
    "        multiple_of: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(2 * hidden_dim / 3)\n",
    "        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
    "\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w2(F.silu(self.w1(x)) * self.w3(x))\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.attention = Attention(args)\n",
    "        self.feed_forward = FeedForward(\n",
    "            dim=args.dim, hidden_dim=4 * args.dim, multiple_of=args.multiple_of\n",
    "        )\n",
    "        self.layer_id = layer_id\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        h = x + self.attention.forward(self.attention_norm(x), start_pos, freqs_cis, mask)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, params: ModelArgs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = params\n",
    "        self.vocab_size = params.vocab_size\n",
    "        self.n_layers = params.n_layers\n",
    "\n",
    "        self.tok_embeddings = nn.Embedding(params.vocab_size, params.dim)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for layer_id in range(params.n_layers):\n",
    "            self.layers.append(TransformerBlock(layer_id, params))\n",
    "\n",
    "        self.norm = RMSNorm(params.dim, eps=params.norm_eps)\n",
    "        self.output = nn.Linear(params.dim, params.vocab_size, bias=False)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(\n",
    "            self.params.dim // self.params.n_heads, self.params.max_seq_len * 2\n",
    "        )\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def forward(self, tokens: torch.Tensor, start_pos: int):\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        h = self.tok_embeddings(tokens)\n",
    "        self.freqs_cis = self.freqs_cis.to(h.device)\n",
    "        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]\n",
    "\n",
    "        mask = None\n",
    "        if seqlen > 1:\n",
    "            mask = torch.full((1, 1, seqlen, seqlen), float(\"-inf\"), device=tokens.device)\n",
    "            mask = torch.triu(mask, diagonal=start_pos + 1).type_as(h)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, start_pos, freqs_cis, mask)\n",
    "        h = self.norm(h)\n",
    "        output = self.output(h[:, -1, :])  # only compute last logits\n",
    "        return output.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e82b02-f6a3-4e59-9024-22cd00257965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama import Tokenizer, LLaMA\n",
    "\n",
    "tokenizer = Tokenizer(model_path='./tokenizer.model')\n",
    "\n",
    "model_args = ModelArgs()\n",
    "model_args.vocab_size = tokenizer.n_words\n",
    "model_args\n",
    "\n",
    "torch.set_default_tensor_type(torch.cuda.HalfTensor)\n",
    "model = Transformer(model_args)\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "checkpoint = torch.load('../7B/consolidated.00.pth', map_location=\"cpu\")\n",
    "\n",
    "# pretrained_checkpoint = {k: v for k, v in checkpoint.items() if 'output' not in k}\n",
    "\n",
    "# model.load_state_dict(pretrained_checkpoint, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fa66d78-3bc7-4cbb-ab37-9ad0919c99ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'wq.weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwq.weight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'wq.weight'"
     ]
    }
   ],
   "source": [
    "model.state_dict()['wq.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9d1947d-70bb-48d4-9435-e4252f777862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.attention.wq.weight\n"
     ]
    }
   ],
   "source": [
    "for key in model.state_dict().keys():\n",
    "    if 'wq.weight' in key:\n",
    "        print(key)\n",
    "        break  # remove this line if you want to print all matching keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52446dc5-c5a8-4f64-87dd-532a7f8bfd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any('layers.0' in key for key in model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66dea049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "# This software may be used and distributed according to the terms of the GNU General Public License version 3.\n",
    "\n",
    "from typing import Tuple\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import fire\n",
    "import time\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from fairscale.nn.model_parallel.initialize import initialize_model_parallel\n",
    "\n",
    "from llama import ModelArgs, Tokenizer, LLaMA\n",
    "\n",
    "\n",
    "def setup_model_parallel() -> Tuple[int, int]:\n",
    "    local_rank = 1\n",
    "    world_size = 1\n",
    "\n",
    "    torch.distributed.init_process_group(\"nccl\")\n",
    "    initialize_model_parallel(world_size)\n",
    "    torch.cuda.set_device(local_rank)\n",
    "\n",
    "    # seed must be the same in all processes\n",
    "    torch.manual_seed(1)\n",
    "    return local_rank, world_size\n",
    "\n",
    "\n",
    "def load(\n",
    "    ckpt_dir: str,\n",
    "    tokenizer_path: str,\n",
    "    local_rank: int,\n",
    "    world_size: int,\n",
    "    max_seq_len: int,\n",
    "    max_batch_size: int,\n",
    ") -> LLaMA:\n",
    "    start_time = time.time()\n",
    "    checkpoints = sorted(Path(ckpt_dir).glob(\"*.pth\"))\n",
    "    assert world_size == len(\n",
    "        checkpoints\n",
    "    ), f\"Loading a checkpoint for MP={len(checkpoints)} but world size is {world_size}\"\n",
    "    ckpt_path = checkpoints[local_rank]\n",
    "    print(\"Loading\")\n",
    "    checkpoint = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    with open(Path(ckpt_dir) / \"params.json\", \"r\") as f:\n",
    "        params = json.loads(f.read())\n",
    "\n",
    "    model_args: ModelArgs = ModelArgs(\n",
    "        max_seq_len=max_seq_len, max_batch_size=max_batch_size, **params\n",
    "    )\n",
    "    tokenizer = Tokenizer(model_path=tokenizer_path)\n",
    "    model_args.vocab_size = tokenizer.n_words\n",
    "    torch.set_default_tensor_type(torch.cuda.HalfTensor)\n",
    "    model = Transformer(model_args)\n",
    "\n",
    "    # for key in model.state_dict().keys():\n",
    "    #     if 'rope.freqs' in key:\n",
    "    #         print(key)\n",
    "    #         break  # remove this line if you want to print all matching keys\n",
    "    #     else:\n",
    "    #         print(\"-------------------------------------- Nope -----------------------------\")\n",
    "    \n",
    "    torch.set_default_tensor_type(torch.FloatTensor)\n",
    "    # model.load_state_dict(checkpoint, strict=False)\n",
    "\n",
    "    # Attempt to load the model's weights from a checkpoint\n",
    "    result = model.load_state_dict(checkpoint, strict=False)\n",
    "    \n",
    "    # Extract missing and unexpected keys\n",
    "    missing_keys = result.missing_keys\n",
    "    unexpected_keys = result.unexpected_keys\n",
    "    \n",
    "    # If there are any missing or unexpected keys, print them out\n",
    "    if missing_keys or unexpected_keys:\n",
    "        print(\"There were some issues loading the checkpoint into the model:\")\n",
    "    \n",
    "        if missing_keys:\n",
    "            print(\"\\nMissing keys:\")\n",
    "            for key in missing_keys:\n",
    "                print(key)\n",
    "        \n",
    "        if unexpected_keys:\n",
    "            print(\"\\nUnexpected keys:\")\n",
    "            for key in unexpected_keys:\n",
    "                print(key)\n",
    "    else:\n",
    "        print(\"Model loaded successfully from checkpoint!\")\n",
    "\n",
    "    \n",
    "    generator = LLaMA(model, tokenizer)\n",
    "    print(f\"Loaded in {time.time() - start_time:.2f} seconds\")\n",
    "    return generator\n",
    "\n",
    "\n",
    "def main(\n",
    "    ckpt_dir: str,\n",
    "    tokenizer_path: str,\n",
    "    temperature: float = 0.8,\n",
    "    top_p: float = 0.95,\n",
    "    max_seq_len: int = 512,\n",
    "    max_batch_size: int = 32,\n",
    "):\n",
    "    local_rank, world_size = 0, 1\n",
    "    if local_rank > 0:\n",
    "        sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "    generator = load(\n",
    "        ckpt_dir, tokenizer_path, local_rank, world_size, max_seq_len, max_batch_size\n",
    "    )\n",
    "\n",
    "    prompts = [\n",
    "        # For these prompts, the expected answer is the natural continuation of the prompt\n",
    "        \"I believe the meaning of life is\",\n",
    "        \"Simply put, the theory of relativity states that \",\n",
    "        \"Building a website can be done in 10 simple steps:\\n\",\n",
    "        # Few shot prompts: https://huggingface.co/blog/few-shot-learning-gpt-neo-and-inference-api\n",
    "        \"\"\"Tweet: \"I hate it when my phone battery dies.\"\n",
    "Sentiment: Negative\n",
    "###\n",
    "Tweet: \"My day has been 👍\"\n",
    "Sentiment: Positive\n",
    "###\n",
    "Tweet: \"This is the link to the article\"\n",
    "Sentiment: Neutral\n",
    "###\n",
    "Tweet: \"This new music video was incredibile\"\n",
    "Sentiment:\"\"\",\n",
    "        \"\"\"Translate English to French:\n",
    "\n",
    "sea otter => loutre de mer\n",
    "\n",
    "peppermint => menthe poivrée\n",
    "\n",
    "plush girafe => girafe peluche\n",
    "\n",
    "cheese =>\"\"\",\n",
    "    ]\n",
    "    results = generator.generate(\n",
    "        prompts, max_gen_len=256, temperature=temperature, top_p=top_p\n",
    "    )\n",
    "\n",
    "    for result in results:\n",
    "        print(result)\n",
    "        print(\"\\n==================================\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1399096b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading\n",
      "There were some issues loading the checkpoint into the model:\n",
      "\n",
      "Unexpected keys:\n",
      "layers.0.attention.inner_attention.rope.freqs\n",
      "layers.1.attention.inner_attention.rope.freqs\n",
      "layers.2.attention.inner_attention.rope.freqs\n",
      "layers.3.attention.inner_attention.rope.freqs\n",
      "layers.4.attention.inner_attention.rope.freqs\n",
      "layers.5.attention.inner_attention.rope.freqs\n",
      "layers.6.attention.inner_attention.rope.freqs\n",
      "layers.7.attention.inner_attention.rope.freqs\n",
      "layers.8.attention.inner_attention.rope.freqs\n",
      "layers.9.attention.inner_attention.rope.freqs\n",
      "layers.10.attention.inner_attention.rope.freqs\n",
      "layers.11.attention.inner_attention.rope.freqs\n",
      "layers.12.attention.inner_attention.rope.freqs\n",
      "layers.13.attention.inner_attention.rope.freqs\n",
      "layers.14.attention.inner_attention.rope.freqs\n",
      "layers.15.attention.inner_attention.rope.freqs\n",
      "layers.16.attention.inner_attention.rope.freqs\n",
      "layers.17.attention.inner_attention.rope.freqs\n",
      "layers.18.attention.inner_attention.rope.freqs\n",
      "layers.19.attention.inner_attention.rope.freqs\n",
      "layers.20.attention.inner_attention.rope.freqs\n",
      "layers.21.attention.inner_attention.rope.freqs\n",
      "layers.22.attention.inner_attention.rope.freqs\n",
      "layers.23.attention.inner_attention.rope.freqs\n",
      "layers.24.attention.inner_attention.rope.freqs\n",
      "layers.25.attention.inner_attention.rope.freqs\n",
      "layers.26.attention.inner_attention.rope.freqs\n",
      "layers.27.attention.inner_attention.rope.freqs\n",
      "layers.28.attention.inner_attention.rope.freqs\n",
      "layers.29.attention.inner_attention.rope.freqs\n",
      "layers.30.attention.inner_attention.rope.freqs\n",
      "layers.31.attention.inner_attention.rope.freqs\n",
      "Loaded in 13.84 seconds\n",
      "I believe the meaning of life is to discover it for yourself. But I do think it’s worthwhile to reflect on what a meaningful life might mean. This is from a talk I did with Monica Tennison. It’s a talk I’ve given in various forms many times. What makes it worthwhile to ask these questions? I think in order to do something meaningful in the world, we need to be aware of what is meaningful. I think if we don’t ask these questions, we might not even know what’s meaningful. And then we would be living a life of quiet desperation. We would be living a life without meaning.\n",
      "By the way, when I say “meaningful,” I’m not just talking about work or your job. Your job is a very small part of life. Most of life is relationships. So I’m talking about what you do in relationships. I’m talking about what gives life meaning. I’m talking about what you do that matters in relationships, whether it’s with friends, family, colleagues, or your community.\n",
      "What is a meaningful life? What is a meaningful relationship? What makes a meaningful contribution to the world?\n",
      "These are not\n",
      "\n",
      "==================================\n",
      "\n",
      "Simply put, the theory of relativity states that 1) there is no absolute reference frame in the universe, and 2) therefore, everything is relative to something else.\n",
      "As such, there is no single reference frame by which everything else can be measured. You cannot say whether the speed of light is 186,000 miles per second in a fixed reference frame. You can only say that the speed of light is 186,000 miles per second in one reference frame, and faster than that in another.\n",
      "This is why Einstein's theory is necessary to explain the results of his famous 1919 experiment.\n",
      "The idea of relativity is not new. It is based on the observation that the motion of a body is relative to the observer. In the 1600s, Galileo discovered that objects fall at the same rate when dropped from the same height, whether that height is from the Earth's surface, or from the surface of the moon.\n",
      "He proved that on Earth, gravity pulls all objects downward, at a constant rate, and that on the moon, gravity pulls objects at the same rate, but in a lower direction.\n",
      "Furthermore, Einstein proved that there is no absolute\n",
      "\n",
      "==================================\n",
      "\n",
      "Building a website can be done in 10 simple steps:\n",
      "This part is super important because it sets the tone for the rest of the process. You’ve got a vision and you need to communicate it to your web developer. Be clear and concise. Let them know what you’re looking for.\n",
      "Your website needs to be mobile-friendly. In 2017, over 50% of all web traffic was done via mobile devices. It’s time to make sure your website is mobile-friendly. This also means that your website needs to be responsive. This means that it will adapt to any screen size automatically. You don’t want your website to look terrible on a 50 inch screen or in a small phone window.\n",
      "You’ve got to understand the power of mobile. Get in touch with a team that can help you build a mobile-friendly website.\n",
      "It’s important that your website is responsive to the users. Make sure that your website is designed to accommodate all types of devices and screen sizes.\n",
      "When building a website, you’ve got to make sure that it’s easy to navigate. This means that the user shouldn’t get lost and find themselves in a dead end.\n",
      "Whether you’re s\n",
      "\n",
      "==================================\n",
      "\n",
      "Tweet: \"I hate it when my phone battery dies.\"\n",
      "Sentiment: Negative\n",
      "###\n",
      "Tweet: \"My day has been 👍\"\n",
      "Sentiment: Positive\n",
      "###\n",
      "Tweet: \"This is the link to the article\"\n",
      "Sentiment: Neutral\n",
      "###\n",
      "Tweet: \"This new music video was incredibile\"\n",
      "Sentiment: Positive\n",
      "###\n",
      "Tweet: \"I can't wait for the new Star Wars movie\"\n",
      "Sentiment: Positive\n",
      "###\n",
      "Tweet: \"I have never seen a movie as good as this\"\n",
      "Sentiment: Positive\n",
      "###\n",
      "Tweet: \"I'm so excited for my vacation next week\"\n",
      "Sentiment: Positive\n",
      "###\n",
      "Tweet: \"I'm so sad my vacation is over\"\n",
      "Sentiment: Negative\n",
      "###\n",
      "Tweet: \"I love my new camera\"\n",
      "Sentiment: Positive\n",
      "###\n",
      "Tweet: \"I'm thinking of getting a new camera\"\n",
      "Sentiment: Neutral\n",
      "###\n",
      "Tweet: \"I really want to go to Morocco\"\n",
      "Sentiment: Positive\n",
      "###\n",
      "Tweet: \"This restaurant is terrible\"\n",
      "Sentiment: Negative\n",
      "###\n",
      "Tweet: \"I just ate the most delicious piece of chicken ever\"\n",
      "Sentiment: Positive\n",
      "###\n",
      "Tweet: \"I can't wait for my next trip to Africa\"\n",
      "Sentiment: Positive\n",
      "\n",
      "==================================\n",
      "\n",
      "Translate English to French:\n",
      "\n",
      "sea otter => loutre de mer\n",
      "\n",
      "peppermint => menthe poivrée\n",
      "\n",
      "plush girafe => girafe peluche\n",
      "\n",
      "cheese => fromage\n",
      "\n",
      "Borrowing and translation in natural language\n",
      "\n",
      "The term borrowing is used in the field of linguistics to denote the process of one language (the borrowing language) borrowing words from another language (the language being borrowed from). The term translation is used to denote a formal language-to-language transfer of meaning from one language to another. It is sometimes necessary to draw a distinction between the two terms, for example in the case of translations of literature or legal documents.\n",
      "\n",
      "## Etymology\n",
      "\n",
      "The word borrow, in the sense of \"to take into one's possession for a time\", has its origins in the Old English gebyrdan (Middle English borrowen), from the verb gebyrda, which means \"to take, receive\" (cf. Middle English borrowen, Middle Dutch berouwen, Middle High German beroben, German erben, Old High German bereben, Old Norse bjóru). This verb comes from Proto-Germanic *bherjaną (with a short i, from Proto-Indo-European *bʰérǵʰon-, \"to sow\"), from the Proto-Indo-European root\n",
      "\n",
      "==================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main('../7B', './tokenizer.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
