{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import html\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import sentencepiece as spm\n",
    "from llama import Tokenizer\n",
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16  # how many independent sequences will we process in parallel?\n",
    "block_size = 1000  # what is the maximum context length for predictions?\n",
    "max_iters = 100\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 128\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.01\n",
    "# ------------\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "df = pd.read_csv('./opt_intelligence_test_data.csv')\n",
    "\n",
    "# remove NaN\n",
    "df = df.dropna(subset=['PL_DATE_OF_BIRTH'])\n",
    "\n",
    "# remove HTML characters\n",
    "df['O_BODY1'] = df['O_BODY1'].apply(html.unescape)\n",
    "df['O_NAME'] = df['O_NAME'].apply(html.unescape)\n",
    "df['O_HEADLINE1'] = df['O_HEADLINE1'].apply(html.unescape)\n",
    "df['O_DISPLAY_NAME'] = df['O_DISPLAY_NAME'].apply(html.unescape)\n",
    "\n",
    "# shuffle dem bitches\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = math.floor(df.shape[0]*.9)\n",
    "train_data = df.iloc[:n, :]\n",
    "val_data = df.iloc[n:, :]\n",
    "\n",
    "tokenizer = Tokenizer(model_path='tokenizer.model')\n",
    "\n",
    "def get_batch(split):\n",
    "    strings = []\n",
    "    optins = []\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    \n",
    "    # Separate positive and negative classes\n",
    "    df_positive = data[data.OPTED_IN == 1]\n",
    "    df_negative = data[data.OPTED_IN == 0]\n",
    "    \n",
    "    # Select half the batch size from each class\n",
    "    half_batch = batch_size // 2\n",
    "    idx_positive = torch.randperm(len(df_positive))[:half_batch]\n",
    "    idx_negative = torch.randperm(len(df_negative))[:half_batch] + len(df_positive)\n",
    "    \n",
    "    # Combine indices and shuffle\n",
    "    indices = torch.cat([idx_positive, idx_negative])\n",
    "    indices = indices[torch.randperm(len(indices))]\n",
    "\n",
    "    # Join positive and negative classes\n",
    "    df_combined = pd.concat([df_positive, df_negative])\n",
    "\n",
    "    for i in indices:\n",
    "        row = df_combined.iloc[i.item()]\n",
    "        string_dict = row[:-1].to_dict()  # turns row into dictionary cols=keys\n",
    "        string = ', '.join(f'{k}: {v}' for k, v in string_dict.items())  # creates string from row dict\n",
    "        encoded_string = torch.tensor(tokenizer.encode(string, bos=True, eos=False))  # encode string to tensor\n",
    "        full_tensor = torch.full((block_size,), 0)  # create tensor as long as longest and fill with new token\n",
    "        # using same token as <unk> 0\n",
    "        full_tensor[:len(encoded_string)] = encoded_string  # replace beginning of full tensor with original string tensor\n",
    "        encoded_string = full_tensor  # encoded string with padding\n",
    "        strings.append(encoded_string)  # add tensor to list of tensors\n",
    "        optin_dict = row[-1:].to_dict()  # convert optin column to dict\n",
    "        optins.append(optin_dict['opted_in'.upper()])  # add optin value to list\n",
    "        \n",
    "    optins = torch.tensor(optins)  # turn optins list to tensor\n",
    "    \n",
    "    x, y = torch.stack(strings), optins\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def get_all_data(split):\n",
    "    strings = []\n",
    "    optins = []\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    \n",
    "    # Separate positive and negative classes\n",
    "    df_positive = data[data.OPTED_IN == 1]\n",
    "    df_negative = data[data.OPTED_IN == 0]\n",
    "    df_negative = df_negative.iloc[:df_positive.shape[0]]  \n",
    "    \n",
    "    # Join positive and negative classes\n",
    "    df_combined = pd.concat([df_positive, df_negative])\n",
    "\n",
    "    for i in range(len(df_combined)):\n",
    "        row = df_combined.iloc[i]\n",
    "        string_dict = row[:-1].to_dict()  # turns row into dictionary cols=keys\n",
    "        string = ', '.join(f'{k}: {v}' for k, v in string_dict.items())  # creates string from row dict\n",
    "        encoded_string = torch.tensor(tokenizer.encode(string, bos=True, eos=False))  # encode string to tensor\n",
    "        full_tensor = torch.full((block_size,), 0)  # create tensor as long as longest and fill with new token\n",
    "        # using same token as <unk> 0\n",
    "        full_tensor[:len(encoded_string)] = encoded_string  # replace beginning of full tensor with original string tensor\n",
    "        encoded_string = full_tensor  # encoded string with padding\n",
    "        strings.append(encoded_string)  # add tensor to list of tensors\n",
    "        optin_dict = row[-1:].to_dict()  # convert optin column to dict\n",
    "        optins.append(optin_dict['opted_in'.upper()])  # add optin value to list\n",
    "        \n",
    "    optins = torch.tensor(optins)  # turn optins list to tensor\n",
    "    \n",
    "    x, y = torch.stack(strings), optins\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "# from typing import Optional, Tuple\n",
    "# from dataclasses import dataclass\n",
    "# import math\n",
    "\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 256\n",
    "    n_layers: int = 4\n",
    "    n_heads: int = 4\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    norm_eps: float = 1e-06\n",
    "    max_batch_size: int = 16\n",
    "    max_seq_len: int = 1024\n",
    "\n",
    "\n",
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight\n",
    "\n",
    "\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis\n",
    "\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "\n",
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cis: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "\n",
    "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        bsz, seqlen, _ = x.shape\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "\n",
    "        xq = xq.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n",
    "\n",
    "        keys = xk\n",
    "        values = xv\n",
    "\n",
    "        xq = xq.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        if mask is not None:\n",
    "            scores = scores + mask\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        output = torch.matmul(scores, values)\n",
    "        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        return self.wo(output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        hidden_dim: int,\n",
    "        multiple_of: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(2 * hidden_dim / 3)\n",
    "        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
    "\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w2(F.silu(self.w1(x)) * self.w3(x))\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.attention = Attention(args)\n",
    "        self.feed_forward = FeedForward(\n",
    "            dim=args.dim, hidden_dim=4 * args.dim, multiple_of=args.multiple_of\n",
    "        )\n",
    "        self.layer_id = layer_id\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        h = x + self.attention.forward(self.attention_norm(x), start_pos, freqs_cis, mask)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, params: ModelArgs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = params\n",
    "        self.vocab_size = params.vocab_size\n",
    "        self.n_layers = params.n_layers\n",
    "\n",
    "        self.tok_embeddings = nn.Embedding(params.vocab_size, params.dim)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for layer_id in range(params.n_layers):\n",
    "            self.layers.append(TransformerBlock(layer_id, params))\n",
    "\n",
    "        self.norm = RMSNorm(params.dim, eps=params.norm_eps)\n",
    "        self.output = nn.Linear(params.dim, 1, bias=False)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(\n",
    "            self.params.dim // self.params.n_heads, self.params.max_seq_len * 2\n",
    "        )\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, start_pos: int, targets=None):\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        h = self.tok_embeddings(tokens)\n",
    "        self.freqs_cis = self.freqs_cis.to(h.device)\n",
    "        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]\n",
    "\n",
    "        mask = None\n",
    "        if seqlen > 1:\n",
    "            mask = torch.full((1, 1, seqlen, seqlen), float(\"-inf\"), device=tokens.device)\n",
    "            mask = torch.triu(mask, diagonal=start_pos + 1).type_as(h)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, start_pos, freqs_cis, mask)\n",
    "        h = self.norm(h)\n",
    "        output = self.output(h[:, -1, :])  # only compute last logits\n",
    "        preds = torch.sigmoid(output) # Apply sigmoid to obtain probabilities\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.binary_cross_entropy(preds.view(-1), targets.float()) # Use BCE loss, ensure targets are float\n",
    "\n",
    "        return preds, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_all_data('train')\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.602432 M parameters\n"
     ]
    }
   ],
   "source": [
    "args = ModelArgs(vocab_size=tokenizer.n_words)\n",
    "args\n",
    "\n",
    "model = Transformer(args)\n",
    "model = model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# Hyperparameters\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.6625794172286987, count = 0\n",
      "loss = 0.7959015369415283, count = 50\n",
      "loss = 0.5712161064147949, count = 100\n",
      "loss = 0.5156165957450867, count = 150\n",
      "loss = 0.6143976449966431, count = 200\n",
      "loss = 0.4973098933696747, count = 250\n",
      "loss = 0.82292640209198, count = 300\n",
      "loss = 0.6432209610939026, count = 350\n",
      "loss = 0.5377069711685181, count = 400\n",
      "loss = 0.6870730519294739, count = 450\n",
      "loss = 0.6705581545829773, count = 500\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "epochs = 1\n",
    "\n",
    "count = 0\n",
    "break_count = 500\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for X_batch, y_batch in dataloader:\n",
    "\n",
    "        # evaluate the loss\n",
    "        logits, loss = model(X_batch, 0, y_batch)\n",
    "        loss_list.append(loss.item())\n",
    "    #     optimizer.zero_grad()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "#         loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if count % (break_count / 10) == 0:\n",
    "            print(f'loss = {loss.item()}, count = {count}')\n",
    "        \n",
    "        if count == break_count:\n",
    "            break\n",
    "        else:\n",
    "            count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe6700be640>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAAsTAAALEwEAmpwYAAA2g0lEQVR4nO2deZwcRd3/3zV75thNwk4OcgABwhFAQO5DBBQ55FDEMsLDI8hD/IGcD4Lg8wAePAiiCD5chkNuseSQgAiPAoqCyCXIDeEK4Up2c26yd9fvj+qe6e7p2ZndzGbTk+/79dqdnu7q6qqe7k9/61vfqlbWWgRBEIT0kxnuAgiCIAiVQQRdEAShShBBFwRBqBJE0AVBEKoEEXRBEIQqoXYYjy3hNYIgCINDJa0cTkHnww8/HNR+2WyW1tbWCpdm7UbqvG4gdV43WJ06T548ueg2cbkIgiBUCSLogiAIVYIIuiAIQpUggi4IglAliKALgiBUCSLogiAIVYIIuiAIQpWQSkHveft17NuvD3cxBEEQ1iqGdWDRYFl8xrEA1Fw7d5hLIgiCsPaQSgtdEARBKEQEXRAEoUoQQRcEQagSRNAFQRCqBBF0QRCEKkEEXRAEoUoQQRcEQagSRNAFQRCqBBF0QRCEKkEEXRAEoUoQQRcEQagSRNAFQRCqBBF0QRCEKkEEXRAEoUooOX2u1roReAxo8NPfaYw5P5amAbgZ2AFoA75mjHm34qUVBEEQilKOhd4F7GuM2RbYDjhAa71rLM1xwBJjzKbAz4GLK1pKQRAEoSQlBd0YY40x7f7XOv/PxpIdBtzkL98JfE5rrSpWSkEQBKEkZb2xSGtdAzwLbApcaYz5RyzJFOB9AGNMr9Z6GdACtMbymQ3M9tORzWYHVehP/M/B7p9Gamtr16n6gtR5XUHqXMF8y0lkjOkDttNajwXu0VpvbYx5aaAHM8bMAeb4X21ra2t/yUuyuvuniWw2u07VF6TO6wpS54ExefLkotsGFOVijFkKPAocENv0ATANQGtdC4zBdY4KgiAIa4iSgq61Hu9b5mitRwD7Aa/Fks0FvuEvHwE8YoyJ+9kFQRCEIaQcl8v6wE2+Hz0DGGPM/VrrHwLPGGPmAtcDt2it5wGLgVlDVmJBEAQhkZKCboz5F7B9wvrzQsudwFcrWzRBEARhIMhIUUEQhCpBBF0QBKFKEEEXBEGoEkTQBUEQqgQRdEEQhCpBBF0QBKFKEEEXBEGoEkTQBUEQqgQRdEEQhCpBBF0QBKFKEEEXBEGoEkTQBUEQqgQRdEEQhCpBBF0QBKFKEEEXBEGoEkTQBUEQqgQRdEEQhCpBBF0QBKFKEEEXBEGoEkTQBUEQqgQRdEEQhCpBBF0QBKFKEEEXBEGoEkTQBUEQqgQRdEEQhCqhtlQCrfU04GZgImCBOcaYy2Np9gbuBd7xV91tjPlhZYsqCIIg9EdJQQd6gTOMMc9prZuAZ7XWfzTGvBJL91djzMGVL6IgCIJQDiVdLsaYj4wxz/nLK4BXgSlDXTBBEARhYJRjoefQWm8EbA/8I2HzblrrF4APge8YY15O2H82MBvAGEM2mx1wgQE+8T9bWlpQSg0qj7RRW1s76POVVqTO6wZS5wrmW25CrfVo4C7gNGPM8tjm54ANjTHtWuuDgN8BM+J5GGPmAHP8r7a1tXVQhQ5oXbQIlVk3+nWz2Syre77ShtR53UDqPDAmT55cdFtZaqi1rsOJ+W3GmLvj240xy40x7f7yA0Cd1nroH7nWDvkhBEEQ0kJJQddaK+B64FVjzKVF0kzy06G13tnPt62SBU1EBF0QBCFHOS6XPYCjgRe11s/7674HbABgjLkGOAI4QWvdC3QAs4wxa0BtRdAFQRACSgq6MeZvQL89j8aYK4ArKlWoshE9FwRByJHyHkVRdEEQhIB0C7r40AVBEHKkXNCHuwCCIAhrD+kWdFF0QRCEHOkWdOsNdwkEQRDWGlIu6MNdAEEQhLWHlAu6KLogCEJAugVdTHRBEIQc6RZ00XNBEIQc6RZ0UXRBEIQc6RZ08aELgiDkSLmgD3cBBEEQ1h7SLeii6IIgCDnSLegysEgQBCFHygV9uAsgCIKw9pByQRdFFwRBCEi3oIuJLgiCkCPdgi56LgiCkCPlgi6KLgiCEJBuQRcTXRAEIUe6BV30XBAEIUe6BV0UXRAEIUfqBN2G/eaeDCwSBEEISJ2gS0eoIAhCMrWlEmitpwE3AxNxPo45xpjLY2kUcDlwELAKOMYY81zliwsRN4uIuyAIQo5yLPRe4AxjzExgV+DbWuuZsTQHAjP8v9nA1RUtZRhb9IsgCMI6TUlBN8Z8FFjbxpgVwKvAlFiyw4CbjTHWGPMkMFZrvX7FSwtRq1z0XBAEIceAfOha642A7YF/xDZNAd4PfV9AoehXCHG5CIIgJFHShx6gtR4N3AWcZoxZPpiDaa1n41wyGGPIZrMDzsP2dLPQXx43biy1g8gjjdTW1g7qfKUZqfO6gdS5gvmWk0hrXYcT89uMMXcnJPkAmBb6PtVfF8EYMweY43+1ra2tAystTtADlixegmoYNeA80kg2m2Uw5yvNSJ3XDaTOA2Py5MlFt5UT5aKA64FXjTGXFkk2FzhJa30HsAuwzBjz0SDKOjDkBReCIAg5yrHQ9wCOBl7UWj/vr/sesAGAMeYa4AFcyOI8XNjisRUvaYB0igqCICRSUtCNMX8DVIk0Fvh2pQrVLxK2KAiCkEj6RopKlIsgCEIi6RP0iIiLoAuCIASkT9ARH7ogCEIS6RP0iIEuii4IghCQQkEXl4sgCEIS6RN0cbkIgiAkkkJBDyEDiwRBEHKkT9DF4yIIgpBI+gRdFF0QBCGR9Am6lYFFgiAISaRQ0MPLIuiCIAgB6RN0cbMIgiAkkj5BF5eLIAhCIukTdOkUFQRBSCR9gh7WcE8EXRAEISB9gh5BBF0QBCEgfYIubywSBEFIJH2CLj50QRCERNIn6BKHLgiCkEgKBV3CFgVBEJJIn6CLm0UQBCGR9Am6uFwEQRASSZ+gS6eoIAhCIukT9LBVLgOLBEEQcqRP0COIoAuCIATUlkqgtb4BOBhYaIzZOmH73sC9wDv+qruNMT+sZCEjyMAiQRCEREoKOnAjcAVwcz9p/mqMObgiJRoQouiCIAgBJV0uxpjHgMVroCzlIXHogiAIiZRjoZfDblrrF4APge8YY15OSqS1ng3MBjDGkM1mB3yg3p5O2vzl5qZmGgaRRxqpra0d1PlKM1LndQOpcwXzrUAezwEbGmPatdYHAb8DZiQlNMbMAeb4X21ra+uAD2YX5xsLy5cvQw0ijzSSzWYZzPlKM1LndQOp88CYPHly0W2rHeVijFlujGn3lx8A6rTWQ/e4FZeLIAhCIqst6FrrSVpr5S/v7OfZ1v9eq4MIuiAIQhLlhC3+GtgbyGqtFwDnA3UAxphrgCOAE7TWvUAHMMsYM3RKK0P/BUEQEikp6MaYr5fYfgUurHEYEEEXBEEISOFIURlYJAiCkET6BN3K5FyCIAhJpFDQw8si6IIgCAHpE/SQooueC4Ig5EmfoIvLRRAEIZH0CbrEoQuCICSSPkEXH7ogCEIiKRR0sdAFQRCSSJ+gRxBBFwRBCEihoMvAIkEQhCTSJ+jiQxcEQUgkfYKOhC0KgiAkkT5Bl5dEC4IgJJJCQS/6RRAEYZ0mfYIeFnHPG75iCIIgrGWkT9AjLhcRdEEQhIB0C3qfCLogCEJA+gQ9TOvH2I5Vw10KQRCEtYJUC7r9v9/h/ei04S6GIAjCWkH6BD0+mGjRx8NTDkEQhLWM9Am6hCoKgiAkkj5BFz0XBEFIJIWCLoouCIKQRPoEXUx0QRCERNIn6KLngiAIidSWSqC1vgE4GFhojNk6YbsCLgcOAlYBxxhjnqt0QfNUp6Lb3h7sbdegDj0SNa5luIsjCEIKKcdCvxE4oJ/tBwIz/L/ZwNWrX6x1kJefx/7tj3i3yekTBGFwlBR0Y8xjwOJ+khwG3GyMscaYJ4GxWuv1K1XAAqq1U7Smxn32dA9vOQRBSC0lXS5lMAV4P/R9gb/uo3hCrfVsnBWPMYZsNjvgg3U3N7Mktm4w+axtdGfHswSoA9ZLqE9tbW1V1HMgSJ3XDaTOFcy34jn2gzFmDjDH/2pbW1sHnIddtqxgXbn52AXvQG8vaqMZAz7uUGPbVwDQ07EqsT7ZbLbselYLUud1A6nzwJg8eXLRbZUQ9A+AaaHvU/11Q8NquFy8H5wKQM21cytVmsrR1+c+e3qGtxyCIKSWSgj6XOAkrfUdwC7AMmNMgbulclSpD72v1332iqALgjA4yglb/DWwN5DVWi8Azse5ejHGXAM8gAtZnIcLWzx2qAoLVK2e5y106RQV1i76fvbfqM98gczOew13UYQSlBR0Y8zXS2y3wLcrVqJSJLhcrOehMukbIxUhZ6H3Dm85BCHOa//CvvYvEEFf60mhCiaY6H1VIIKBhS4ul9XGrliG93uDlXfOrjbhc9h3/KHY558cxtIIpUihoCdQBR2JNrDMV67AdnUOb2FSjnfzldjf3QrzXhnuoqSfwNDw8f76x2EqiFAO6RP0JB/6AK1a+95b2KVtlSlPpQjdON71l5a9m332Cew/y7ea7Hvz8B5/eEBFSx0dK91nTIyEQRBv/So1POWoEuxLz+LdfdOQ5b9G49ArQ4Ki9yPodmU7atToyDrvgtNhVBM1l91W6cINnvCN884bZe/mXXMRUH4opnfBfwJgd98XVa03Z9DPUq31W5PIQ7GieJf/wC3MPmNI8k+hhZ4k6L1Ya7GvvoANbfd+b/BOOxK7PD62FFi5YggLOQjCgr7JFkN/vAq/XNt2ddJ3/KF4fyo/xt+78XK8v/5fRcvhl8Z9xATdtn5C3w9OwS5LuB6EZKqhf2otxA7RFCYpFPSEdb098ObLeJeeC/NezSf93a1uYcXyNVO21SFkCanauqE/XqVdTivbAbAP3lX2Lvbxh7E3X1HZcoSJWZf24fthwbvYJx8dumOuBvat1+h+aQgnKh0McQv95X9i5T2+q0/30IQnp0/Qi7hc7CcfuuUVbmqAyBOws2MNlGs1CSyhsS3YCka62GVL6LvorMI+g0oLenC+u7sqm+9gCMoSP491vodxLQ0N9S46iyXnnjTcxchhvT7sH+6MruztwTt/7SljOdgF77gInYVDON5xgNjOyraQA9In6ElNle5uWOzmRbCBeIcjRbo6C0PYBmEFe/93D979v8G+8PSA9y1JYAk1NlZUcOxfH4K3XsP++Q9uRX29W7+kvwk0B0EgnsMg6AXN1+BrXNCD37zKQkPtS89in3ui8vk+/Tfso78v3DDIwW925Qrnlvv7mm0h2ccfcZ9DEHJpP5yP99DdeNf/fGD7DVEkW/oEPclC7+mGtoVuOXjyrVqZ397VWdh0HDFy4Ef+7a+w996Gd8WPykvf1UXfj07De/xP2BWFk4pFCCz0hhFDKzgNI9xnpS30oMxruBPNznsFb/Zh2PfeCq91/+PhrHXuYba2j8a1r780IGvSu/wHeFdfVPmCVPrhvNC5auzD97nPea/kDbChxPrGnKq83Hnnn4S988YBu/FshfuwAtIn6Ek+9K5O7OJFbrljFfadN+Ht1/K7dHYUimTjiIEddjBW80fzYf7b2Bt/gfej0/tPGwhhXX3ZFvqAOlaCpMFx2ivcrzAMVq/tWIV3nQvxtO/NC20o4nIJ5pyvsMvFfjifvkvPxXZVRgC9n34P77++VZG81lbsimV4F5+daNlaa7FLXQvSvvK8c5dUwm+vFHbBuy6/iAEQOnZvD95Tjw2q09IOwJjxhuhBlj5BT8B2d0Eg6J0deBeegffLn+QTdHWs/k0ci4qxXl/pkYiBRQiwpMRUmX29UFMLdXXli2NZEQj5SA9rbb4FU+konwGe30g00i1XuamNB4j9vcm1zOKhqUChJR5Y7BUeiOb99gZ49QV448Vo+Xp78R5/OL0jVisdiREOOgpcDvPzD2LvyT9jX3gKe98deGceg13ShvXdM/bN5EFitqur9PkNtiuFfeoxt98L/yjMa0kb3sVnY6/9Kbz0bMnqeDfEHkbl3Lf+FCVD5XJJXxx60kXW2ZH3oX/wXuH2rk7oi53sgTYn26MC6F14JtTUUHPOJcX3GYjV2tfnLMjauqi7qD8GKkw93bmL2/pRKZXAfrwA76KzBrhT/ia0jz2Iff9tar7304Hl4eUtItvdndeL4BqJn5/g9+hJ/u29h+9Dbb4NaupGAytHfYP7jN2k9i8PYu+YA709qM/29xbHtZUKC3pgwVobujdCBsf1l0aPuHJFTgDD10sufV8f3klfRX3uENSs4/PrX30B+8JTMH6SP8gsyFXlw3UbClvo3sXfzRkIdtVK+hvFYL2+3MMmR083NDT2sxdQWwvd3eJyyZMwOdctV+at1aQna2dH4c090LChuIvivXnw9us5y9KGLF67uBX76gsD89X29TkLvbY28UFge3uxfX3YVSvzI0NDwlRWEzHcs15BCz3X4ToQ4s3TwVixYZ9o+AHtnwv70D3Y8MPR/82Tbibr9WHvuBbvh6cOvBj17iYucLlYv44L3i2ZRyXiksN9BrarE++Oa1dPOCodKp27ri2U457q6c6PJfA8bGdHNALMd1vY2FgG79JzsQ/fh73jWuy9t4cGmpG/j1clGDRBPxzkHyTFSHKZlGPA1biOeekUDSh1kSVa8J2F7omOlfSd/R/uSV4ORXzO9oP52HfexDvtKLyn/waA96NTXUx8+CFSqhO2rxdqa10Mesh9YT+Yj533Km2nHIl34Xfwbv5fvKsudJ1m4YdSSf+dzcWKA+W3AgaBLedBFi/v4kVli1rfBf+Jd+/tTsSDGy/J6l62GPvbG/LfgzRJde/0b7DBCGuDb6HHW30jm1yWRdxt3iP351uUlfDrh0TGPvaQE7WH7i57d+t5FesHiObb566J8HURErSeea8m//bh39d6eCd/zd1XAYGBUkp8c4KewS70w5uXLx1YJeIkPSjff7f0frXOKSJhizn6ueFG+n7UjTfPr2sag33p2WQXS9tCvFuuKn3Ers7cEPsCFi/Cvv+2Ww5aB4F7JnwBj0zw8YbJuVxqXT/A9Zfi3XoV3vdPwrv4u/R9tADmvwXP+uFpCz+K5t/bg/fYQ3h+BEGo9Lkl78ZfuIX1xg/tSNkyLNICQV+xrOh4gYIO6ffmYe+/w/2mo5vduu5u7FuvYRe8GzkvNuwqCx6wiYK+Gp1UgculO2Z19frlWPhRgSvQ9nRjfz0H78e+q6oMF6B3y5V4/Ql0WCQCd1RnB7ZtUcm8Aex9v8Y76av5yJMEN0cu+ycepu+73yzrIWyvvwzvxCOiFmxQ38WLWHzmcdgn/1y4Y1jQgxbcm69g5/v3W0e5gh5aDlyzixdh33otOT0UuM8KSBB07xc/6D9PyHXM206x0B3+BaSOOgG194HRbf7JUtvtml+3Yhl8vAD7YJEbobsT+/I/8R59wPWuW4vtXIX3xCP5i/WtV5P3BdcZW+N3RXixkYnhi2LkqP7r1dvju1zqnGX55J+xf3mwaHL78YKohd7bg73lSuwd10YT9vk3gvXcQ2CjGagd94SV7QNu5ltr8a7/Od69sTlw4kPsS13UUHCuAPjkA/pOPRL7zN/yeS36GO+Ew/H8sLBIB1hXp3tQKgXdXXgXnYX3g1OiLaNMqGzB+YoJr33njUhU1IAJ4ttXxW7y4HgfvY/3/ZOj/RaB1d6VMG4iAdvV5azuO2/Mf48/mMIPJd8dZR++D+/s47CLS7+/0j7h4rUJpkbop9Vgb77CiWMZLh371F9yZc4Rf/gldYqHBT107rwfneYWyhZ0/5rp6si3tF95Hu+is6LRM2EXXkJLxXp9eeOiSL1zAxyT9l30cU4rhipcM3WCnms9zdiKzFEn5Narb5ycs4LVnp8n892LUP92Yn6/D+cnZ9jZiXfZ+djbr8G75Bzs7ddgb7sG+6vLnJ8csG8XnyzLti3KC1pfHzbkh7NzQh2mCZ0l9qP3XQjVvFeiFnoxttkxv/zJB1ELvZgLJUjTvgLal6M+vRs0NTsXjy8i9s1XsP0MOe87/d/ou+gsePEZ7JOPYu//DXb+29jclAqx7qP33sJ7+D48cz02Qbi9e27Fu/XqhPW3wKp2vKf/Rt/VP6av9RP4eIEr49//7BKFrFDb3eXOa1199FyE3S+v/SsX9maD9TFr2LvwO5GoqLKszlUr83UL3Hm+X9Y++wTeE48U9qG0LcR7+D7X7A9ZzbazA4JWXvgY4XK8+XK0zHN+gnfq16MPz7DIxI/d+okTlff7iSYKWhqBO6K/TnffePJ+eXGBONl/Pun6kOJ1CPmtC1w7CRarS+NfW4sTWhk5l4tv9b70LHZJ8fEV9q6EWQ7DLbggrBWwv7sFu7QN27kqd517l30f74TD6Tvv25A0PxQUnRDO3nUT3vdmwzI/HHOIBD11US5q1GhqNt0Sr74+un7LbVGbbQVLl6CaxkDTGNSmM/Heeg3790egyJMz0qx88xX3BA5+lM4O7PIl2D/eC+tPQ03ZMGI9ojLuQvNvHvv0X7FP/7XwGOMnwdLF2LaFqJYJrhXw5z/Ae2+6/Z5/ChuELfYzglVttb27IZe2YT/+ABUSpnBcrbU2P5Oi38y1vjCSnZi/8Ve2Q+MIvJ+cDUDm6rvcBd7dhZqwfv7A7cuhfXn+ZmkY4ayk8ZPIXHB11Aoe2+J8xr5FrXbbF9vQiP29QR19Iqq2DvuAiVZszDhnFQZN6Y8XwIfz6XrmiZwfOi+a4U7OLjfytb4hKtJhIfLT27dey68v5d5YtRJCYZDeYw+iJk1z1xfOXeKd+nXU5w9Ffe0/8pas78YK3HPq4FmRbO2H77mOuj/eizok/yIw76KzICk665MPYdIU7IJ3sR+/79YFv+srz7s8wzNzhgU99oD3LjkHtdNnsE//lcz3r0BN2cDtv+Bd7PP/QG24aW4UcU6s+uvkq6kFuuGV57F/fxS1z0H5Y111oUty7dyoEAduPmsLf4OuBIHr7sq15GyCoNuQhW69PjeTYZKgxjvcJ28AgYEXdlOFAxI6O/BuvtIJ8Py3nbEYPJA+eh/70fuFx+mHnG709sLEKYzc/0sMxZjq1FnoauZ2tFxyPWr8pOiGEaNQEybnbrqAzDdPQ+26T/khhEva8s2A9uXYV56HVe3uBoxbzxtvBh+8h/1LiSiP0c3Q+gne2f/hrLoP57uWQDAvefPYaNhiUNedPxvNp3ksNZf8CrXbvq4Z//Pz8ttezE9H4F32/bxlFIjYR07QVcuEfAdt7CayD96Fd+YxxQe19MRcFos+xvvWl7FPhR5iTc2wND+tgH33TbzrfoZ94mEoZh0GfvCgOew/fHvnv1348uywaHV3OTGvr4+6LJJG5XpeqPzdbjDQ8Ydi3369MO2H853b7c8PYHt6sLdchXfJOa4+iz52/mDABjNLBg/Nf/49OmdOXLSCB1b7iqjQJYk54J17AvaFp/F+cAr2Lw+5lda6ayhwM4RcBt4VP8q7pBL6SHLGRqiM3hUXuNHPv/hBrnx2aTmCnrdm+43vC89sGVjDlsIQzySX0+KF2NdfcsuxfgDredFO0cAlk9S6igm6mrJhPh+/THZpW2E/Sk93/jeLR8UU65ew1o0/eOyhaOs09IBVW25LzcTJyfuvJqkT9KL0M/JT7bV/+fksW5ITQbtsaU5A1OZb533lQb6bbe0W+mvGxsrmfevLCVa8jYYtAmy+DZnjzyDzizvyxxvh++HXnxq9USAaE/vKP2HFMhe1EIhk8JmdiArcP8uW0HfWN/N53Ht7ftm/6SMdkoEgxm+asIg1jYkIOu/Ny38vFpoYHxTki3jv++/kb/ykDs2cy6UBWypqoac7L7C9PblOOPvw/QVJ7Wv/wj7xiHO9meui22KuD+t5+bL19kbn+YlF3uQ683q7YWGRFmO8LIFlHrSwAO+0o3J1sY/Eyt/Z4Tpckx5UuUxLuJQCC72/aKXwvaAy2O4uvHtvi7hS7NK2mKCHIsXiPvSEMEL7h7vy9Q6HFAJ88iE2CGjwrLOmixF/MIXHGbz9untonpnwbvt+YsqDFoM65pTohu4u7MNzXX9W0CcB0YdFf27V1SR1Lpdi9PeSaDVjJkyaAh9/4FaMbUFtswO0TMhPsds0xll21stZT/aOOflMRox0ozjD+W6+TeFsdEnEQhbti7FY+c4Of6RoyEL3O1FVeN9g3cQpybE+W20PL//TLbd+4lxF4Umb6htcPf0L1fvDnUVHsNrXX8KuWIb69O75lWWEI6qmMdiQ5W8XvJs/RkcRP/+opsTVve+9BTvs4b7Mf8v1g3SEbvzODlR9A7a+PioctQmjbduXR10xvgUbdNjlWG88dt6ruVDEghj72Hwgdu7tzqU3dj3nVrs1FDUVH+sQCHpfX3JURxI1CbdoUofc+tPgo/dhVbuLy+7PJdDdhV26GDv39rzfPIzv5y3bQl+10oVI3v8bqM+LoHfmsZHzlRurseCdwpHBS6MGSlKZw9g/3Rvatw2e78d3HhJTtf+XYXzenWj/dG80rxCqvgFbU+PqFL922xaByqBGN0fuRXv3TaitPu2++L53+6/YZH7hc1dhqsdCL0HmjP+BTWe6L2PGkfn3k1Cf2S+fIHKBxqyFTAZVV1/on9toBqyXLXlsFb9p4k3szo4Cl4tKiooJQh832jS/LtRRmvlsPurHLvq4cG7ylgnOtx5YHoHAJGCfeBj7m+uwj/8pWs5ShMV5XBZCnXZ21Ur6/vPogl1UEUG3K5bBok9y370LvxON7FixzHe5NEQFPWmk54plxcMZw0zZ0Fmo816FcLQUvjXui5LabV8YOdpNPwB+tE3sdurphhGh3zEuCkliWkCZkUh+n4d3zvHYN17uN6l39Y+xd91UVPhznd3FolyUynVEAu6cBBZ03M0U7qMqds4h/xApE/vhAHzYLz6TW1Qzt0eNTr7eANSue+eP8fbr0NeH2usLhQnbFrqWd1wTOlbl/eVenxtFffWPo2lqhu59B6kXdPWFL8G2O5dON3Y9Mie4zr/cMOzRY/IJ+gt9ijdRa2pQRxyLGjWazFkXR7clDSCKW1nxQU6dHe6mqKvPH2tEQtz6SJe3Wm886rCj4FM7kTngK/nt643PF/m6nxXun53oPoNhz/3Fovuz/dmXQ9Ev5bzppzFU/w02jm6b90qyfzvscgluEP88RjpQuzqL+NAbovk2NJL5ya9g+5Agty+Pik3SQLHaOtSYcS7Ko315wRQA9g935h726piTow+O2lricdv2qcdgvSyZcy9LdvtN3qBwXcBGM9znitBv1DQmmibUj6TGrJdfH7wce6vt3efU6ahDYh20/c0OGFwXRVtkKtbx3J57CNj77yiyD/1fb3EfeizoAYCp0/PLxV4AHroHEmloLNoiBKKaEDykpm1cmK63p+Qwf/u7W/HOPbHwwTiELpfUC3rmq9+k5qT/Liutah5LzbVzyXzGPXEjbppMrBm07c6ooLkfE3R1xDFk9v+y+9I8Np/F934aaXLmKPED2rdegwXvorbeIe8jDlno6tjTyIwZl4/4ADIHf42ak8/Nu4Hq62HKBi7GvAgqJ+jFLcPMqd93gt/qW8ZhC3tpghUVv/FG5gU913G95bZu/0cfSD5o+AYLRM7fp4DlsQdCfWN0EjRwD9xxLZEOcvuPvzjXT5B/2O8fvPKvrs510C5f6n7zoLM2yON3t7rOt5GjUJkaCFt6XhFL2vNQG2zs+j3itITEZ8w41IGhh3PwkAu7xKZtTOaae8hcegvqS/9G5vz/zYvKmLHRvDfYOH8ttIzPP8wTUDvsgTrimPyK9hVuqolifUPWi7Q27MoV0F5iemg/37IZFT33TN0Itc2no+s+vVtB4IAKDypMor6hf0HvaEftuV9kldp0y8JrDNy5L/e9tTuEXJfichk6MuddTuai6wss9MzeBxX8sDlU/gdRIb+6mr5Z9CYNSPKDTp3u/K6TprgQqppaF43TUSjomd33ZfyNv0clPhj8Cyo7CVVbR+ZbZ+Wa3wVMnOI+EyYmytHU7F6ykcQbLxWuWz9mZYYsdPWpnaCmlsyhRxY/HqHOZXDhc/5nzaQp+URjnQVaEPJYX+/cYWH886222qHwWDN8t1tovnEVWHWNI139AxKa5nbxopwgRFxFxWa+9FsOqqVQUFXoXGUuuZHM4d/IuWGCvMNRM2rESFRNDappDJkvalRDQ/63DlvoAKPHuPBdQDU0omIPpwgNjajpISFcuQJ7722FrsGtd3B/4EJbD5kFM2ZC60JYkBCpE7aoIepyqq2DmdtFNqvd9sl/iXUo15z/i4KHpho/CabmI1YYP8m5zPqjoSHxd83R3U3mGyfnWpfqqP/nIsOS3GMNjZCdVLg+XMZdXZ3UxNC1PNwWutb6AK3161rreVrrsxO2H6O1XqS1ft7/+4/KF3VoUNOmo1rG55vPwdNz7HrRm9ulLplf5ivfKFyZ8AOqXfem5pIbcxa+2m4XVPh48eZ1MUY4cVY775VfF1htQZM7OObmvnD2Y6Ezurl/wY9d2Cr+8Ai7nCZvQM01dzsLpwiZU85DhV+KHdR7vSzj/iffwZi5+HqYvpn7sskWEOQ5qqlwFG5wvidNgRkzUd88PZ/vjGhYKwAtE9znyFERqzws2Gq/w9zCO2/k+zLCgl6sAzFw7UyfUbitOf8bB+MGVBARFVjo4RGeSe48/7dSoZYi4K6loC6NIwpaG2FsVwdsugXqc4e4foOV7dH49iDPSVNR4ZZT4whnSc9/K3myq6QpjX0y3/9fMiefF1mn/v3k/G+ZZM3HXZ+jmiIt4poL5+Q7JItR3+AecN88HWIhztTXo75yjFv2BzqpsS3ue3CNhGloQK0/1RmECaj9DgsZeCHtSDLwKkTJnLXWNcCVwH7AAuBprfVcY0zcifUbY0y6XjYYInPsqbDnfngP/NZ1iI1rSYgmsLFPf9/zLs9bVpttTeacS/B+fGY+QVITK7ASgnjW7Vw/gPrSUTC6Oe/uKYGaNJXM/1wT6bkPBF01joyW1Lde+n0J9egxeQt9dHNekILliZOjYZqbbQ2hMEw1InTMJB/jJltE3DgFc9z4x1bjxjs3U5Bvpga1wx5OaBpHkDnhHDclwyYzC2YUVIGFrhQ1Z7lBPnaTzbGvv4RqGV/YzRjcdCNGRaMWwoLttxxYtgSmbORvD5W9txe190HYPye7ldTYFtSu++R812rHPVFfnOVC88LpGhrc8UcWulwSX/IQPJzj19jIUfmHWENjsqA3NOb6JVSmBjXreLw/3ute1ZZkRY4cFV0/bjxqE8+lDw+8CeWvjv42YPMhhgFjxqFqa8lceivjGutZsmih+/4/v4RlS7DPPu5Cb8NRRvG5ZUaORo1tifyeavoMMhfOgcaReFdeEL3WIHefZnbbB++9eZEO5Mz/O9sZd5D36fstQzV5GnZ+7KUYwX0Wa5VnLpzj3HKjmrBvvOQG1W22FTa4NIZQ0Mux0HcG5hlj3jbGdAN3AIcNWYmGCdU4ErXNjqhxWdccHDm6X6smsu+06ajwQIG4j64m5Ofe2rcggg6n4AUNmziLU40cTebQr6MG4GdTEybnR4ZC3mppaER99Zuofz+JzAXXRNPE89j/y6gvfMk14wMrcePNUZ8/lMx//cyFe0HESsp876eoHWMPnnDLIqmZGr+Y/XpmTjmfzH//PH/scS05Yc6VMfBDd3U5K2vm9qiGhui5h+QW0YTJru8kqUyBvzYsghBpmqsNN8kv+zd5ZOxDbw/qyG8VtIrCZI47PeeGUAcc7s51vJxB6yi4hrq7cj5+ldDhl3PbxIfpL1+Wr0sxCz1wb4U7AoPjJkU0jRyVD6sdMw61w+45w0OFO6D9loRqaCSz1/5k9jog/5uMHOVGDPvnTjU1U7v+VJTft6FGN6OmbEjm0CPzU3v451TtFGqFgrtHp8XcOjhXjGpqJvNFXViHcB9X3PUSNnSC+geCvktskF88r/jxA7fcZluTuex21Fbb5926wxyHPgUIxwgtAHZJSPcVrfVewBvA6caYgrgirfVsYDaAMYZstnTIXxK1tbWD3rcUnZ8/mJ5pG9E0fjzWWhYC1NSQzWZZPmIkHcDo0aMZ2c/x+2wvgV1Vt8WnqG9qYiUw6pBZjDhYs+Lqi2ne7xAyY8axbJ+D6Hz0AbJbbNWv4A6kzkubx9AFNDaPofnIZO9XEAxYs/40+j56n+ZtPk3jHp8DYElTM93AiEmTaT7huwCsWvwJK4Aa6zH2KkPvO2/QuNPuWM8jGPKx3k+uo3aDTXLfx0/IN1NXHusGYHQ/8zjh2ImxLS3UZbOwj4sC6Zu2AR3WMmqLragNXfjZbJa+7XakFWja75DI+e/dfCbhKORRm81kVJFz1du1MpIWoLm5mWXAiInrM3rGFgRjAFs22Ci/vOHGdB5/Bit/+yvGHTWb2myWVU3NBI4B1dfH+PHjWTJyVKR+Iw/5Gk2hsvScfh4rf3MDYz61A6qujs6zfwwqQ6OfZnFjI31A08T1CeJwRn5qBxpP/C41608lMyLqXuo78bu03z6H5n32p7NGUTNpKl3PPM6Izx1M7bQNWHX8GdRvvws1k6awEMiMa8Hzp3Bo3v8wOPDLNOy0JxlfgLomT2EpJIa0Nk2YhO3uYgXQuN3OjJkwASZMoOeS66mdtjEL/RDXlktuoO2kWYw9bBb1fr0WjWrCW7aEhm13Yuzh/xbJt79r27vlQffwrquHbBbueYJPvuw6GMdMnkL9jM1z11s8j66WrKtLbW0u0mT8pLzPe+W4FsJtijHjJ+TKu+Kgw1l1z21kp2/iDIu996d7wkSW/Fd+fqjG5jGM8dOvPOpbtN/2S1TjiMK6+N8/qXMjmpvGjh0yDavUo+I+4NfGmC6t9beAm4B944mMMXOAYLSObW0tPQNcEtlslsHuW5KNt4SNt6TLz1/NPhM1dTqtra14ftO+vb2dVf0c34ZCzbwzLmDV3F8DsKqzk85eD44/k8U9fdDaip01m4w+jra2/l/aPJA6e76/rtNaukvsY485BX55MSsmT6fdT9vnz9DYOWJUbv/cPFSdnSyta4TNPpVLD8CndmLZuAmRMLtIeXf/vNv/H9FRskuXt6PC6TJ1sN+X6Fy8mGw260JNMzV+XorMVXeysrYucv5tnd/03ftA1A57sGqzrekoUm+70nfP1NTmOjJXbLIlav/D6TroCLp78836tlUdznfatpC2latcRMWOe7I0UwOtrXihGQBtTzetra309YQ6R8dPouvQo3LXEgDNLXD8mbQt86NCNnF+3OBcZnyrrz3kR+icvgVdzS2wssP9xZk1m7blK2C73dz3g2e5eUJaW2Hnz7IKoK3NhXKOboJTj4SebtrXm4CaOp2VHV3Q4Y88HT3WtZp6ul2npT9nDEB7n4d9x01Y1zW2Jf/7jh0f+d2XNoyk5tq57oEUXD8TJ8OyJXS3TCy4jkte253J4ZPLe/tQbW2uc7Z5bEEeNpj9clRzLs49nMbzR7WqXT4Lm2/DspZJuWvRHqjJfOFw2pYszedXE21RdYXz2/uLriViKV6Xlgnw4XxWrFzFiN7eQWvY5MnFpw0oR9A/AKaFvk/11+UwxoTV6DrgJ1QJmZ0+M/CdamNRF4GbIiHWXWUypaf/HChBKGGRJmHk+BtvTs3FN0RXBj7pcXkLQo0c5XyVCZ1/mavvitYh7iePJI7VtYRrKTJSFQojWnADtzI/uxlGNZV2VQX7b7QpmeP+08Wb19ZFwvYyP7wK+96bKKXInPlj7Fuv5iKMVCi8Ve2wB/aBO53bLIg1Dtevv76KIhR0ikJ+QNxqosb5HXybb+Pm7p80rTBNdiLqC192Mfc1tahjT3P9AmPWg5nboRpHYB+6O7GPR+11QPEXxgSupBJRIWVRU+MG4vn9DEWjqILzX+yaCFqAdfW5UOYApVTh7xd318XuLxUPfY6hdvqMix4aSPjmAClH0J8GZmitp+OEfBYQOYNa6/WNMUEc2KFAPxOIpxkV+yxCbIqA3BwmlRbuovjl6yeaRenjCjuZAoL5awIBgHz0QcKUqvFO1sx3Liyed/zmqlBMbjzKo2i6pjGu1bXlti6ULz7JG85XH/jrVcv4gk6vXLpRTWS+/wu8k2fl6quax+Y76UrNgZ+UZ/CbNY11nzO3i4TGVoLMt86C5UuLhMG6uGsLsKSVzO77wu6hxvYWn3KzKCble/SJcPSJidvULp/FvvhMpC9i0Mzc3o3+7CeKBsgLcrF6Tt8cC278RznEBb2/aLGk4x1wuBsjsXuB86JilBR0Y0yv1vok4CGgBrjBGPOy1vqHwDPGmLnAKVrrQ4FeYDFwzJCVeDjZeHN49PeocOxrEvGOv0Dc4kPDh4rgeZM0GMIns18//dpBvPDYkKAHvtve5OZv5PD9dfoM0EIfCgbV6ipGYKX59VJf+YZ7SCxbgtr34AFnl+8UHU3m/F/ApIQBSauJahzR72R2uRG+g2hhFCOzy2exW3+66DQPA8pr9pmw4B1UqbeABX1SNbXOgIlNiKamTSfzv7/Jt4pKUV/vYuX7PDcHUKkXQseLU1uHOvCIAe0zUMryoRtjHgAeiK07L7R8DnBOZYu29pHZdW/splvmR1wWoWCisDVtoZc7eq3Y7pvOdCFyQTQH5EeAhn3Eg8k7UxMNGyzRTF3bUZkM6ohjcvHZqnGEm45isPkFIlFbWzD1wJpCjW1xkShbblfZfCsg5uA/kMpxQwVusNraogZM2WKOc8Oob57u3h381F/KcmmuaapmtsU1RSkxjxC4AeyadrmsHuroE1EHHhG1gAILvZ/3TJaV915fcDHGAUMYk7umyOx/eMXyUsEYgCGcwKkcMnsdMKzHrwiTp8FmW5E5ImFq3NUg1580QJfLmiD9d9NaSubsn+Tnzwgs9NW0nMvHP84gXmAPfsdjbO4RVVcPI0aiDv16kb3KzHvm9tRcO5e+4w91K2rS8ZBbU2SaxrhO7WFwRVUbqq6emjN/XDrhQPHj1wdi3a8pRNCHiMhw9n6iXIbm4LkDVzTbmtDLNiqXqVyCYUYc+BVWbbxlv/P7C8PMtI3d+4rL7Uxdg8hVswYI5jJRG2xaImWFjreb60Uvu/d+OBFLNEJm5ChUwuhHYe1BZTJkPntA4XsO1gLEPFoDqB33JLPZVqjmcaUTV+J40zcrGlq21hDEEqe8U1QQ1iZE0NcQa0rM00Lm3MuwLz0nrgVBqCAi6MKwoKZsGHn7uiAIq4+YR4IgCFWCCLogCEKVIIIuCIJQJYigC4IgVAki6IIgCFWCCLogCEKVIIIuCIJQJYigC4IgVAnK2spO4DQAhu3AgiAIKSdx6tbhtNDVYP+01s+uzv5p/JM6rxt/Uud1468CdU5EXC6CIAhVggi6IAhClZBWQZ8z3AUYBqTO6wZS53WDIanzcHaKCoIgCBUkrRa6IAiCEEMEXRAEoUpI3QsutNYHAJcDNcB1xpiLhrlIFUFrfQNwMLDQGLO1v2494DfARsC7gDbGLNFaK9w5OAhYBRxjjHluOMo9WLTW04CbgYm4MQlzjDGXV3mdG4HHgAbcvXenMeZ8rfV04A6gBXgWONoY0621bsCdox2ANuBrxph3h6Xwq4nWugZ4BvjAGHNwtddZa/0usALoA3qNMTuuiWs7VRa6f1FcCRwIzAS+rrWeObylqhg3AgfE1p0NPGyMmQE87H8HV/8Z/t9s4Oo1VMZK0gucYYyZCewKfNv/Lau5zl3AvsaYbYHtgAO01rsCFwM/N8ZsCiwBjvPTHwcs8df/3E+XVk4FXg19XxfqvI8xZjtjzI7+9yG/tlMl6MDOwDxjzNvGmG7cE/6wYS5TRTDGPAYsjq0+DLjJX74J+FJo/c3GGGuMeRIYq7Vef40UtEIYYz4KrBBjzArczT6F6q6zNca0+1/r/D8L7Avc6a+P1zk4F3cCn/OtuVShtZ4KfBG4zv+uqPI6F2HIr+20CfoU4P3Q9wX+umplojHmI3/5Y5x7AqrsPGitNwK2B/5BlddZa12jtX4eWAj8EXgLWGqM6fWThOuVq7O/fRnORZE2LgPOAjz/ewvVX2cL/J/W+lmt9Wx/3ZBf22kT9HUWY4ylCue/0VqPBu4CTjPGLA9vq8Y6G2P6jDHbAVNxLc4thrdEQ4vWOugXena4y7KG2dMY82mcO+XbWuu9whuH6tpOm6B/AEwLfZ/qr6tWPgmaXv7nQn99VZwHrXUdTsxvM8bc7a+u6joHGGOWAo8Cu+Ga2EGAQrheuTr728fgOgrTxB7AoX4n4R04V8vlVHedMcZ84H8uBO7BPbyH/NpOm6A/DczQWk/XWtcDs4C5w1ymoWQu8A1/+RvAvaH1/661Vn6n2rJQUy4V+H7R64FXjTGXhjZVc53Ha63H+ssjgP1wfQePAkf4yeJ1Ds7FEcAjvmWXGowx5xhjphpjNsLdr48YY46iiuustR6ltW4KloEvAC+xBq7tVIUtGmN6tdYnAQ/hwhZvMMa8PMzFqgha618DewNZrfUC4HzgIsBorY8D3gO0n/wBXIjTPFyY07FrvMCrzx7A0cCLvk8Z4HtUd53XB27yo7UygDHG3K+1fgW4Q2t9AfBP3IMO//MWrfU8XIf5rOEo9BDxXaq3zhOBe7TW4DT2dmPMg1rrpxnia1uG/guCIFQJaXO5CIIgCEUQQRcEQagSRNAFQRCqBBF0QRCEKkEEXRAEoUoQQRcEQagSRNAFQRCqhP8PiPj4cu2aQNYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(list1, list2):\n",
    "    correct = 0\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] == list2[i]:\n",
    "            correct += 1\n",
    "    return correct / len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 14.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.641875\n",
      "perc   pred   true  \n",
      "  0.59      1      1\n",
      "  0.96      1      0\n",
      "  0.21      0      0\n",
      "  0.54      1      0\n",
      "  0.96      1      1\n",
      "  0.52      1      0\n",
      "  0.32      0      0\n",
      "  0.61      1      0\n",
      "  0.96      1      1\n",
      "  0.64      1      1\n",
      "  0.54      1      0\n",
      "  0.55      1      1\n",
      "  0.55      1      1\n",
      "  0.52      1      1\n",
      "  0.26      0      1\n",
      "  0.26      0      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "lists1 = []\n",
    "lists2 = []\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "for epoch in trange(EPOCHS):\n",
    "\n",
    "    X, y = get_batch('test')\n",
    "\n",
    "    output, _ = model(X, 0)\n",
    "\n",
    "\n",
    "#     mean = output.mean()\n",
    "\n",
    "    outing = []\n",
    "\n",
    "    for outs in output:\n",
    "        if outs.item() >= 0.5:\n",
    "            outing.append(1)\n",
    "        else:\n",
    "            outing.append(0)\n",
    "\n",
    "    list1 = outing\n",
    "    lists1.append(list1)\n",
    "\n",
    "    list2 = y.tolist()\n",
    "    lists2.append(list2)\n",
    "    \n",
    "    accuracy_list.append(accuracy(list1, list2))\n",
    "        \n",
    "print(f'Accuracy = {sum(accuracy_list) / len(accuracy_list)}')\n",
    "\n",
    "print('{:6s} {:6s} {:6s}'.format('perc', 'pred', 'true'))\n",
    "for l1, l2, l3 in zip([round(num, 2) for num in output.view(-1).tolist()], list1, list2):\n",
    "    print(f'{l1:6.2f} {l2:6} {l3:6}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
