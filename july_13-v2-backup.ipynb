{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import html\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import sentencepiece as spm\n",
    "from llama import ModelArgs, Transformer, Tokenizer, LLaMA\n",
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 32  # how many independent sequences will we process in parallel?\n",
    "block_size = 1000  # what is the maximum context length for predictions?\n",
    "max_iters = 100\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 128\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.01\n",
    "# ------------\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "df = pd.read_csv('../data/opt_intelligence_test_data.csv')\n",
    "\n",
    "# remove NaN\n",
    "df = df.dropna(subset=['PL_DATE_OF_BIRTH'])\n",
    "\n",
    "# remove HTML characters\n",
    "df['O_BODY1'] = df['O_BODY1'].apply(html.unescape)\n",
    "df['O_NAME'] = df['O_NAME'].apply(html.unescape)\n",
    "df['O_HEADLINE1'] = df['O_HEADLINE1'].apply(html.unescape)\n",
    "df['O_DISPLAY_NAME'] = df['O_DISPLAY_NAME'].apply(html.unescape)\n",
    "\n",
    "# shuffle dem bitches\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = math.floor(df.shape[0]*.9)\n",
    "train_data = df.iloc[:n, :]\n",
    "val_data = df.iloc[n:, :]\n",
    "\n",
    "tokenizer = Tokenizer(model_path='tokenizer.model')\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    strings = []\n",
    "    optins = []\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    idx = torch.randperm(len(data))[:batch_size] # random number used as start index into dataset\n",
    "    for i in range(batch_size):\n",
    "        string_dict = data.iloc[idx[i].item()][:-1].to_dict() # turns row into dictionary cols=keys\n",
    "        string = ', '.join(f'{k}: {v}' for k, v in string_dict.items()) # creates string from row dict\n",
    "        encoded_string = torch.tensor(tokenizer.encode(string, bos=True, eos=False)) # encode string to tensor\n",
    "        full_tensor = torch.full((block_size,), 0) # create tensor as long as longest and fill with new token\n",
    "        full_tensor[:len(encoded_string)] = encoded_string # replace beginning of full tensor with original string tensor\n",
    "        encoded_string = full_tensor # encoded string with padding\n",
    "        strings.append(encoded_string) # add tensor to list of tensors\n",
    "        optin_dict = df.iloc[idx[i].item()][-1:].to_dict() # convert optin column to dict\n",
    "        optins.append(optin_dict['opted_in'.upper()]) # add optin value to list\n",
    "        \n",
    "    optins = torch.tensor(optins) # turn optins list to tensor\n",
    "    \n",
    "    x, y = torch.stack(strings), optins\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Optional, Tuple\n",
    "# from dataclasses import dataclass\n",
    "# import math\n",
    "\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 512\n",
    "    n_layers: int = 8\n",
    "    n_heads: int = 8\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    norm_eps: float = 1e-06\n",
    "    max_batch_size: int = 32\n",
    "    max_seq_len: int = 2048\n",
    "\n",
    "\n",
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight\n",
    "\n",
    "\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis\n",
    "\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "\n",
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cis: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "\n",
    "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
    "\n",
    "        self.cache_k = torch.zeros(\n",
    "            (args.max_batch_size, args.max_seq_len, self.n_heads, self.head_dim)\n",
    "        ).cuda()\n",
    "        self.cache_v = torch.zeros(\n",
    "            (args.max_batch_size, args.max_seq_len, self.n_heads, self.head_dim)\n",
    "        ).cuda()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        bsz, seqlen, _ = x.shape\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "\n",
    "        xq = xq.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n",
    "\n",
    "        self.cache_k = self.cache_k.to(xq)\n",
    "        self.cache_v = self.cache_v.to(xq)\n",
    "\n",
    "        self.cache_k[:bsz, start_pos : start_pos + seqlen] = xk\n",
    "        self.cache_v[:bsz, start_pos : start_pos + seqlen] = xv\n",
    "\n",
    "        keys = self.cache_k[:bsz, : start_pos + seqlen]\n",
    "        values = self.cache_v[:bsz, : start_pos + seqlen]\n",
    "\n",
    "        xq = xq.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        if mask is not None:\n",
    "            scores = scores + mask  # (bs, n_local_heads, slen, cache_len + slen)\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        output = torch.matmul(scores, values)  # (bs, n_local_heads, slen, head_dim)\n",
    "        output = output.transpose(\n",
    "            1, 2\n",
    "        ).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        return self.wo(output)\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        hidden_dim: int,\n",
    "        multiple_of: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(2 * hidden_dim / 3)\n",
    "        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
    "\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w2(F.silu(self.w1(x)) * self.w3(x))\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.attention = Attention(args)\n",
    "        self.feed_forward = FeedForward(\n",
    "            dim=args.dim, hidden_dim=4 * args.dim, multiple_of=args.multiple_of\n",
    "        )\n",
    "        self.layer_id = layer_id\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        h = x + self.attention.forward(self.attention_norm(x), start_pos, freqs_cis, mask)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, params: ModelArgs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = params\n",
    "        self.vocab_size = params.vocab_size\n",
    "        self.n_layers = params.n_layers\n",
    "\n",
    "        self.tok_embeddings = nn.Embedding(params.vocab_size, params.dim)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for layer_id in range(params.n_layers):\n",
    "            self.layers.append(TransformerBlock(layer_id, params))\n",
    "\n",
    "        self.norm = RMSNorm(params.dim, eps=params.norm_eps)\n",
    "        self.output = nn.Linear(params.dim, 1, bias=False)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(\n",
    "            self.params.dim // self.params.n_heads, self.params.max_seq_len * 2\n",
    "        )\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def forward(self, tokens: torch.Tensor, start_pos: int):\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        h = self.tok_embeddings(tokens)\n",
    "        self.freqs_cis = self.freqs_cis.to(h.device)\n",
    "        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]\n",
    "\n",
    "        mask = None\n",
    "        if seqlen > 1:\n",
    "            mask = torch.full((1, 1, seqlen, seqlen), float(\"-inf\"), device=tokens.device)\n",
    "            mask = torch.triu(mask, diagonal=start_pos + 1).type_as(h)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, start_pos, freqs_cis, mask)\n",
    "        h = self.norm(h)\n",
    "        output = self.output(h[:, -1, :])  # only compute last logits\n",
    "        preds = torch.sigmoid(output) # Apply sigmoid to obtain probabilities\n",
    "        return preds.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelArgs(dim=512, n_layers=8, n_heads=8, vocab_size=32000, multiple_of=256, norm_eps=1e-06, max_batch_size=32, max_seq_len=2048)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = ModelArgs(vocab_size=tokenizer.n_words)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.656192 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(args)\n",
    "model = model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,  2660,  4186,  ...,  7103,    -1,     2],\n",
      "        [    1, 21078, 30430,  ..., 29518,    -1,     2],\n",
      "        [    1, 28669, 10993,  ..., 13641,    -1,     2],\n",
      "        ...,\n",
      "        [    1,  8158, 12016,  ..., 24155,    -1,     2],\n",
      "        [    1, 11896,  5572,  ..., 10499,    -1,     2],\n",
      "        [    1, 31689,  8008,  ...,  5534,    -1,     2]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-1, device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.randint(0, args.vocab_size, (32, 1000)).to(device)\n",
    "input_tensor[:, 0:1] = 1\n",
    "input_tensor[:, -2:-1] = -1\n",
    "input_tensor[:, -1:] = 2\n",
    "print(input_tensor)\n",
    "input_tensor.shape\n",
    "input_tensor.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1, 16507, 29918,  ...,     0,     0,     2],\n",
      "        [    1, 16507, 29918,  ...,     0,     0,     2],\n",
      "        [    1, 16507, 29918,  ...,     0,     0,     2],\n",
      "        ...,\n",
      "        [    1, 16507, 29918,  ...,     0,     0,     2],\n",
      "        [    1, 16507, 29918,  ...,     0,     0,     2],\n",
      "        [    1, 16507, 29918,  ...,     0,     0,     2]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0, device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor, _ = get_batch('train')\n",
    "input_tensor[:, -1:] = 2\n",
    "print(input_tensor)\n",
    "input_tensor.shape\n",
    "input_tensor.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 4, 0, 6, 3],\n",
      "        [9, 8, 5, 7, 5],\n",
      "        [4, 1, 2, 5, 0]], device='cuda:0')\n",
      "\n",
      "input shape = torch.Size([3, 5])\n",
      "\n",
      "tensor([[0.3675],\n",
      "        [0.6468],\n",
      "        [0.6144]], device='cuda:0')\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "# ensure that the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# create a random input tensor of shape (batch_size, sequence_length)\n",
    "# input_tensor = torch.randint(0, args.vocab_size, (32, 1000)).to(device)\n",
    "input_tensor = torch.randint(0, 10, (3, 5)).to(device)\n",
    "# input_tensor, _ = get_batch('train')\n",
    "\n",
    "\n",
    "print(input_tensor)\n",
    "print()\n",
    "print('input shape = {}'.format(input_tensor.shape))\n",
    "print()\n",
    "\n",
    "# forward pass through the model\n",
    "output_tensor = model(input_tensor, start_pos=0)\n",
    "\n",
    "# let's print the output tensor\n",
    "print(output_tensor)\n",
    "print(output_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 1000\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=300)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
