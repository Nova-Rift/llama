{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import html\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import sentencepiece as spm\n",
    "from llama import Tokenizer\n",
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16  # how many independent sequences will we process in parallel?\n",
    "block_size = 1000  # what is the maximum context length for predictions?\n",
    "max_iters = 100\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 128\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.01\n",
    "# ------------\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "df = pd.read_csv('../data/opt_intelligence_test_data.csv')\n",
    "\n",
    "# remove NaN\n",
    "df = df.dropna(subset=['PL_DATE_OF_BIRTH'])\n",
    "\n",
    "# remove HTML characters\n",
    "df['O_BODY1'] = df['O_BODY1'].apply(html.unescape)\n",
    "df['O_NAME'] = df['O_NAME'].apply(html.unescape)\n",
    "df['O_HEADLINE1'] = df['O_HEADLINE1'].apply(html.unescape)\n",
    "df['O_DISPLAY_NAME'] = df['O_DISPLAY_NAME'].apply(html.unescape)\n",
    "\n",
    "# shuffle dem bitches\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = math.floor(df.shape[0]*.9)\n",
    "train_data = df.iloc[:n, :]\n",
    "val_data = df.iloc[n:, :]\n",
    "\n",
    "tokenizer = Tokenizer(model_path='tokenizer.model')\n",
    "\n",
    "def get_batch(split):\n",
    "    strings = []\n",
    "    optins = []\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    \n",
    "    # Separate positive and negative classes\n",
    "    df_positive = data[data.OPTED_IN == 1]\n",
    "    df_negative = data[data.OPTED_IN == 0]\n",
    "    \n",
    "    # Select half the batch size from each class\n",
    "    half_batch = batch_size // 2\n",
    "    idx_positive = torch.randperm(len(df_positive))[:half_batch]\n",
    "    idx_negative = torch.randperm(len(df_negative))[:half_batch] + len(df_positive)\n",
    "    \n",
    "    # Combine indices and shuffle\n",
    "    indices = torch.cat([idx_positive, idx_negative])\n",
    "    indices = indices[torch.randperm(len(indices))]\n",
    "\n",
    "    # Join positive and negative classes\n",
    "    df_combined = pd.concat([df_positive, df_negative])\n",
    "\n",
    "    for i in indices:\n",
    "        row = df_combined.iloc[i.item()]\n",
    "        string_dict = row[:-1].to_dict()  # turns row into dictionary cols=keys\n",
    "        string = ', '.join(f'{k}: {v}' for k, v in string_dict.items())  # creates string from row dict\n",
    "        encoded_string = torch.tensor(tokenizer.encode(string, bos=True, eos=False))  # encode string to tensor\n",
    "        full_tensor = torch.full((block_size,), 0)  # create tensor as long as longest and fill with new token\n",
    "        # using same token as <unk> 0\n",
    "        full_tensor[:len(encoded_string)] = encoded_string  # replace beginning of full tensor with original string tensor\n",
    "        encoded_string = full_tensor  # encoded string with padding\n",
    "        strings.append(encoded_string)  # add tensor to list of tensors\n",
    "        optin_dict = row[-1:].to_dict()  # convert optin column to dict\n",
    "        optins.append(optin_dict['opted_in'.upper()])  # add optin value to list\n",
    "        \n",
    "    optins = torch.tensor(optins)  # turn optins list to tensor\n",
    "    \n",
    "    x, y = torch.stack(strings), optins\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "# from typing import Optional, Tuple\n",
    "# from dataclasses import dataclass\n",
    "# import math\n",
    "\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 256\n",
    "    n_layers: int = 4\n",
    "    n_heads: int = 4\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    norm_eps: float = 1e-06\n",
    "    max_batch_size: int = 16\n",
    "    max_seq_len: int = 1024\n",
    "\n",
    "\n",
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight\n",
    "\n",
    "\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis\n",
    "\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "\n",
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cis: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "\n",
    "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        bsz, seqlen, _ = x.shape\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "\n",
    "        xq = xq.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n",
    "\n",
    "        keys = xk\n",
    "        values = xv\n",
    "\n",
    "        xq = xq.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        if mask is not None:\n",
    "            scores = scores + mask\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        output = torch.matmul(scores, values)\n",
    "        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        return self.wo(output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        hidden_dim: int,\n",
    "        multiple_of: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(2 * hidden_dim / 3)\n",
    "        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
    "\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w2(F.silu(self.w1(x)) * self.w3(x))\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.attention = Attention(args)\n",
    "        self.feed_forward = FeedForward(\n",
    "            dim=args.dim, hidden_dim=4 * args.dim, multiple_of=args.multiple_of\n",
    "        )\n",
    "        self.layer_id = layer_id\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        h = x + self.attention.forward(self.attention_norm(x), start_pos, freqs_cis, mask)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, params: ModelArgs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = params\n",
    "        self.vocab_size = params.vocab_size\n",
    "        self.n_layers = params.n_layers\n",
    "\n",
    "        self.tok_embeddings = nn.Embedding(params.vocab_size, params.dim)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for layer_id in range(params.n_layers):\n",
    "            self.layers.append(TransformerBlock(layer_id, params))\n",
    "\n",
    "        self.norm = RMSNorm(params.dim, eps=params.norm_eps)\n",
    "        self.output = nn.Linear(params.dim, 1, bias=False)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(\n",
    "            self.params.dim // self.params.n_heads, self.params.max_seq_len * 2\n",
    "        )\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, start_pos: int, targets=None):\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        h = self.tok_embeddings(tokens)\n",
    "        self.freqs_cis = self.freqs_cis.to(h.device)\n",
    "        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]\n",
    "\n",
    "        mask = None\n",
    "        if seqlen > 1:\n",
    "            mask = torch.full((1, 1, seqlen, seqlen), float(\"-inf\"), device=tokens.device)\n",
    "            mask = torch.triu(mask, diagonal=start_pos + 1).type_as(h)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, start_pos, freqs_cis, mask)\n",
    "        h = self.norm(h)\n",
    "        output = self.output(h[:, -1, :])  # only compute last logits\n",
    "        preds = torch.sigmoid(output) # Apply sigmoid to obtain probabilities\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.binary_cross_entropy(preds.view(-1), targets.float()) # Use BCE loss, ensure targets are float\n",
    "\n",
    "        return preds, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.602432 M parameters\n"
     ]
    }
   ],
   "source": [
    "args = ModelArgs(vocab_size=tokenizer.n_words)\n",
    "args\n",
    "\n",
    "model = Transformer(args)\n",
    "model = model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# Hyperparameters\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:17<00:00,  5.66it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "eval_num = 10\n",
    "epochs = 100\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "max_iters = epochs\n",
    "for iter in trange(max_iters):\n",
    "\n",
    "#     # every once in a while evaluate the loss on train and val sets\n",
    "#     if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "#         losses = estimate_loss()\n",
    "#         print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, 0, yb)\n",
    "    loss_list.append(loss.item())\n",
    "#     optimizer.zero_grad()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    \n",
    "#     if iter % eval_num == 0:\n",
    "#         total = sum(loss_list)\n",
    "#         loss_list = []\n",
    "#         avg = total / eval_num\n",
    "#         print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd583d16850>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(list1, list2):\n",
    "    correct = 0\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] == list2[i]:\n",
    "            correct += 1\n",
    "    return correct / len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 14.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.635625\n",
      "perc   pred   true  \n",
      "  0.38      0      0\n",
      "  0.43      0      0\n",
      "  0.40      0      0\n",
      "  0.81      1      1\n",
      "  0.38      0      1\n",
      "  0.37      0      0\n",
      "  0.48      0      0\n",
      "  0.71      1      1\n",
      "  0.41      0      0\n",
      "  0.44      0      1\n",
      "  0.41      0      0\n",
      "  0.43      0      1\n",
      "  0.81      1      1\n",
      "  0.58      1      1\n",
      "  0.42      0      1\n",
      "  0.39      0      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "lists1 = []\n",
    "lists2 = []\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "for epoch in trange(EPOCHS):\n",
    "\n",
    "    X, y = get_batch('test')\n",
    "\n",
    "    output, _ = model(X, 0)\n",
    "\n",
    "\n",
    "#     mean = output.mean()\n",
    "\n",
    "    outing = []\n",
    "\n",
    "    for outs in output:\n",
    "        if outs.item() >= 0.5:\n",
    "            outing.append(1)\n",
    "        else:\n",
    "            outing.append(0)\n",
    "\n",
    "    list1 = outing\n",
    "    lists1.append(list1)\n",
    "\n",
    "    list2 = y.tolist()\n",
    "    lists2.append(list2)\n",
    "    \n",
    "    accuracy_list.append(accuracy(list1, list2))\n",
    "        \n",
    "print(f'Accuracy = {sum(accuracy_list) / len(accuracy_list)}')\n",
    "\n",
    "print('{:6s} {:6s} {:6s}'.format('perc', 'pred', 'true'))\n",
    "for l1, l2, l3 in zip([round(num, 2) for num in output.view(-1).tolist()], list1, list2):\n",
    "    print(f'{l1:6.2f} {l2:6} {l3:6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=300)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
