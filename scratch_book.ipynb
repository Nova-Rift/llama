{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symmetric Weights:\n",
      " Parameter containing:\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.4000, 0.4000]], requires_grad=True)\n",
      "\n",
      "Asymmetric Weights:\n",
      " Parameter containing:\n",
      "tensor([[-0.2730, -0.5135],\n",
      "        [ 0.5311,  0.0217]], requires_grad=True)\n",
      "\n",
      "Output with Symmetric Weights:\n",
      " tensor([1.5000, 1.2000], grad_fn=<SqueezeBackward4>)\n",
      "\n",
      "Output with Asymmetric Weights:\n",
      " tensor([-1.2999,  0.5745], grad_fn=<SqueezeBackward4>)\n",
      "\n",
      "Output with Symmetric Weights:\n",
      " tensor([1.5030, 1.1970], grad_fn=<SqueezeBackward4>)\n",
      "\n",
      "Output with Asymmetric Weights:\n",
      " tensor([-1.2969,  0.5775], grad_fn=<SqueezeBackward4>)\n",
      "Symmetric Weights:\n",
      " Parameter containing:\n",
      "tensor([[0.6667, 0.6667],\n",
      "        [0.3333, 0.3333]], requires_grad=True)\n",
      "\n",
      "Asymmetric Weights:\n",
      " Parameter containing:\n",
      "tensor([[0.8116, 0.5941],\n",
      "        [0.6406, 0.1797]], requires_grad=True)\n",
      "\n",
      "Output with Symmetric Weights:\n",
      " tensor([2.0000, 1.0000], grad_fn=<SqueezeBackward4>)\n",
      "\n",
      "Output with Asymmetric Weights:\n",
      " tensor([1.9999, 1.0000], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a simple neural network class\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, symmetric_weights=False):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 2, bias=False)\n",
    "        \n",
    "        # If symmetric weights are desired, manually set them\n",
    "        if symmetric_weights:\n",
    "            with torch.no_grad():\n",
    "                self.fc1.weight[0].fill_(0.5)\n",
    "                self.fc1.weight[1].fill_(0.4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "# Create two networks, one with symmetric and one with asymmetric weights\n",
    "net_symmetric = SimpleNet(symmetric_weights=True)\n",
    "net_asymmetric = SimpleNet(symmetric_weights=False)\n",
    "\n",
    "# Print initial weights for comparison\n",
    "print(\"Symmetric Weights:\\n\", net_symmetric.fc1.weight)\n",
    "print(\"\\nAsymmetric Weights:\\n\", net_asymmetric.fc1.weight)\n",
    "\n",
    "# Define a simple input\n",
    "input = torch.tensor([1.0, 2.0])\n",
    "target = torch.tensor([2.0, 1.0])\n",
    "\n",
    "# Compare the outputs\n",
    "output_symmetric = net_symmetric(input)\n",
    "output_asymmetric = net_asymmetric(input)\n",
    "\n",
    "print(\"\\nOutput with Symmetric Weights:\\n\", output_symmetric)\n",
    "print(\"\\nOutput with Asymmetric Weights:\\n\", output_asymmetric)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(list(net_symmetric.parameters()) + list(net_asymmetric.parameters()), lr=1e-3)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    output_symmetric = net_symmetric(input)\n",
    "    output_asymmetric = net_asymmetric(input)\n",
    "\n",
    "    loss_symmetric = loss_fn(output_symmetric, target)\n",
    "    loss_asymmetric = loss_fn(output_asymmetric, target)\n",
    "\n",
    "    if epoch == 1:\n",
    "        print(\"\\nOutput with Symmetric Weights:\\n\", output_symmetric)\n",
    "        print(\"\\nOutput with Asymmetric Weights:\\n\", output_asymmetric)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss_symmetric.backward()\n",
    "    loss_asymmetric.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Compare the outputs\n",
    "output_symmetric = net_symmetric(input)\n",
    "output_asymmetric = net_asymmetric(input)\n",
    "\n",
    "# Print initial weights for comparison\n",
    "print(\"Symmetric Weights:\\n\", net_symmetric.fc1.weight)\n",
    "print(\"\\nAsymmetric Weights:\\n\", net_asymmetric.fc1.weight)\n",
    "\n",
    "print(\"\\nOutput with Symmetric Weights:\\n\", output_symmetric)\n",
    "print(\"\\nOutput with Asymmetric Weights:\\n\", output_asymmetric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symmetric Weights:\n",
      " Parameter containing:\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.4000, 0.4000]], requires_grad=True)\n",
      "\n",
      "Asymmetric Weights:\n",
      " Parameter containing:\n",
      "tensor([[0.1954, 0.0780],\n",
      "        [0.3082, 0.6438]], requires_grad=True)\n",
      "\n",
      "Epoch 1\n",
      "Output with Symmetric Weights: tensor([1.3557, 1.3503], grad_fn=<SqueezeBackward4>)\n",
      "Output with Asymmetric Weights: tensor([0.8707, 0.5941], grad_fn=<SqueezeBackward4>)\n",
      "\n",
      "Epoch 9999\n",
      "Output with Symmetric Weights: tensor([2.0000, 1.0000], grad_fn=<SqueezeBackward4>)\n",
      "Output with Asymmetric Weights: tensor([2.0000, 1.0000], grad_fn=<SqueezeBackward4>)\n",
      "\n",
      "Final Symmetric Weights:\n",
      " Parameter containing:\n",
      "tensor([[0.6063, 0.6063],\n",
      "        [0.5165, 0.5165]], requires_grad=True)\n",
      "\n",
      "Final Asymmetric Weights:\n",
      " Parameter containing:\n",
      "tensor([[0.4959, 0.3897],\n",
      "        [0.5046, 0.8083]], requires_grad=True)\n",
      "\n",
      "Final Output with Symmetric Weights:\n",
      " tensor([2.0000, 1.0000], grad_fn=<SqueezeBackward4>)\n",
      "\n",
      "Final Output with Asymmetric Weights:\n",
      " tensor([2.0000, 1.0000], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a more complex neural network class\n",
    "class ComplexNet(nn.Module):\n",
    "    def __init__(self, symmetric_weights=False):\n",
    "        super(ComplexNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 2, bias=False)\n",
    "        self.fc2 = nn.Linear(2, 2, bias=False)  # Additional layer\n",
    "\n",
    "        # If symmetric weights are desired, manually set them\n",
    "        if symmetric_weights:\n",
    "            with torch.no_grad():\n",
    "                self.fc1.weight[0].fill_(0.5)\n",
    "                self.fc1.weight[1].fill_(0.4)\n",
    "                self.fc2.weight.fill_(0.5)  # Set weights for the second layer as well\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))  # Adding non-linear activation function\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create two networks, one with symmetric and one with asymmetric weights\n",
    "net_symmetric = ComplexNet(symmetric_weights=True)\n",
    "net_asymmetric = ComplexNet(symmetric_weights=False)\n",
    "\n",
    "# Print initial weights for comparison\n",
    "print(\"Symmetric Weights:\\n\", net_symmetric.fc1.weight)\n",
    "print(\"\\nAsymmetric Weights:\\n\", net_asymmetric.fc1.weight)\n",
    "\n",
    "# Define a simple input and target\n",
    "input = torch.tensor([1.0, 2.0])\n",
    "target = torch.tensor([2.0, 1.0])\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = torch.optim.AdamW(list(net_symmetric.parameters()) + list(net_asymmetric.parameters()), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output_symmetric = net_symmetric(input)\n",
    "    output_asymmetric = net_asymmetric(input)\n",
    "\n",
    "    loss_symmetric = loss_fn(output_symmetric, target)\n",
    "    loss_asymmetric = loss_fn(output_asymmetric, target)\n",
    "\n",
    "    loss_symmetric.backward()\n",
    "    loss_asymmetric.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch in [1, epochs-1]:\n",
    "        print(f\"\\nEpoch {epoch}\")\n",
    "        print(\"Output with Symmetric Weights:\", output_symmetric)\n",
    "        print(\"Output with Asymmetric Weights:\", output_asymmetric)\n",
    "\n",
    "# Final weights and outputs\n",
    "print(\"\\nFinal Symmetric Weights:\\n\", net_symmetric.fc1.weight)\n",
    "print(\"\\nFinal Asymmetric Weights:\\n\", net_asymmetric.fc1.weight)\n",
    "\n",
    "print(\"\\nFinal Output with Symmetric Weights:\\n\", net_symmetric(input))\n",
    "print(\"\\nFinal Output with Asymmetric Weights:\\n\", net_asymmetric(input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([0., 0.])\n",
      "Symmetric Output: tensor([0.], grad_fn=<SqueezeBackward4>), Asymmetric Output: tensor([0.], grad_fn=<SqueezeBackward4>)\n",
      "Input: tensor([0., 1.])\n",
      "Symmetric Output: tensor([0.3332], grad_fn=<SqueezeBackward4>), Asymmetric Output: tensor([0.3332], grad_fn=<SqueezeBackward4>)\n",
      "Input: tensor([1., 0.])\n",
      "Symmetric Output: tensor([0.3332], grad_fn=<SqueezeBackward4>), Asymmetric Output: tensor([0.3332], grad_fn=<SqueezeBackward4>)\n",
      "Input: tensor([1., 1.])\n",
      "Symmetric Output: tensor([0.6663], grad_fn=<SqueezeBackward4>), Asymmetric Output: tensor([0.6663], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a neural network class with non-linear activation\n",
    "class XORNet(nn.Module):\n",
    "    def __init__(self, symmetric_weights=False):\n",
    "        super(XORNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 1, bias=False)\n",
    "\n",
    "        # If symmetric weights are desired, manually set them\n",
    "        if symmetric_weights:\n",
    "            with torch.no_grad():\n",
    "                self.fc1.weight.fill_(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "# XOR input and output pairs\n",
    "inputs = torch.tensor([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
    "targets = torch.tensor([[0.], [1.], [1.], [0.]])\n",
    "\n",
    "# Create two networks\n",
    "net_symmetric = XORNet(symmetric_weights=True)\n",
    "net_asymmetric = XORNet(symmetric_weights=False)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer_symmetric = torch.optim.Adam(net_symmetric.parameters(), lr=0.01)\n",
    "optimizer_asymmetric = torch.optim.Adam(net_asymmetric.parameters(), lr=0.01)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    for input, target in zip(inputs, targets):\n",
    "        optimizer_symmetric.zero_grad()\n",
    "        optimizer_asymmetric.zero_grad()\n",
    "\n",
    "        output_symmetric = net_symmetric(input)\n",
    "        output_asymmetric = net_asymmetric(input)\n",
    "\n",
    "        loss_symmetric = loss_fn(output_symmetric, target)\n",
    "        loss_asymmetric = loss_fn(output_asymmetric, target)\n",
    "\n",
    "        loss_symmetric.backward()\n",
    "        loss_asymmetric.backward()\n",
    "\n",
    "        optimizer_symmetric.step()\n",
    "        optimizer_asymmetric.step()\n",
    "\n",
    "# Testing the trained networks\n",
    "for input, target in zip(inputs, targets):\n",
    "    print(f\"Input: {input}\")\n",
    "    output_symmetric = net_symmetric(input)\n",
    "    output_asymmetric = net_asymmetric(input)\n",
    "    print(f\"Symmetric Output: {output_symmetric}, Asymmetric Output: {output_asymmetric}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
