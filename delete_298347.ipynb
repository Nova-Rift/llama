{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import html\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import sentencepiece as spm\n",
    "from llama import Tokenizer\n",
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16  # how many independent sequences will we process in parallel?\n",
    "block_size = 1000  # what is the maximum context length for predictions?\n",
    "max_iters = 100\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 128\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.01\n",
    "# ------------\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "df = pd.read_csv('../data/opt_intelligence_test_data.csv')\n",
    "\n",
    "# remove NaN\n",
    "df = df.dropna(subset=['PL_DATE_OF_BIRTH'])\n",
    "\n",
    "# remove HTML characters\n",
    "df['O_BODY1'] = df['O_BODY1'].apply(html.unescape)\n",
    "df['O_NAME'] = df['O_NAME'].apply(html.unescape)\n",
    "df['O_HEADLINE1'] = df['O_HEADLINE1'].apply(html.unescape)\n",
    "df['O_DISPLAY_NAME'] = df['O_DISPLAY_NAME'].apply(html.unescape)\n",
    "\n",
    "# shuffle dem bitches\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = math.floor(df.shape[0]*.9)\n",
    "train_data = df.iloc[:n, :]\n",
    "val_data = df.iloc[n:, :]\n",
    "\n",
    "tokenizer = Tokenizer(model_path='tokenizer.model')\n",
    "\n",
    "def get_batch(split):\n",
    "    strings = []\n",
    "    optins = []\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    \n",
    "    # Separate positive and negative classes\n",
    "    df_positive = data[data.OPTED_IN == 1]\n",
    "    df_negative = data[data.OPTED_IN == 0]\n",
    "    \n",
    "    # Select half the batch size from each class\n",
    "    half_batch = batch_size // 2\n",
    "    idx_positive = torch.randperm(len(df_positive))[:half_batch]\n",
    "    idx_negative = torch.randperm(len(df_negative))[:half_batch] + len(df_positive)\n",
    "    \n",
    "    # Combine indices and shuffle\n",
    "    indices = torch.cat([idx_positive, idx_negative])\n",
    "    indices = indices[torch.randperm(len(indices))]\n",
    "\n",
    "    # Join positive and negative classes\n",
    "    df_combined = pd.concat([df_positive, df_negative])\n",
    "\n",
    "    for i in indices:\n",
    "        row = df_combined.iloc[i.item()]\n",
    "        string_dict = row[:-1].to_dict()  # turns row into dictionary cols=keys\n",
    "        string = ', '.join(f'{k}: {v}' for k, v in string_dict.items())  # creates string from row dict\n",
    "        encoded_string = torch.tensor(tokenizer.encode(string, bos=True, eos=False))  # encode string to tensor\n",
    "        full_tensor = torch.full((block_size,), 0)  # create tensor as long as longest and fill with new token\n",
    "        # using same token as <unk> 0\n",
    "        full_tensor[:len(encoded_string)] = encoded_string  # replace beginning of full tensor with original string tensor\n",
    "        encoded_string = full_tensor  # encoded string with padding\n",
    "        strings.append(encoded_string)  # add tensor to list of tensors\n",
    "        optin_dict = row[-1:].to_dict()  # convert optin column to dict\n",
    "        optins.append(optin_dict['opted_in'.upper()])  # add optin value to list\n",
    "        \n",
    "    optins = torch.tensor(optins)  # turn optins list to tensor\n",
    "    \n",
    "    x, y = torch.stack(strings), optins\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "# from typing import Optional, Tuple\n",
    "# from dataclasses import dataclass\n",
    "# import math\n",
    "\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 256\n",
    "    n_layers: int = 4\n",
    "    n_heads: int = 4\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    norm_eps: float = 1e-06\n",
    "    max_batch_size: int = 16\n",
    "    max_seq_len: int = 1024\n",
    "\n",
    "\n",
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight\n",
    "\n",
    "\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis\n",
    "\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "\n",
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cis: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "\n",
    "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        bsz, seqlen, _ = x.shape\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "\n",
    "        xq = xq.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n",
    "\n",
    "        keys = xk\n",
    "        values = xv\n",
    "\n",
    "        xq = xq.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        if mask is not None:\n",
    "            scores = scores + mask\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        output = torch.matmul(scores, values)\n",
    "        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        return self.wo(output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        hidden_dim: int,\n",
    "        multiple_of: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(2 * hidden_dim / 3)\n",
    "        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
    "\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w2(F.silu(self.w1(x)) * self.w3(x))\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.attention = Attention(args)\n",
    "        self.feed_forward = FeedForward(\n",
    "            dim=args.dim, hidden_dim=4 * args.dim, multiple_of=args.multiple_of\n",
    "        )\n",
    "        self.layer_id = layer_id\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        h = x + self.attention.forward(self.attention_norm(x), start_pos, freqs_cis, mask)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, params: ModelArgs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = params\n",
    "        self.vocab_size = params.vocab_size\n",
    "        self.n_layers = params.n_layers\n",
    "\n",
    "        self.tok_embeddings = nn.Embedding(params.vocab_size, params.dim)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for layer_id in range(params.n_layers):\n",
    "            self.layers.append(TransformerBlock(layer_id, params))\n",
    "\n",
    "        self.norm = RMSNorm(params.dim, eps=params.norm_eps)\n",
    "        self.output = nn.Linear(params.dim, 1, bias=False)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(\n",
    "            self.params.dim // self.params.n_heads, self.params.max_seq_len * 2\n",
    "        )\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, start_pos: int, targets=None):\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        h = self.tok_embeddings(tokens)\n",
    "        self.freqs_cis = self.freqs_cis.to(h.device)\n",
    "        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]\n",
    "\n",
    "        mask = None\n",
    "        if seqlen > 1:\n",
    "            mask = torch.full((1, 1, seqlen, seqlen), float(\"-inf\"), device=tokens.device)\n",
    "            mask = torch.triu(mask, diagonal=start_pos + 1).type_as(h)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, start_pos, freqs_cis, mask)\n",
    "        h = self.norm(h)\n",
    "        output = self.output(h[:, -1, :])  # only compute last logits\n",
    "        preds = torch.sigmoid(output) # Apply sigmoid to obtain probabilities\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.binary_cross_entropy(preds.view(-1), targets.float()) # Use BCE loss, ensure targets are float\n",
    "\n",
    "        return preds, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.602432 M parameters\n"
     ]
    }
   ],
   "source": [
    "args = ModelArgs(vocab_size=tokenizer.n_words)\n",
    "args\n",
    "\n",
    "model = Transformer(args)\n",
    "model = model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# Hyperparameters\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:17<00:00,  5.61it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "eval_num = 10\n",
    "epochs = 100\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "max_iters = epochs\n",
    "for iter in trange(max_iters):\n",
    "\n",
    "#     # every once in a while evaluate the loss on train and val sets\n",
    "#     if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "#         losses = estimate_loss()\n",
    "#         print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, 0, yb)\n",
    "    loss_list.append(loss.item())\n",
    "#     optimizer.zero_grad()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    \n",
    "#     if iter % eval_num == 0:\n",
    "#         total = sum(loss_list)\n",
    "#         loss_list = []\n",
    "#         avg = total / eval_num\n",
    "#         print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f60cdb78430>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(list1, list2):\n",
    "    correct = 0\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] == list2[i]:\n",
    "            correct += 1\n",
    "    return correct / len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.636875\n",
      "perc   pred   true  \n",
      "  0.59      1      1\n",
      "  0.43      0      0\n",
      "  0.48      0      0\n",
      "  0.50      0      0\n",
      "  0.35      0      0\n",
      "  0.48      0      1\n",
      "  0.47      0      0\n",
      "  0.48      0      1\n",
      "  0.46      0      1\n",
      "  0.48      0      1\n",
      "  0.31      0      0\n",
      "  0.56      1      0\n",
      "  0.42      0      0\n",
      "  0.55      1      1\n",
      "  0.99      1      1\n",
      "  0.53      1      1\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "lists1 = []\n",
    "lists2 = []\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    X, y = get_batch('test')\n",
    "\n",
    "    output, _ = model(X, 0)\n",
    "\n",
    "\n",
    "#     mean = output.mean()\n",
    "\n",
    "    outing = []\n",
    "\n",
    "    for outs in output:\n",
    "        if outs.item() >= 0.5:\n",
    "            outing.append(1)\n",
    "        else:\n",
    "            outing.append(0)\n",
    "\n",
    "    list1 = outing\n",
    "    lists1.append(list1)\n",
    "\n",
    "    list2 = y.tolist()\n",
    "    lists2.append(list2)\n",
    "    \n",
    "    accuracy_list.append(accuracy(list1, list2))\n",
    "        \n",
    "print(f'Accuracy = {sum(accuracy_list) / len(accuracy_list)}')\n",
    "\n",
    "print('{:6s} {:6s} {:6s}'.format('perc', 'pred', 'true'))\n",
    "for l1, l2, l3 in zip([round(num, 2) for num in output.view(-1).tolist()], list1, list2):\n",
    "    print(f'{l1:6.2f} {l2:6} {l3:6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=300)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
