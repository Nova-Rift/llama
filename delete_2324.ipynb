{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import html\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import sentencepiece as spm\n",
    "from llama import Tokenizer\n",
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16  # how many independent sequences will we process in parallel?\n",
    "block_size = 1000  # what is the maximum context length for predictions?\n",
    "max_iters = 100\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 128\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.01\n",
    "# ------------\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "df = pd.read_csv('./opt_intelligence_test_data.csv')\n",
    "\n",
    "# remove NaN\n",
    "df = df.dropna(subset=['PL_DATE_OF_BIRTH'])\n",
    "\n",
    "# remove HTML characters\n",
    "df['O_BODY1'] = df['O_BODY1'].apply(html.unescape)\n",
    "df['O_NAME'] = df['O_NAME'].apply(html.unescape)\n",
    "df['O_HEADLINE1'] = df['O_HEADLINE1'].apply(html.unescape)\n",
    "df['O_DISPLAY_NAME'] = df['O_DISPLAY_NAME'].apply(html.unescape)\n",
    "\n",
    "# shuffle dem bitches\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = math.floor(df.shape[0]*.9)\n",
    "train_data = df.iloc[:n, :]\n",
    "val_data = df.iloc[n:, :]\n",
    "\n",
    "tokenizer = Tokenizer(model_path='tokenizer.model')\n",
    "\n",
    "def get_batch(split):\n",
    "    strings = []\n",
    "    optins = []\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    \n",
    "    # Separate positive and negative classes\n",
    "    df_positive = data[data.OPTED_IN == 1]\n",
    "    df_negative = data[data.OPTED_IN == 0]\n",
    "    \n",
    "    # Select half the batch size from each class\n",
    "    half_batch = batch_size // 2\n",
    "    idx_positive = torch.randperm(len(df_positive))[:half_batch]\n",
    "    idx_negative = torch.randperm(len(df_negative))[:half_batch] + len(df_positive)\n",
    "    \n",
    "    # Combine indices and shuffle\n",
    "    indices = torch.cat([idx_positive, idx_negative])\n",
    "    indices = indices[torch.randperm(len(indices))]\n",
    "\n",
    "    # Join positive and negative classes\n",
    "    df_combined = pd.concat([df_positive, df_negative])\n",
    "\n",
    "    for i in indices:\n",
    "        row = df_combined.iloc[i.item()]\n",
    "        string_dict = row[:-1].to_dict()  # turns row into dictionary cols=keys\n",
    "        string = ', '.join(f'{k}: {v}' for k, v in string_dict.items())  # creates string from row dict\n",
    "        encoded_string = torch.tensor(tokenizer.encode(string, bos=True, eos=False))  # encode string to tensor\n",
    "        full_tensor = torch.full((block_size,), 0)  # create tensor as long as longest and fill with new token\n",
    "        # using same token as <unk> 0\n",
    "        full_tensor[:len(encoded_string)] = encoded_string  # replace beginning of full tensor with original string tensor\n",
    "        encoded_string = full_tensor  # encoded string with padding\n",
    "        strings.append(encoded_string)  # add tensor to list of tensors\n",
    "        optin_dict = row[-1:].to_dict()  # convert optin column to dict\n",
    "        optins.append(optin_dict['opted_in'.upper()])  # add optin value to list\n",
    "        \n",
    "    optins = torch.tensor(optins)  # turn optins list to tensor\n",
    "    \n",
    "    x, y = torch.stack(strings), optins\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "# from typing import Optional, Tuple\n",
    "# from dataclasses import dataclass\n",
    "# import math\n",
    "\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 256\n",
    "    n_layers: int = 4\n",
    "    n_heads: int = 4\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    norm_eps: float = 1e-06\n",
    "    max_batch_size: int = 16\n",
    "    max_seq_len: int = 1024\n",
    "\n",
    "\n",
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight\n",
    "\n",
    "\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis\n",
    "\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "\n",
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cis: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "\n",
    "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        bsz, seqlen, _ = x.shape\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "\n",
    "        xq = xq.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n",
    "\n",
    "        keys = xk\n",
    "        values = xv\n",
    "\n",
    "        xq = xq.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        if mask is not None:\n",
    "            scores = scores + mask\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        output = torch.matmul(scores, values)\n",
    "        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        return self.wo(output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        hidden_dim: int,\n",
    "        multiple_of: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(2 * hidden_dim / 3)\n",
    "        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
    "\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w2(F.silu(self.w1(x)) * self.w3(x))\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.attention = Attention(args)\n",
    "        self.feed_forward = FeedForward(\n",
    "            dim=args.dim, hidden_dim=4 * args.dim, multiple_of=args.multiple_of\n",
    "        )\n",
    "        self.layer_id = layer_id\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        h = x + self.attention.forward(self.attention_norm(x), start_pos, freqs_cis, mask)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, params: ModelArgs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = params\n",
    "        self.vocab_size = params.vocab_size\n",
    "        self.n_layers = params.n_layers\n",
    "\n",
    "        self.tok_embeddings = nn.Embedding(params.vocab_size, params.dim)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for layer_id in range(params.n_layers):\n",
    "            self.layers.append(TransformerBlock(layer_id, params))\n",
    "\n",
    "        self.norm = RMSNorm(params.dim, eps=params.norm_eps)\n",
    "        self.output = nn.Linear(params.dim, 1, bias=False)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(\n",
    "            self.params.dim // self.params.n_heads, self.params.max_seq_len * 2\n",
    "        )\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, start_pos: int, targets=None):\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        h = self.tok_embeddings(tokens)\n",
    "        self.freqs_cis = self.freqs_cis.to(h.device)\n",
    "        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]\n",
    "\n",
    "        mask = None\n",
    "        if seqlen > 1:\n",
    "            mask = torch.full((1, 1, seqlen, seqlen), float(\"-inf\"), device=tokens.device)\n",
    "            mask = torch.triu(mask, diagonal=start_pos + 1).type_as(h)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, start_pos, freqs_cis, mask)\n",
    "        h = self.norm(h)\n",
    "        output = self.output(h[:, -1, :])  # only compute last logits\n",
    "        preds = torch.sigmoid(output) # Apply sigmoid to obtain probabilities\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.binary_cross_entropy(preds.view(-1), targets.float()) # Use BCE loss, ensure targets are float\n",
    "\n",
    "        return preds, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.602432 M parameters\n"
     ]
    }
   ],
   "source": [
    "args = ModelArgs(vocab_size=tokenizer.n_words)\n",
    "args\n",
    "\n",
    "model = Transformer(args)\n",
    "model = model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# Hyperparameters\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:18<00:00,  5.54it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "eval_num = 10\n",
    "epochs = 20\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "max_iters = epochs\n",
    "for iter in trange(max_iters):\n",
    "\n",
    "#     # every once in a while evaluate the loss on train and val sets\n",
    "#     if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "#         losses = estimate_loss()\n",
    "#         print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, 0, yb)\n",
    "    loss_list.append(loss.item())\n",
    "#     optimizer.zero_grad()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    \n",
    "#     if iter % eval_num == 0:\n",
    "#         total = sum(loss_list)\n",
    "#         loss_list = []\n",
    "#         avg = total / eval_num\n",
    "#         print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc2a27cab20>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(list1, list2):\n",
    "    correct = 0\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] == list2[i]:\n",
    "            correct += 1\n",
    "    return correct / len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 14.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6325\n",
      "perc   pred   true  \n",
      "  0.44      0      1\n",
      "  0.59      1      1\n",
      "  0.40      0      1\n",
      "  0.54      1      1\n",
      "  0.38      0      0\n",
      "  0.37      0      0\n",
      "  0.37      0      1\n",
      "  0.89      1      1\n",
      "  0.36      0      0\n",
      "  0.38      0      0\n",
      "  0.51      1      1\n",
      "  0.53      1      0\n",
      "  0.55      1      1\n",
      "  0.38      0      0\n",
      "  0.37      0      0\n",
      "  0.39      0      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "lists1 = []\n",
    "lists2 = []\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "for epoch in trange(EPOCHS):\n",
    "\n",
    "    X, y = get_batch('test')\n",
    "\n",
    "    output, _ = model(X, 0)\n",
    "\n",
    "\n",
    "#     mean = output.mean()\n",
    "\n",
    "    outing = []\n",
    "\n",
    "    for outs in output:\n",
    "        if outs.item() >= 0.5:\n",
    "            outing.append(1)\n",
    "        else:\n",
    "            outing.append(0)\n",
    "\n",
    "    list1 = outing\n",
    "    lists1.append(list1)\n",
    "\n",
    "    list2 = y.tolist()\n",
    "    lists2.append(list2)\n",
    "    \n",
    "    accuracy_list.append(accuracy(list1, list2))\n",
    "        \n",
    "print(f'Accuracy = {sum(accuracy_list) / len(accuracy_list)}')\n",
    "\n",
    "print('{:6s} {:6s} {:6s}'.format('perc', 'pred', 'true'))\n",
    "for l1, l2, l3 in zip([round(num, 2) for num in output.view(-1).tolist()], list1, list2):\n",
    "    print(f'{l1:6.2f} {l2:6} {l3:6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=300)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
