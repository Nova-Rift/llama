{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import html\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import sentencepiece as spm\n",
    "from llama import Tokenizer\n",
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16  # how many independent sequences will we process in parallel?\n",
    "block_size = 1000  # what is the maximum context length for predictions?\n",
    "max_iters = 100\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 128\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.01\n",
    "# ------------\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "df = pd.read_csv('../data/opt_intelligence_test_data.csv')\n",
    "\n",
    "# remove NaN\n",
    "df = df.dropna(subset=['PL_DATE_OF_BIRTH'])\n",
    "\n",
    "# remove HTML characters\n",
    "df['O_BODY1'] = df['O_BODY1'].apply(html.unescape)\n",
    "df['O_NAME'] = df['O_NAME'].apply(html.unescape)\n",
    "df['O_HEADLINE1'] = df['O_HEADLINE1'].apply(html.unescape)\n",
    "df['O_DISPLAY_NAME'] = df['O_DISPLAY_NAME'].apply(html.unescape)\n",
    "\n",
    "# shuffle dem bitches\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = math.floor(df.shape[0]*.9)\n",
    "train_data = df.iloc[:n, :]\n",
    "val_data = df.iloc[n:, :]\n",
    "\n",
    "tokenizer = Tokenizer(model_path='tokenizer.model')\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    strings = []\n",
    "    optins = []\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    \n",
    "    # Separate positive and negative classes\n",
    "    df_positive = data[data.OPTED_IN == 1]\n",
    "    df_negative = data[data.OPTED_IN == 0]\n",
    "    \n",
    "    # Select half the batch size from each class\n",
    "    half_batch = batch_size // 2\n",
    "    idx_positive = torch.randperm(len(df_positive))[:half_batch]\n",
    "    idx_negative = torch.randperm(len(df_negative))[:half_batch]\n",
    "    \n",
    "    for idx, df_class in zip([idx_positive, idx_negative], [df_positive, df_negative]):\n",
    "        for i in idx:\n",
    "            string_dict = df_class.iloc[i.item()][:-1].to_dict() # turns row into dictionary cols=keys\n",
    "            string = ', '.join(f'{k}: {v}' for k, v in string_dict.items()) # creates string from row dict\n",
    "            encoded_string = torch.tensor(tokenizer.encode(string, bos=True, eos=False)) # encode string to tensor\n",
    "            full_tensor = torch.full((block_size,), 0) # create tensor as long as longest and fill with new token\n",
    "            # using same token as <unk> 0\n",
    "            full_tensor[:len(encoded_string)] = encoded_string # replace beginning of full tensor with original string tensor\n",
    "            encoded_string = full_tensor # encoded string with padding\n",
    "            strings.append(encoded_string) # add tensor to list of tensors\n",
    "            optin_dict = df_class.iloc[i.item()][-1:].to_dict() # convert optin column to dict\n",
    "            optins.append(optin_dict['opted_in'.upper()]) # add optin value to list\n",
    "        \n",
    "    optins = torch.tensor(optins) # turn optins list to tensor\n",
    "    \n",
    "    x, y = torch.stack(strings), optins\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "# from typing import Optional, Tuple\n",
    "# from dataclasses import dataclass\n",
    "# import math\n",
    "\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 256\n",
    "    n_layers: int = 4\n",
    "    n_heads: int = 4\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    norm_eps: float = 1e-06\n",
    "    max_batch_size: int = 16\n",
    "    max_seq_len: int = 1024\n",
    "\n",
    "\n",
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight\n",
    "\n",
    "\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis\n",
    "\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "\n",
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cis: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "\n",
    "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        bsz, seqlen, _ = x.shape\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "\n",
    "        xq = xq.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n",
    "\n",
    "        keys = xk\n",
    "        values = xv\n",
    "\n",
    "        xq = xq.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        if mask is not None:\n",
    "            scores = scores + mask\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        output = torch.matmul(scores, values)\n",
    "        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        return self.wo(output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        hidden_dim: int,\n",
    "        multiple_of: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(2 * hidden_dim / 3)\n",
    "        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
    "\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w2(F.silu(self.w1(x)) * self.w3(x))\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.attention = Attention(args)\n",
    "        self.feed_forward = FeedForward(\n",
    "            dim=args.dim, hidden_dim=4 * args.dim, multiple_of=args.multiple_of\n",
    "        )\n",
    "        self.layer_id = layer_id\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        h = x + self.attention.forward(self.attention_norm(x), start_pos, freqs_cis, mask)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, params: ModelArgs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = params\n",
    "        self.vocab_size = params.vocab_size\n",
    "        self.n_layers = params.n_layers\n",
    "\n",
    "        self.tok_embeddings = nn.Embedding(params.vocab_size, params.dim)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for layer_id in range(params.n_layers):\n",
    "            self.layers.append(TransformerBlock(layer_id, params))\n",
    "\n",
    "        self.norm = RMSNorm(params.dim, eps=params.norm_eps)\n",
    "        self.output = nn.Linear(params.dim, 1, bias=False)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(\n",
    "            self.params.dim // self.params.n_heads, self.params.max_seq_len * 2\n",
    "        )\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, start_pos: int, targets=None):\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        h = self.tok_embeddings(tokens)\n",
    "        self.freqs_cis = self.freqs_cis.to(h.device)\n",
    "        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]\n",
    "\n",
    "        mask = None\n",
    "        if seqlen > 1:\n",
    "            mask = torch.full((1, 1, seqlen, seqlen), float(\"-inf\"), device=tokens.device)\n",
    "            mask = torch.triu(mask, diagonal=start_pos + 1).type_as(h)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, start_pos, freqs_cis, mask)\n",
    "        h = self.norm(h)\n",
    "        output = self.output(h[:, -1, :])  # only compute last logits\n",
    "        preds = torch.sigmoid(output) # Apply sigmoid to obtain probabilities\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.binary_cross_entropy(preds.view(-1), targets.float()) # Use BCE loss, ensure targets are float\n",
    "\n",
    "        return preds, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    1, 16507, 29918,  ...,     0,     0,     0],\n",
       "         [    1, 16507, 29918,  ...,     0,     0,     0],\n",
       "         [    1, 16507, 29918,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [    1, 16507, 29918,  ...,     0,     0,     0],\n",
       "         [    1, 16507, 29918,  ...,     0,     0,     0],\n",
       "         [    1, 16507, 29918,  ...,     0,     0,     0]], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.602432 M parameters\n"
     ]
    }
   ],
   "source": [
    "args = ModelArgs(vocab_size=tokenizer.n_words)\n",
    "args\n",
    "\n",
    "model = Transformer(args)\n",
    "model = model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# Hyperparameters\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:17<00:00,  5.67it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "eval_num = 10\n",
    "epochs = 100\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "max_iters = epochs\n",
    "for iter in trange(max_iters):\n",
    "\n",
    "#     # every once in a while evaluate the loss on train and val sets\n",
    "#     if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "#         losses = estimate_loss()\n",
    "#         print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, 0, yb)\n",
    "    loss_list.append(loss.item())\n",
    "#     optimizer.zero_grad()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    \n",
    "#     if iter % eval_num == 0:\n",
    "#         total = sum(loss_list)\n",
    "#         loss_list = []\n",
    "#         avg = total / eval_num\n",
    "#         print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd3158a4820>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(list1, list2):\n",
    "    correct = 0\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] == list2[i]:\n",
    "            correct += 1\n",
    "    return correct / len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.5\n",
      "perc   pred   true  \n",
      "  0.67      1      1\n",
      "  0.66      1      1\n",
      "  0.67      1      1\n",
      "  0.67      1      1\n",
      "  0.66      1      1\n",
      "  0.66      1      1\n",
      "  0.66      1      1\n",
      "  0.66      1      1\n",
      "  0.67      1      0\n",
      "  0.66      1      0\n",
      "  0.67      1      0\n",
      "  0.66      1      0\n",
      "  0.66      1      0\n",
      "  0.67      1      0\n",
      "  0.67      1      0\n",
      "  0.66      1      0\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "lists1 = []\n",
    "lists2 = []\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    X, y = get_batch('test')\n",
    "\n",
    "    output, _ = model(X, 0)\n",
    "\n",
    "\n",
    "#     mean = output.mean()\n",
    "\n",
    "    outing = []\n",
    "\n",
    "    for outs in output:\n",
    "        if outs.item() >= 0.5:\n",
    "            outing.append(1)\n",
    "        else:\n",
    "            outing.append(0)\n",
    "\n",
    "    list1 = outing\n",
    "    lists1.append(list1)\n",
    "\n",
    "    list2 = y.tolist()\n",
    "    lists2.append(list2)\n",
    "    \n",
    "    accuracy_list.append(accuracy(list1, list2))\n",
    "        \n",
    "print(f'Accuracy = {sum(accuracy_list) / len(accuracy_list)}')\n",
    "\n",
    "print('{:6s} {:6s} {:6s}'.format('perc', 'pred', 'true'))\n",
    "for l1, l2, l3 in zip([round(num, 2) for num in output.view(-1).tolist()], list1, list2):\n",
    "    print(f'{l1:6.2f} {l2:6} {l3:6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=300)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
