{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import html\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import sentencepiece as spm\n",
    "from llama import Tokenizer\n",
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "import random\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 1000  # what is the maximum context length for predictions?\n",
    "max_iters = 100\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 128\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.01\n",
    "# ------------\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "df = pd.read_csv('../data/opt_intelligence_test_data.csv')\n",
    "\n",
    "# remove NaN\n",
    "df = df.dropna(subset=['PL_DATE_OF_BIRTH'])\n",
    "\n",
    "# remove HTML characters\n",
    "df['O_BODY1'] = df['O_BODY1'].apply(html.unescape)\n",
    "df['O_NAME'] = df['O_NAME'].apply(html.unescape)\n",
    "df['O_HEADLINE1'] = df['O_HEADLINE1'].apply(html.unescape)\n",
    "df['O_DISPLAY_NAME'] = df['O_DISPLAY_NAME'].apply(html.unescape)\n",
    "\n",
    "# shuffle dem bitches\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = math.floor(df.shape[0]*.9)\n",
    "train_data = df.iloc[:n, :]\n",
    "val_data = df.iloc[n:, :]\n",
    "\n",
    "tokenizer = Tokenizer(model_path='tokenizer.model')\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    strings = []\n",
    "    optins = []\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    \n",
    "    # Separate positive and negative classes\n",
    "    df_positive = data[data.OPTED_IN == 1]\n",
    "    df_negative = data[data.OPTED_IN == 0]\n",
    "    \n",
    "    # Select half the batch size from each class\n",
    "    half_batch = batch_size // 2\n",
    "    idx_positive = torch.randperm(len(df_positive))[:half_batch]\n",
    "    idx_negative = torch.randperm(len(df_negative))[:half_batch]\n",
    "\n",
    "    for idx, df_class in zip([idx_positive, idx_negative], [df_positive, df_negative]):\n",
    "        for i in idx:\n",
    "            string_dict = df_class.iloc[i.item()][:-1].to_dict() # turns row into dictionary cols=keys\n",
    "            string = ', '.join(f'{k}: {v}' for k, v in string_dict.items()) # creates string from row dict\n",
    "            encoded_string = torch.tensor(tokenizer.encode(string, bos=True, eos=False)) # encode string to tensor\n",
    "            full_tensor = torch.full((block_size,), 0) # create tensor as long as longest and fill with new token\n",
    "            # using same token as <unk> 0\n",
    "            full_tensor[:len(encoded_string)] = encoded_string # replace beginning of full tensor with original string tensor\n",
    "            encoded_string = full_tensor # encoded string with padding\n",
    "            strings.append(encoded_string) # add tensor to list of tensors\n",
    "            optin_dict = df_class.iloc[i.item()][-1:].to_dict() # convert optin column to dict\n",
    "            optins.append(optin_dict['opted_in'.upper()]) # add optin value to list\n",
    "\n",
    "    # Turn lists into tensors\n",
    "    strings_tensor = torch.stack(strings)\n",
    "    optins_tensor = torch.tensor(optins)\n",
    "\n",
    "    # Concatenate positive and negative examples, then randomize the whole batch\n",
    "    combined = list(zip(strings_tensor, optins_tensor))\n",
    "    random.shuffle(combined)\n",
    "    x, y = zip(*combined)\n",
    "\n",
    "    x, y = torch.stack(x), torch.tensor(y)\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "get_batch('train')\n",
    "\n",
    "# from typing import Optional, Tuple\n",
    "# from dataclasses import dataclass\n",
    "# import math\n",
    "\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 256\n",
    "    n_layers: int = 4\n",
    "    n_heads: int = 4\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    norm_eps: float = 1e-06\n",
    "    max_batch_size: int = 16\n",
    "    max_seq_len: int = 1024\n",
    "\n",
    "\n",
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight\n",
    "\n",
    "\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis\n",
    "\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "\n",
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cis: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "\n",
    "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        bsz, seqlen, _ = x.shape\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "\n",
    "        xq = xq.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n",
    "\n",
    "        keys = xk\n",
    "        values = xv\n",
    "\n",
    "        xq = xq.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        if mask is not None:\n",
    "            scores = scores + mask\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        output = torch.matmul(scores, values)\n",
    "        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        return self.wo(output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        hidden_dim: int,\n",
    "        multiple_of: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(2 * hidden_dim / 3)\n",
    "        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
    "\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w2(F.silu(self.w1(x)) * self.w3(x))\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.attention = Attention(args)\n",
    "        self.feed_forward = FeedForward(\n",
    "            dim=args.dim, hidden_dim=4 * args.dim, multiple_of=args.multiple_of\n",
    "        )\n",
    "        self.layer_id = layer_id\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        h = x + self.attention.forward(self.attention_norm(x), start_pos, freqs_cis, mask)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, params: ModelArgs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = params\n",
    "        self.vocab_size = params.vocab_size\n",
    "        self.n_layers = params.n_layers\n",
    "\n",
    "        self.tok_embeddings = nn.Embedding(params.vocab_size, params.dim)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for layer_id in range(params.n_layers):\n",
    "            self.layers.append(TransformerBlock(layer_id, params))\n",
    "\n",
    "        self.norm = RMSNorm(params.dim, eps=params.norm_eps)\n",
    "        self.output = nn.Linear(params.dim, 1, bias=False)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(\n",
    "            self.params.dim // self.params.n_heads, self.params.max_seq_len * 2\n",
    "        )\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, start_pos: int, targets=None):\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        h = self.tok_embeddings(tokens)\n",
    "        self.freqs_cis = self.freqs_cis.to(h.device)\n",
    "        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]\n",
    "\n",
    "        mask = None\n",
    "        if seqlen > 1:\n",
    "            mask = torch.full((1, 1, seqlen, seqlen), float(\"-inf\"), device=tokens.device)\n",
    "            mask = torch.triu(mask, diagonal=start_pos + 1).type_as(h)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, start_pos, freqs_cis, mask)\n",
    "        h = self.norm(h)\n",
    "        output = self.output(h[:, -1, :])  # only compute last logits\n",
    "        preds = torch.sigmoid(output) # Apply sigmoid to obtain probabilities\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.binary_cross_entropy(preds.view(-1), targets.float()) # Use BCE loss, ensure targets are float\n",
    "\n",
    "        return preds, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.602432 M parameters\n"
     ]
    }
   ],
   "source": [
    "args = ModelArgs(vocab_size=tokenizer.n_words)\n",
    "args\n",
    "\n",
    "model = Transformer(args)\n",
    "model = model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# Hyperparameters\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:17<00:00,  5.70it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "eval_num = 10\n",
    "epochs = 100\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "max_iters = epochs\n",
    "for iter in trange(max_iters):\n",
    "\n",
    "#     # every once in a while evaluate the loss on train and val sets\n",
    "#     if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "#         losses = estimate_loss()\n",
    "#         print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, 0, yb)\n",
    "    loss_list.append(loss.item())\n",
    "#     optimizer.zero_grad()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    \n",
    "#     if iter % eval_num == 0:\n",
    "#         total = sum(loss_list)\n",
    "#         loss_list = []\n",
    "#         avg = total / eval_num\n",
    "#         print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff0401ee880>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(list1, list2):\n",
    "    correct = 0\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] == list2[i]:\n",
    "            correct += 1\n",
    "    return correct / len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output = [0.69, 0.69, 0.54, 0.54, 0.54, 0.54, 0.51, 0.51, 0.49, 0.47, 0.47, 0.47, 0.45, 0.45, 0.41, 0.41]\n",
      "list1 = [0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0]\n",
      "list2 = [0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1]\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "output = [0.81, 0.62, 0.57, 0.56, 0.5, 0.5, 0.48, 0.48, 0.48, 0.46, 0.43, 0.42, 0.42, 0.41, 0.41, 0.41]\n",
      "list1 = [0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
      "list2 = [0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0]\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "output = [0.81, 0.81, 0.81, 0.8, 0.55, 0.53, 0.51, 0.48, 0.47, 0.47, 0.46, 0.46, 0.46, 0.45, 0.42, 0.38]\n",
      "list1 = [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
      "list2 = [0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1]\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "output = [0.8, 0.8, 0.69, 0.69, 0.62, 0.54, 0.5, 0.49, 0.48, 0.47, 0.46, 0.45, 0.44, 0.4, 0.4, 0.39]\n",
      "list1 = [1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "list2 = [1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0]\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "output = [0.81, 0.8, 0.6, 0.57, 0.55, 0.53, 0.51, 0.49, 0.47, 0.47, 0.46, 0.45, 0.45, 0.44, 0.42, 0.42]\n",
      "list1 = [0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0]\n",
      "list2 = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1]\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "output = [0.69, 0.64, 0.54, 0.52, 0.49, 0.49, 0.48, 0.48, 0.47, 0.46, 0.46, 0.46, 0.45, 0.43, 0.42, 0.42]\n",
      "list1 = [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0]\n",
      "list2 = [0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0]\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "output = [0.81, 0.81, 0.69, 0.63, 0.61, 0.58, 0.57, 0.54, 0.51, 0.5, 0.46, 0.46, 0.46, 0.43, 0.4, 0.39]\n",
      "list1 = [1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1]\n",
      "list2 = [1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1]\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "output = [0.57, 0.57, 0.57, 0.54, 0.54, 0.54, 0.51, 0.51, 0.47, 0.47, 0.45, 0.44, 0.42, 0.42, 0.41, 0.4]\n",
      "list1 = [0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0]\n",
      "list2 = [1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1]\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "output = [0.81, 0.81, 0.81, 0.61, 0.51, 0.49, 0.48, 0.46, 0.45, 0.41, 0.41, 0.41, 0.4, 0.4, 0.39, 0.38]\n",
      "list1 = [0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "list2 = [0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0]\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "output = [0.81, 0.8, 0.57, 0.54, 0.54, 0.54, 0.53, 0.49, 0.48, 0.48, 0.47, 0.46, 0.42, 0.41, 0.41, 0.38]\n",
      "list1 = [1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1]\n",
      "list2 = [0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1]\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "output = [0.81, 0.81, 0.57, 0.53, 0.49, 0.48, 0.47, 0.47, 0.47, 0.47, 0.46, 0.46, 0.46, 0.45, 0.44, 0.39]\n",
      "list1 = [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]\n",
      "list2 = [0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0]\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "output = [0.69, 0.62, 0.57, 0.56, 0.54, 0.5, 0.49, 0.49, 0.49, 0.48, 0.47, 0.46, 0.45, 0.42, 0.41, 0.41]\n",
      "list1 = [0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0]\n",
      "list2 = [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "output = [0.7, 0.69, 0.69, 0.68, 0.55, 0.54, 0.53, 0.51, 0.48, 0.47, 0.47, 0.44, 0.42, 0.41, 0.4, 0.39]\n",
      "list1 = [0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0]\n",
      "list2 = [1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0]\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "output = [0.8, 0.68, 0.64, 0.59, 0.56, 0.51, 0.51, 0.51, 0.5, 0.49, 0.49, 0.47, 0.46, 0.46, 0.45, 0.45]\n",
      "list1 = [0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1]\n",
      "list2 = [0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1]\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "output = [0.81, 0.81, 0.63, 0.55, 0.54, 0.52, 0.51, 0.48, 0.48, 0.46, 0.46, 0.44, 0.42, 0.41, 0.41, 0.39]\n",
      "list1 = [1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1]\n",
      "list2 = [1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1]\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "output = [0.81, 0.81, 0.8, 0.56, 0.55, 0.51, 0.5, 0.47, 0.45, 0.45, 0.45, 0.45, 0.42, 0.42, 0.42, 0.41]\n",
      "list1 = [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0]\n",
      "list2 = [1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0]\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "output = [0.81, 0.81, 0.61, 0.58, 0.57, 0.57, 0.53, 0.52, 0.51, 0.5, 0.48, 0.47, 0.46, 0.46, 0.45, 0.39]\n",
      "list1 = [1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "list2 = [0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0]\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "output = [0.81, 0.69, 0.69, 0.63, 0.62, 0.57, 0.55, 0.51, 0.51, 0.48, 0.48, 0.44, 0.44, 0.43, 0.42, 0.42]\n",
      "list1 = [0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1]\n",
      "list2 = [0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1]\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "output = [0.64, 0.61, 0.58, 0.51, 0.49, 0.48, 0.47, 0.47, 0.47, 0.46, 0.44, 0.43, 0.42, 0.41, 0.41, 0.4]\n",
      "list1 = [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n",
      "list2 = [1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0]\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "output = [0.81, 0.81, 0.69, 0.67, 0.6, 0.57, 0.55, 0.54, 0.48, 0.47, 0.45, 0.42, 0.42, 0.41, 0.41, 0.39]\n",
      "list1 = [1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "list2 = [1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0]\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "0.665625\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "lists1 = []\n",
    "lists2 = []\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    X, y = get_batch('test')\n",
    "    \n",
    "    \n",
    "\n",
    "    output, _ = model(X, 0)\n",
    "    output\n",
    "\n",
    "    # Assuming output is a PyTorch tensor\n",
    "    output_sorted = output.tolist()\n",
    "\n",
    "    # Flatten the list if it's a list of lists\n",
    "    output_sorted = [item for sublist in output_sorted for item in sublist]\n",
    "\n",
    "    # Round each number in the list\n",
    "    output_sorted = [round(num, 2) for num in output_sorted]\n",
    "\n",
    "    # Sort the list\n",
    "    output_sorted.sort(reverse=True)\n",
    "\n",
    "    # Print the list\n",
    "    print('output = {}'.format(output_sorted))\n",
    "    \n",
    "    mean = output.mean()\n",
    "\n",
    "    outing = []\n",
    "\n",
    "    for outs in output:\n",
    "        if outs.item() >= mean:\n",
    "            outing.append(1)\n",
    "        else:\n",
    "            outing.append(0)\n",
    "\n",
    "    list1 = outing\n",
    "    print('list1 = {}'.format(list1))\n",
    "    lists1.append(list1)\n",
    "\n",
    "    list2 = y.tolist()\n",
    "    print('list2 = {}'.format(list2))\n",
    "    lists2.append(list2)\n",
    "    \n",
    "    print()\n",
    "    print('------------------------------------------')\n",
    "    print()\n",
    "    accuracy_list.append(accuracy(list1, list2))\n",
    "    \n",
    "print(sum(accuracy_list) / len(accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=300)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
