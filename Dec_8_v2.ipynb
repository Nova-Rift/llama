{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import html\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import sentencepiece as spm\n",
    "from llama import Tokenizer\n",
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16  # how many independent sequences will we process in parallel?\n",
    "block_size = 1000  # what is the maximum context length for predictions?\n",
    "max_iters = 100\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 128\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.01\n",
    "# ------------\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "df = pd.read_csv('./opt_intelligence_test_data.csv')\n",
    "\n",
    "# remove NaN\n",
    "df = df.dropna(subset=['PL_DATE_OF_BIRTH'])\n",
    "\n",
    "# remove HTML characters\n",
    "df['O_BODY1'] = df['O_BODY1'].apply(html.unescape)\n",
    "df['O_NAME'] = df['O_NAME'].apply(html.unescape)\n",
    "df['O_HEADLINE1'] = df['O_HEADLINE1'].apply(html.unescape)\n",
    "df['O_DISPLAY_NAME'] = df['O_DISPLAY_NAME'].apply(html.unescape)\n",
    "\n",
    "# shuffle dem bitches\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n = math.floor(df.shape[0]*.9)\n",
    "train_data = df.iloc[:n, :]\n",
    "val_data = df.iloc[n:, :]\n",
    "\n",
    "tokenizer = Tokenizer(model_path='tokenizer.model')\n",
    "\n",
    "def get_batch(split):\n",
    "    strings = []\n",
    "    optins = []\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    \n",
    "    # Separate positive and negative classes\n",
    "    df_positive = data[data.OPTED_IN == 1]\n",
    "    df_negative = data[data.OPTED_IN == 0]\n",
    "    \n",
    "    # Select half the batch size from each class\n",
    "    half_batch = batch_size // 2\n",
    "    idx_positive = torch.randperm(len(df_positive))[:half_batch]\n",
    "    idx_negative = torch.randperm(len(df_negative))[:half_batch] + len(df_positive)\n",
    "    \n",
    "    # Combine indices and shuffle\n",
    "    indices = torch.cat([idx_positive, idx_negative])\n",
    "    indices = indices[torch.randperm(len(indices))]\n",
    "\n",
    "    # Join positive and negative classes\n",
    "    df_combined = pd.concat([df_positive, df_negative])\n",
    "\n",
    "    for i in indices:\n",
    "        row = df_combined.iloc[i.item()]\n",
    "        string_dict = row[:-1].to_dict()  # turns row into dictionary cols=keys\n",
    "        string = ', '.join(f'{k}: {v}' for k, v in string_dict.items())  # creates string from row dict\n",
    "        encoded_string = torch.tensor(tokenizer.encode(string, bos=True, eos=False))  # encode string to tensor\n",
    "        full_tensor = torch.full((block_size,), 0)  # create tensor as long as longest and fill with new token\n",
    "        # using same token as <unk> 0\n",
    "        full_tensor[:len(encoded_string)] = encoded_string  # replace beginning of full tensor with original string tensor\n",
    "        encoded_string = full_tensor  # encoded string with padding\n",
    "        strings.append(encoded_string)  # add tensor to list of tensors\n",
    "        optin_dict = row[-1:].to_dict()  # convert optin column to dict\n",
    "        optins.append(optin_dict['opted_in'.upper()])  # add optin value to list\n",
    "        \n",
    "    optins = torch.tensor(optins)  # turn optins list to tensor\n",
    "    \n",
    "    x, y = torch.stack(strings), optins\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "# from typing import Optional, Tuple\n",
    "# from dataclasses import dataclass\n",
    "# import math\n",
    "\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 256\n",
    "    n_layers: int = 4\n",
    "    n_heads: int = 4\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "    multiple_of: int = 256  # make SwiGLU hidden layer size multiple of large power of 2\n",
    "    norm_eps: float = 1e-06\n",
    "    max_batch_size: int = 16\n",
    "    max_seq_len: int = 1024\n",
    "\n",
    "\n",
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight\n",
    "\n",
    "\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis\n",
    "\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "\n",
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cis: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "\n",
    "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        bsz, seqlen, _ = x.shape\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "\n",
    "        xq = xq.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
    "\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)\n",
    "\n",
    "        keys = xk\n",
    "        values = xv\n",
    "\n",
    "        xq = xq.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "        if mask is not None:\n",
    "            scores = scores + mask\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "        output = torch.matmul(scores, values)\n",
    "        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        return self.wo(output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        hidden_dim: int,\n",
    "        multiple_of: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(2 * hidden_dim / 3)\n",
    "        hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
    "\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w2(F.silu(self.w1(x)) * self.w3(x))\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.dim = args.dim\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        self.attention = Attention(args)\n",
    "        self.feed_forward = FeedForward(\n",
    "            dim=args.dim, hidden_dim=4 * args.dim, multiple_of=args.multiple_of\n",
    "        )\n",
    "        self.layer_id = layer_id\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "        h = x + self.attention.forward(self.attention_norm(x), start_pos, freqs_cis, mask)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, params: ModelArgs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = params\n",
    "        self.vocab_size = params.vocab_size\n",
    "        self.n_layers = params.n_layers\n",
    "\n",
    "        self.tok_embeddings = nn.Embedding(params.vocab_size, params.dim)\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for layer_id in range(params.n_layers):\n",
    "            self.layers.append(TransformerBlock(layer_id, params))\n",
    "\n",
    "        self.norm = RMSNorm(params.dim, eps=params.norm_eps)\n",
    "        self.output = nn.Linear(params.dim, 1, bias=False)\n",
    "\n",
    "        self.freqs_cis = precompute_freqs_cis(\n",
    "            self.params.dim // self.params.n_heads, self.params.max_seq_len * 2\n",
    "        )\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, start_pos: int, targets=None):\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        h = self.tok_embeddings(tokens)\n",
    "        self.freqs_cis = self.freqs_cis.to(h.device)\n",
    "        freqs_cis = self.freqs_cis[start_pos : start_pos + seqlen]\n",
    "\n",
    "        mask = None\n",
    "        if seqlen > 1:\n",
    "            mask = torch.full((1, 1, seqlen, seqlen), float(\"-inf\"), device=tokens.device)\n",
    "            mask = torch.triu(mask, diagonal=start_pos + 1).type_as(h)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, start_pos, freqs_cis, mask)\n",
    "        h = self.norm(h)\n",
    "        output = self.output(h[:, -1, :])  # only compute last logits\n",
    "        preds = torch.sigmoid(output) # Apply sigmoid to obtain probabilities\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.binary_cross_entropy(preds.view(-1), targets.float()) # Use BCE loss, ensure targets are float\n",
    "\n",
    "        return preds, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.602432 M parameters\n"
     ]
    }
   ],
   "source": [
    "args = ModelArgs(vocab_size=tokenizer.n_words)\n",
    "args\n",
    "\n",
    "model = Transformer(args)\n",
    "model = model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# Hyperparameters\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "\n",
    "# Set up the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:18<00:00,  5.44it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "eval_num = 10\n",
    "epochs = 100\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "max_iters = epochs\n",
    "for iter in trange(max_iters):\n",
    "\n",
    "#     # every once in a while evaluate the loss on train and val sets\n",
    "#     if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "#         losses = estimate_loss()\n",
    "#         print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, 0, yb)\n",
    "    loss_list.append(loss.item())\n",
    "#     optimizer.zero_grad()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    \n",
    "#     if iter % eval_num == 0:\n",
    "#         total = sum(loss_list)\n",
    "#         loss_list = []\n",
    "#         avg = total / eval_num\n",
    "#         print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6d449357c0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(list1, list2):\n",
    "    correct = 0\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] == list2[i]:\n",
    "            correct += 1\n",
    "    return correct / len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 14.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.609375\n",
      "perc   pred   true  \n",
      "  0.60      1      1\n",
      "  0.43      0      1\n",
      "  0.27      0      1\n",
      "  0.42      0      1\n",
      "  0.29      0      0\n",
      "  0.23      0      0\n",
      "  0.44      0      1\n",
      "  0.29      0      1\n",
      "  0.33      0      0\n",
      "  0.23      0      0\n",
      "  0.37      0      1\n",
      "  0.29      0      0\n",
      "  0.81      1      1\n",
      "  0.42      0      0\n",
      "  0.22      0      0\n",
      "  0.40      0      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "lists1 = []\n",
    "lists2 = []\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "for epoch in trange(EPOCHS):\n",
    "\n",
    "    X, y = get_batch('test')\n",
    "\n",
    "    output, _ = model(X, 0)\n",
    "\n",
    "\n",
    "#     mean = output.mean()\n",
    "\n",
    "    outing = []\n",
    "\n",
    "    for outs in output:\n",
    "        if outs.item() >= 0.5:\n",
    "            outing.append(1)\n",
    "        else:\n",
    "            outing.append(0)\n",
    "\n",
    "    list1 = outing\n",
    "    lists1.append(list1)\n",
    "\n",
    "    list2 = y.tolist()\n",
    "    lists2.append(list2)\n",
    "    \n",
    "    accuracy_list.append(accuracy(list1, list2))\n",
    "        \n",
    "print(f'Accuracy = {sum(accuracy_list) / len(accuracy_list)}')\n",
    "\n",
    "print('{:6s} {:6s} {:6s}'.format('perc', 'pred', 'true'))\n",
    "for l1, l2, l3 in zip([round(num, 2) for num in output.view(-1).tolist()], list1, list2):\n",
    "    print(f'{l1:6.2f} {l2:6} {l3:6}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
